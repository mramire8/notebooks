{
 "metadata": {
  "name": "",
  "signature": "sha256:4e7db12715e69e4674f62c422642c676ed73ac42cfa807b3a4785ef98777f5f4"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# Expert Feature Analysis\n",
      "\n",
      "In this notebook, we analyze the features and errors made by the simulate expert on IMDB, SRAA and Twitter data. We will discuss: \n",
      "\n",
      "* Features relevant to classes based on the expert model\n",
      "* How the features change from different models (L1 vs L2)\n",
      "* What are the difficult snippets to classify (where is the expert making mistakes)\n",
      "\n",
      "## Configuration of Experiment\n",
      "\n",
      "We test two expert models: losgist regression with L1 regularization, and L2 regularization. Both models will use a deafult C parameter (C=1). The expert is trained on half of the data (training portion of the dataset), same procedure as performed for the active learning experiments. The expert is trained on the snippets from the data. \n",
      "\n",
      "We select N random snippets and test the expert accuracy, confidence, and evaluate the errors. \n"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## 1. Experiment Settings\n",
      "\n",
      "* Imports\n",
      "* Loading data\n",
      "* Fitting experts\n",
      "* Setting test data\n",
      "\n"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "## Imports \n",
      "%matplotlib inline\n",
      "\n",
      "STRUCTURED = '/Users/maru/MyCode/structured'\n",
      "IMDB_DATA='/Users/maru/MyCode/data/imdb'\n",
      "SRAA_DATA='/Users/maru/MyCode/data/imdb'\n",
      "TWIITER_DATA = ''\n",
      "\n",
      "STRUCTURED = '/Users/maru/My Code/structured'\n",
      "IMDB_DATA='/Users/maru/Dataset/aclImdb'\n",
      "SRAA_DATA='/Users/maru/Dataset/aviation/data'\n",
      "TWIITER_DATA = '/Users/maru/Dataset/twitter'\n",
      "\n",
      "import sys\n",
      "import os\n",
      "sys.path.append(os.path.abspath(STRUCTURED))\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import utilities.experimentutils as exputil\n",
      "import utilities.datautils as datautil\n",
      "import numpy as np\n",
      "import nltk\n",
      "from sklearn import metrics\n",
      "import matplotlib.pyplot as plt\n",
      "import matplotlib as mpl\n",
      "\n",
      "mpl.style.use('bmh')\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 2
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Loading Data\n",
      "rnd = np.random.RandomState(2345)\n",
      "vct = exputil.get_vectorizer({'vectorizer':\"tfidf\", 'limit':None, 'min_size':None})\n",
      "\n",
      "def load_data(dataname, path):\n",
      "    import pickle\n",
      "\n",
      "    DATA_PKL = path + '/data.pkl'\n",
      "\n",
      "    if os.path.isfile(DATA_PKL):\n",
      "        vct, data = pickle.load(open(DATA_PKL, 'rb'))\n",
      "    else:\n",
      "        vct = exputil.get_vectorizer({'vectorizer':\"tfidf\", 'limit':None, 'min_size':None})\n",
      "        data = datautil.load_dataset(dataname, path, categories=None, rnd=5463, shuffle=True)\n",
      "        data.train.data = np.array(data.train.data, dtype=object)\n",
      "        data.test.data = np.array(data.test.data, dtype=object)\n",
      "        data.train.bow = vct.fit_transform(data.train.data)\n",
      "        data.test.bow = vct.transform(data.test.data)\n",
      "        pickle.dump((vct, data), open(DATA_PKL, 'wb'))\n",
      "\n",
      "    return data, vct\n",
      "\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 6
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Get the sentences for testing\n",
      "def _sentences(sent, doc_labels):\n",
      "    data = []\n",
      "    true_labels = []\n",
      "    for sentences, doc_label in zip(sent, doc_labels):\n",
      "        data.extend(sentences)\n",
      "        true_labels.extend([doc_label] * len(sentences))\n",
      "    return data, np.array(true_labels)\n",
      "\n",
      "\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 11
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Expert Settings\n",
      "imdb, vct = load_data('imdb', IMDB_DATA)\n",
      "\n",
      "expertl2 = exputil.get_classifier('lrl2', parameter=1)\n",
      "expertl1 = exputil.get_classifier('lr', parameter=1)\n",
      "\n",
      "expertl2.fit(imdb.train.bow, imdb.train.target)\n",
      "expertl1.fit(imdb.train.bow, imdb.train.target)\n",
      "\n",
      "sent_tk = nltk.data.load('tokenizers/punkt/english.pickle')\n",
      "\n",
      "\n",
      "## Get Test data ready\n",
      "test_docs = rnd.permutation(len(imdb.test.target))\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 9
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Prepare testing data\n",
      "n=1000\n",
      "\n",
      "sent = sent_tk.tokenize_sents(imdb.test.data[test_docs[:n]])\n",
      "snippets, y_test = _sentences(sent, imdb.test.target[test_docs[:n]])\n",
      "x_test = vct.transform(snippets)\n",
      "\n",
      "print \"Number testing of documents:\", len(sent)\n",
      "print \"Number of sentences:\", len(snippets)\n",
      "print \"Number of features:\", x_test.shape[1]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Number testing of documents: 1000\n",
        "Number of sentences: 10697\n",
        "Number of features: 27316\n"
       ]
      }
     ],
     "prompt_number": 12
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## 2. Test: Most Relevant Features per Class \n",
      "\n",
      "Most relevant features of the expert \n"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def print_top_terms(model, terms, n=20):\n",
      "    print '\\nTop Coefficients'\n",
      "    coef = model.coef_[0]\n",
      "    srted = np.argsort(coef)\n",
      "    topi = srted[::-1][:n]\n",
      "    boti = srted[:n]\n",
      "    \n",
      "    print 'Class-0 Terms:\\n' + '\\n'.join('%s (%g)' % (n, c) for n, c in zip(terms[topi], coef[topi]))\n",
      "    print '\\nClass-1 Terms:\\n' + '\\n'.join('%s (%g)' % (n, c) for n, c in zip(terms[boti], coef[boti]))\n",
      "    print '\\nintercept=%g' % model.intercept_\n",
      "\n",
      "def print_terms_and_coef(row, terms, coef):\n",
      "    indices = sorted(row.indices, key=lambda x: coef[x])\n",
      "    print 'Top Terms:'\n",
      "    for i in indices:\n",
      "        if coef[i] != 0:\n",
      "            print terms[i], \"%.3f\" % coef[i]\n",
      "    print\n",
      "    "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 13
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### IMDB Expert Features\n",
      "Top 100 per class "
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Expert L2 regularization\n",
      "terms = np.array(vct.get_feature_names())\n",
      "print \"Classes\", imdb.train.target_names\n",
      "print_top_terms(expertl2, np.array(terms), n=50)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Classes ['neg', 'pos']\n",
        "\n",
        "Top Coefficients\n",
        "Class-0 Terms:\n",
        "great (7.40314)\n",
        "excellent (6.14048)\n",
        "best (5.05269)\n",
        "perfect (4.7995)\n",
        "wonderful (4.64902)\n",
        "amazing (4.13527)\n",
        "well (3.96193)\n",
        "today (3.75632)\n",
        "loved (3.74943)\n",
        "favorite (3.71035)\n",
        "fun (3.69905)\n",
        "love (3.63271)\n",
        "enjoyed (3.499)\n",
        "highly (3.35153)\n",
        "brilliant (3.29206)\n",
        "superb (3.28635)\n",
        "it (3.21836)\n",
        "definitely (2.99259)\n",
        "and (2.99227)\n",
        "still (2.96424)\n",
        "beautiful (2.94152)\n",
        "bit (2.92951)\n",
        "job (2.91885)\n",
        "liked (2.8882)\n",
        "also (2.86519)\n",
        "enjoyable (2.83431)\n",
        "fantastic (2.81908)\n",
        "you (2.6806)\n",
        "very (2.66965)\n",
        "enjoy (2.66535)\n",
        "both (2.59455)\n",
        "rare (2.53444)\n",
        "good (2.52046)\n",
        "world (2.4744)\n",
        "especially (2.46776)\n",
        "entertaining (2.43762)\n",
        "wonderfully (2.43026)\n",
        "funniest (2.41267)\n",
        "simple (2.37988)\n",
        "classic (2.36154)\n",
        "heart (2.35425)\n",
        "hilarious (2.33928)\n",
        "surprised (2.33319)\n",
        "life (2.32771)\n",
        "always (2.3046)\n",
        "perfectly (2.2998)\n",
        "gem (2.25464)\n",
        "recommended (2.24856)\n",
        "true (2.23719)\n",
        "will (2.23051)\n",
        "\n",
        "Class-1 Terms:\n",
        "worst (-9.20311)\n",
        "bad (-7.79338)\n",
        "awful (-6.47113)\n",
        "waste (-6.28699)\n",
        "boring (-6.00867)\n",
        "poor (-5.43114)\n",
        "terrible (-4.81422)\n",
        "nothing (-4.72223)\n",
        "worse (-4.55978)\n",
        "no (-4.27846)\n",
        "horrible (-4.23739)\n",
        "poorly (-4.219)\n",
        "dull (-4.17493)\n",
        "unfortunately (-4.04356)\n",
        "annoying (-3.81917)\n",
        "script (-3.78958)\n",
        "stupid (-3.78047)\n",
        "ridiculous (-3.68997)\n",
        "disappointment (-3.56317)\n",
        "instead (-3.53479)\n",
        "minutes (-3.51162)\n",
        "mess (-3.50963)\n",
        "fails (-3.50919)\n",
        "disappointing (-3.49119)\n",
        "supposed (-3.42372)\n",
        "lame (-3.418)\n",
        "even (-3.40967)\n",
        "save (-3.34834)\n",
        "avoid (-3.29191)\n",
        "badly (-3.25286)\n",
        "oh (-3.24158)\n",
        "just (-3.1794)\n",
        "lacks (-3.0626)\n",
        "money (-3.05769)\n",
        "pointless (-3.00237)\n",
        "looks (-2.92014)\n",
        "unless (-2.8968)\n",
        "only (-2.82346)\n",
        "weak (-2.8228)\n",
        "plot (-2.76385)\n",
        "predictable (-2.7631)\n",
        "laughable (-2.71359)\n",
        "crap (-2.71159)\n",
        "any (-2.68117)\n",
        "attempt (-2.58122)\n",
        "couldn (-2.54012)\n",
        "unfunny (-2.52495)\n",
        "tries (-2.52038)\n",
        "pathetic (-2.50628)\n",
        "half (-2.48105)\n",
        "\n",
        "intercept=-0.0742925\n"
       ]
      }
     ],
     "prompt_number": 27
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Expert L1 regularization\n",
      "print_top_terms(expertl1, np.array(terms), n=50)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Top Coefficients\n",
        "Class-0 Terms:\n",
        "excellent (13.6307)\n",
        "perfect (11.4718)\n",
        "great (11.2124)\n",
        "wonderful (9.80502)\n",
        "wonderfully (9.52575)\n",
        "amazing (9.25298)\n",
        "refreshing (9.1792)\n",
        "best (8.71312)\n",
        "today (8.08792)\n",
        "favorite (7.75519)\n",
        "brilliant (7.26138)\n",
        "superb (7.22829)\n",
        "rare (7.22215)\n",
        "highly (7.13076)\n",
        "enjoyable (6.69884)\n",
        "loved (6.68104)\n",
        "noir (6.46586)\n",
        "fantastic (6.17932)\n",
        "funniest (6.03204)\n",
        "enjoyed (5.89457)\n",
        "definitely (5.84849)\n",
        "perfectly (5.7102)\n",
        "fun (5.43988)\n",
        "well (5.40516)\n",
        "touching (5.24678)\n",
        "incredible (5.14273)\n",
        "subtle (5.09727)\n",
        "simple (5.00283)\n",
        "bit (4.96401)\n",
        "surprisingly (4.87689)\n",
        "liked (4.83479)\n",
        "beautiful (4.82737)\n",
        "gem (4.79942)\n",
        "beautifully (4.75461)\n",
        "love (4.75268)\n",
        "finest (4.71223)\n",
        "hilarious (4.70259)\n",
        "job (4.68165)\n",
        "surprised (4.657)\n",
        "entertaining (4.64287)\n",
        "delightful (4.42805)\n",
        "still (4.41908)\n",
        "outstanding (4.38517)\n",
        "terrific (4.38299)\n",
        "world (4.36258)\n",
        "recommended (4.21433)\n",
        "moving (4.2108)\n",
        "unique (4.20792)\n",
        "fascinating (4.18531)\n",
        "enjoy (4.14857)\n",
        "\n",
        "Class-1 Terms:\n",
        "worst (-23.0285)\n",
        "waste (-18.504)\n",
        "awful (-17.0069)\n",
        "poorly (-13.6239)\n",
        "boring (-12.9875)\n",
        "disappointment (-12.4296)\n",
        "fails (-11.7651)\n",
        "mess (-11.6347)\n",
        "dull (-11.3054)\n",
        "bad (-11.1422)\n",
        "lacks (-11.119)\n",
        "poor (-10.9166)\n",
        "horrible (-10.4893)\n",
        "disappointing (-10.4668)\n",
        "laughable (-10.3439)\n",
        "unfunny (-10.1473)\n",
        "worse (-10.1167)\n",
        "pointless (-10.0926)\n",
        "terrible (-9.95195)\n",
        "annoying (-9.69245)\n",
        "unfortunately (-9.63914)\n",
        "badly (-9.38504)\n",
        "ridiculous (-9.3432)\n",
        "avoid (-9.13358)\n",
        "save (-8.43738)\n",
        "nothing (-8.43237)\n",
        "forgettable (-8.37294)\n",
        "lame (-8.07242)\n",
        "oh (-7.7971)\n",
        "supposed (-7.3243)\n",
        "wooden (-7.17083)\n",
        "instead (-6.94805)\n",
        "pathetic (-6.74809)\n",
        "redeeming (-6.69728)\n",
        "unless (-6.60298)\n",
        "script (-6.49221)\n",
        "mediocre (-6.48338)\n",
        "basically (-6.39206)\n",
        "stupid (-6.14769)\n",
        "mst3k (-6.036)\n",
        "lousy (-6.03483)\n",
        "weak (-5.96211)\n",
        "no (-5.93144)\n",
        "mildly (-5.807)\n",
        "minutes (-5.71842)\n",
        "pretentious (-5.6911)\n",
        "looks (-5.68645)\n",
        "insult (-5.66243)\n",
        "tedious (-5.54425)\n",
        "wonder (-5.43602)\n",
        "\n",
        "intercept=-0.101363\n"
       ]
      }
     ],
     "prompt_number": 25
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Difference in terms from the two models \n",
      "coef1 = expertl1.coef_[0]\n",
      "srted1 = np.argsort(abs(coef1))[::-1]\n",
      "l1_terms = terms[srted1][:500]\n",
      "# l1_terms = np.append(l1_terms,terms[srted1][-500:])\n",
      "\n",
      "coef2 = expertl2.coef_[0]\n",
      "srted2 = np.argsort(abs(coef2))[::-1]\n",
      "l2_terms = terms[srted2][:500]\n",
      "# l2_terms = np.append(l2_terms, terms[srted2][-500:])\n",
      "\n",
      "intr = list(set(l1_terms) & set(l2_terms))\n",
      "l1_l2 = list(set(l1_terms) - set(l2_terms))\n",
      "print 'Intersection:', len(intr)\n",
      "print 'Terms:\\n' + '\\n'.join('%s' % n for n in intr[:20])\n",
      "print '\\nDiff', len(l1_l2)\n",
      "print 'Diff Terms:\\n' + '\\n'.join('%s ' % n for n in l1_l2[:20])\n",
      "\n",
      "l2_l1 = list(set(l2_terms) - set(l1_terms))\n",
      "print 'Diff Terms:\\n' + '\\n'.join('%s ' % n for n in l2_l1[:20])\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Intersection: 440\n",
        "Terms:\n",
        "skip\n",
        "lack\n",
        "enjoyable\n",
        "poorly\n",
        "dreadful\n",
        "supposedly\n",
        "disgusting\n",
        "sorry\n",
        "worth\n",
        "worse\n",
        "far\n",
        "caught\n",
        "worst\n",
        "jack\n",
        "awful\n",
        "screaming\n",
        "incoherent\n",
        "wooden\n",
        "trite\n",
        "enjoy\n",
        "\n",
        "Diff 60\n",
        "Diff Terms:\n",
        "holmes \n",
        "modesty \n",
        "charles \n",
        "brothers \n",
        "murray \n",
        "jesus \n",
        "spinal \n",
        "scientist \n",
        "cassie \n",
        "ability \n",
        "impact \n",
        "orleans \n",
        "unusual \n",
        "said \n",
        "monkey \n",
        "sidney \n",
        "has \n",
        "spectacular \n",
        "ralph \n",
        "three \n",
        "Diff Terms:\n",
        "major \n",
        "atrocious \n",
        "dire \n",
        "family \n",
        "point \n",
        "favorites \n",
        "ages \n",
        "rest \n",
        "sex \n",
        "themes \n",
        "as \n",
        "manages \n",
        "simply \n",
        "have \n",
        "our \n",
        "throughout \n",
        "brilliantly \n",
        "rented \n",
        "different \n",
        "humor \n"
       ]
      }
     ],
     "prompt_number": 47
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## 3. Test: Error Analysis\n",
      "\n",
      "Check the snippets where the expert's label is incorret but the model is highly confident. \n",
      "\n",
      "We select 1000 random documents and split them into snippets (sentences). We test the simulated expert classifier on the resulting snippets and check for errors. "
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### IMDB Expert Error Analysis\n",
      "\n",
      "We tested 1000 documents and their snippets. "
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# error analysis    \n",
      "def error_analysis(clf, test_x, test_y, snippets, terms, threshold=.95, sort=False, n=20):\n",
      "    predicted = clf.predict(test_x)\n",
      "    predicted_proba = clf.predict_proba(test_x)\n",
      "    print 'Accuracy: %.4f' % metrics.accuracy_score(test_y, predicted)\n",
      "    print 'Test size: %s' % len(test_y)\n",
      "    print '\\nERRORS (P > {}):'.format(threshold)\n",
      "    if sort:\n",
      "        order = predicted_proba.max(axis=1).argsort()[::-1]\n",
      "    else:\n",
      "        order = range(predicted_proba.shape[0])\n",
      "    for i in order:\n",
      "        probability = predicted_proba[i][predicted[i]]\n",
      "        # If we're very wrong.\n",
      "        if predicted[i] != y_test[i] and probability > threshold:\n",
      "            \n",
      "            print '\\npred=%d (%g) truth=%d \\ntext=%s ' % (predicted[i],\n",
      "                                                            probability,\n",
      "                                                            test_y[i],\n",
      "                                                            snippets[i])\n",
      "            print_terms_and_coef(test_x.getrow(i), terms, clf.coef_[0])\n",
      "\n",
      "print \"EXPERT L2\"\n",
      "error_analysis(expertl2, x_test, y_test, snippets, vct.get_feature_names(), sort=True)\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "EXPERT L2\n",
        "Accuracy: 0.6837"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Test size: 10697\n",
        "\n",
        "ERRORS (P > 0.95):\n",
        "\n",
        "pred=0 (0.999492) truth=1 \n",
        "text=Not bad, not bad at all. \n",
        "Top Terms:\n",
        "bad -7.793\n",
        "not -2.435\n",
        "at -0.747\n",
        "all 0.054\n",
        "\n",
        "\n",
        "pred=1 (0.997728) truth=0 \n",
        "text=Try great-great-GREAT! \n",
        "Top Terms:\n",
        "try -0.884\n",
        "great 7.403\n",
        "\n",
        "\n",
        "pred=1 (0.996098) truth=0 \n",
        "text=All excellent. \n",
        "Top Terms:\n",
        "all 0.054\n",
        "excellent 6.140\n",
        "\n",
        "\n",
        "pred=0 (0.995839) truth=1 \n",
        "text=But that isn't a bad thing. \n",
        "Top Terms:\n",
        "bad -7.793\n",
        "thing -1.762\n",
        "isn -0.947\n",
        "but -0.823\n",
        "that -0.323\n",
        "\n",
        "\n",
        "pred=0 (0.993017) truth=1 \n",
        "text=Don't waste your time with 1-3. \n",
        "Top Terms:\n",
        "waste -6.287\n",
        "don -1.874\n",
        "your -0.488\n",
        "with 0.203\n",
        "time 0.730\n",
        "\n",
        "\n",
        "pred=0 (0.991061) truth=1 \n",
        "text=So nothing much there. \n",
        "Top Terms:\n",
        "nothing -4.722\n",
        "there -1.570\n",
        "much -1.225\n",
        "so -0.698\n",
        "\n",
        "\n",
        "pred=1 (0.987543) truth=0 \n",
        "text=And while I haven't seen all of their other movies, I've always enjoyed their performances until now. \n",
        "Top Terms:\n",
        "of -0.029\n",
        "ve 0.042\n",
        "all 0.054\n",
        "until 0.551\n",
        "movies 0.574\n",
        "their 0.635\n",
        "while 0.657\n",
        "haven 0.785\n",
        "other 0.835\n",
        "now 1.120\n",
        "performances 1.742\n",
        "seen 1.878\n",
        "always 2.305\n",
        "and 2.992\n",
        "enjoyed 3.499\n",
        "\n",
        "\n",
        "pred=0 (0.987292) truth=1 \n",
        "text=Answerve: No! \n",
        "Top Terms:\n",
        "no -4.278\n",
        "\n",
        "\n",
        "pred=0 (0.987292) truth=1 \n",
        "text=No. \n",
        "Top Terms:\n",
        "no -4.278\n",
        "\n",
        "\n",
        "pred=1 (0.984573) truth=0 \n",
        "text=I'm sure the soundtrack is wonderful, though. \n",
        "Top Terms:\n",
        "sure 0.446\n",
        "the 0.722\n",
        "soundtrack 1.324\n",
        "is 1.359\n",
        "though 1.540\n",
        "wonderful 4.649\n",
        "\n",
        "\n",
        "pred=1 (0.981629) truth=0 \n",
        "text=Efremova is great and Goldblum is very good. \n",
        "Top Terms:\n",
        "goldblum 0.029\n",
        "is 1.359\n",
        "good 2.520\n",
        "very 2.670\n",
        "and 2.992\n",
        "great 7.403\n",
        "\n",
        "\n",
        "pred=0 (0.979959) truth=1 \n",
        "text=Jane: (seriously) NO, it's not, it's awful! \n",
        "Top Terms:\n",
        "awful -6.471\n",
        "no -4.278\n",
        "not -2.435\n",
        "seriously -1.259\n",
        "jane 0.506\n",
        "it 3.218\n",
        "\n",
        "\n",
        "pred=0 (0.97918) truth=1 \n",
        "text=We also have some that are so 'good' they suck, and then, we have some that are so bad they are just bad. \n",
        "Top Terms:\n",
        "bad -7.793\n",
        "just -3.179\n",
        "then -2.095\n",
        "they -1.185\n",
        "have -1.114\n",
        "so -0.698\n",
        "are -0.640\n",
        "suck -0.602\n",
        "that -0.323\n",
        "some -0.095\n",
        "we 0.292\n",
        "good 2.520\n",
        "also 2.865\n",
        "and 2.992\n",
        "\n",
        "\n",
        "pred=0 (0.977785) truth=1 \n",
        "text=I had no problem with any of them in the end. \n",
        "Top Terms:\n",
        "no -4.278\n",
        "any -2.681\n",
        "problem -2.316\n",
        "had -0.772\n",
        "end -0.233\n",
        "them -0.222\n",
        "of -0.029\n",
        "with 0.203\n",
        "in 0.483\n",
        "the 0.722\n",
        "\n",
        "\n",
        "pred=1 (0.976288) truth=0 \n",
        "text=You will be surprised at how miserable you become watching this especially if you loved the series. \n",
        "Top Terms:\n",
        "if -1.657\n",
        "this -1.135\n",
        "be -1.128\n",
        "watching -1.089\n",
        "at -0.747\n",
        "miserable -0.273\n",
        "how 0.038\n",
        "become 0.628\n",
        "the 0.722\n",
        "series 1.868\n",
        "will 2.231\n",
        "surprised 2.333\n",
        "especially 2.468\n",
        "you 2.681\n",
        "loved 3.749\n",
        "\n",
        "\n",
        "pred=0 (0.975221) truth=1 \n",
        "text=Not that Grey's novel is a bad one; I just like the movie story better. \n",
        "Top Terms:\n",
        "bad -7.793\n",
        "just -3.179\n",
        "not -2.435\n",
        "better -2.012\n",
        "like -0.686\n",
        "novel -0.543\n",
        "that -0.323\n",
        "movie -0.312\n",
        "grey -0.219\n",
        "one 0.095\n",
        "the 0.722\n",
        "story 0.921\n",
        "is 1.359\n",
        "\n",
        "\n",
        "pred=0 (0.972492) truth=1 \n",
        "text=There is so much emotions happening even in small moments that the plot breezes by; nothing seems wasted or placed on screen due to a lack of editing. \n",
        "Top Terms:\n",
        "nothing -4.722\n",
        "even -3.410\n",
        "plot -2.764\n",
        "wasted -2.412\n",
        "seems -2.381\n",
        "lack -1.978\n",
        "there -1.570\n",
        "or -1.359\n",
        "much -1.225\n",
        "to -1.219\n",
        "editing -1.182\n",
        "so -0.698\n",
        "on -0.676\n",
        "by -0.483\n",
        "that -0.323\n",
        "happening -0.246\n",
        "of -0.029\n",
        "screen 0.073\n",
        "placed 0.076\n",
        "moments 0.324\n",
        "in 0.483\n",
        "due 0.525\n",
        "the 0.722\n",
        "small 1.130\n",
        "emotions 1.301\n",
        "is 1.359\n",
        "\n",
        "\n",
        "pred=0 (0.969988) truth=1 \n",
        "text=(or, at least, they don't seem to care). \n",
        "Top Terms:\n",
        "least -2.373\n",
        "don -1.874\n",
        "or -1.359\n",
        "care -1.240\n",
        "to -1.219\n",
        "they -1.185\n",
        "at -0.747\n",
        "seem -0.297\n",
        "\n",
        "\n",
        "pred=1 (0.968387) truth=0 \n",
        "text=THAT is GREAT ACTING. \n",
        "Top Terms:\n",
        "acting -2.073\n",
        "that -0.323\n",
        "is 1.359\n",
        "great 7.403\n",
        "\n",
        "\n",
        "pred=0 (0.967142) truth=1 \n",
        "text=Everything is just out of the blue, and nothing seems to make sense. \n",
        "Top Terms:\n",
        "nothing -4.722\n",
        "just -3.179\n",
        "seems -2.381\n",
        "make -1.998\n",
        "to -1.219\n",
        "sense -0.773\n",
        "blue -0.291\n",
        "out -0.275\n",
        "of -0.029\n",
        "everything 0.520\n",
        "the 0.722\n",
        "is 1.359\n",
        "and 2.992\n",
        "\n",
        "\n",
        "pred=1 (0.966551) truth=0 \n",
        "text=How is it beautiful?? \n",
        "Top Terms:\n",
        "how 0.038\n",
        "is 1.359\n",
        "beautiful 2.942\n",
        "it 3.218\n",
        "\n",
        "\n",
        "pred=1 (0.964431) truth=0 \n",
        "text=I enjoyed the beautiful scenery in this movie the first time I saw it when I was 9 . \n",
        "Top Terms:\n",
        "was -1.557\n",
        "this -1.135\n",
        "scenery -0.418\n",
        "movie -0.312\n",
        "in 0.483\n",
        "the 0.722\n",
        "time 0.730\n",
        "when 0.825\n",
        "first 0.870\n",
        "saw 0.884\n",
        "beautiful 2.942\n",
        "it 3.218\n",
        "enjoyed 3.499\n",
        "\n",
        "\n",
        "pred=0 (0.964138) truth=1 \n",
        "text=BUt I don't have that problem with this movie. \n",
        "Top Terms:\n",
        "problem -2.316\n",
        "don -1.874\n",
        "this -1.135\n",
        "have -1.114\n",
        "but -0.823\n",
        "that -0.323\n",
        "movie -0.312\n",
        "with 0.203\n",
        "\n",
        "\n",
        "pred=1 (0.964029) truth=0 \n",
        "text=Well hopefully one day this type of movies will not be released but then hey where will all the Low Budget actors go :-) <br /><br />The movie also contains many Bloops but that I will leave to you to find because it adds quite a bit of fun while watching and also if you a bit of a perfectionist it will bother you ;-) Cheers! \n",
        "Top Terms:\n",
        "not -2.435\n",
        "then -2.095\n",
        "if -1.657\n",
        "bother -1.322\n",
        "low -1.308\n",
        "to -1.219\n",
        "this -1.135\n",
        "be -1.128\n",
        "actors -1.108\n",
        "watching -1.089\n",
        "but -0.823\n",
        "br -0.714\n",
        "because -0.468\n",
        "that -0.323\n",
        "movie -0.312\n",
        "where -0.255\n",
        "budget -0.254\n",
        "hopefully -0.234\n",
        "leave -0.105\n",
        "go -0.099\n",
        "hey -0.055\n",
        "of -0.029\n",
        "perfectionist 0.021\n",
        "all 0.054\n",
        "one 0.095\n",
        "contains 0.469\n",
        "type 0.491\n",
        "cheers 0.571\n",
        "movies 0.574\n",
        "while 0.657\n",
        "the 0.722\n",
        "released 0.768\n",
        "adds 0.983\n",
        "many 1.008\n",
        "find 1.029\n",
        "quite 1.391\n",
        "day 1.476\n",
        "will 2.231\n",
        "you 2.681\n",
        "also 2.865\n",
        "bit 2.930\n",
        "and 2.992\n",
        "it 3.218\n",
        "fun 3.699\n",
        "well 3.962\n",
        "\n",
        "\n",
        "pred=0 (0.963693) truth=1 \n",
        "text=One line by itself, is not so bad but this movie borrows so much from so many movies it becomes a bad risk.<br /><br />BUT...<br /><br />See The Movie! \n",
        "Top Terms:\n",
        "bad -7.793\n",
        "not -2.435\n",
        "much -1.225\n",
        "this -1.135\n",
        "but -0.823\n",
        "line -0.756\n",
        "becomes -0.723\n",
        "br -0.714\n",
        "so -0.698\n",
        "by -0.483\n",
        "itself -0.472\n",
        "risk -0.336\n",
        "movie -0.312\n",
        "borrows -0.126\n",
        "one 0.095\n",
        "from 0.119\n",
        "movies 0.574\n",
        "the 0.722\n",
        "many 1.008\n",
        "is 1.359\n",
        "see 2.033\n",
        "it 3.218\n",
        "\n",
        "\n",
        "pred=1 (0.959692) truth=0 \n",
        "text=He played very well and convincing for his age... \n",
        "Top Terms:\n",
        "for -0.487\n",
        "convincing -0.171\n",
        "he 0.367\n",
        "age 1.065\n",
        "his 1.210\n",
        "played 1.287\n",
        "very 2.670\n",
        "and 2.992\n",
        "well 3.962\n",
        "\n",
        "\n",
        "pred=1 (0.959567) truth=0 \n",
        "text=And that's it. \n",
        "Top Terms:\n",
        "that -0.323\n",
        "and 2.992\n",
        "it 3.218\n",
        "\n",
        "\n",
        "pred=1 (0.959557) truth=0 \n",
        "text=It is cloyed. \n",
        "Top Terms:\n",
        "is 1.359\n",
        "it 3.218\n",
        "\n",
        "\n",
        "pred=0 (0.95953) truth=1 \n",
        "text=It had a script, too! \n",
        "Top Terms:\n",
        "script -3.790\n",
        "too -1.726\n",
        "had -0.772\n",
        "it 3.218\n",
        "\n",
        "\n",
        "pred=1 (0.959096) truth=0 \n",
        "text=Not the best. \n",
        "Top Terms:\n",
        "not -2.435\n",
        "the 0.722\n",
        "best 5.053\n",
        "\n",
        "\n",
        "pred=1 (0.958693) truth=0 \n",
        "text=Not highly recommended. \n",
        "Top Terms:\n",
        "not -2.435\n",
        "recommended 2.249\n",
        "highly 3.352\n",
        "\n",
        "\n",
        "pred=1 (0.958674) truth=0 \n",
        "text=It's o.k. \n",
        "Top Terms:\n",
        "it 3.218\n",
        "\n",
        "\n",
        "pred=0 (0.955368) truth=1 \n",
        "text=If Martha Coolidge had been given more money and time on this movie then the results would of been even better. \n",
        "Top Terms:\n",
        "even -3.410\n",
        "money -3.058\n",
        "then -2.095\n",
        "better -2.012\n",
        "would -1.990\n",
        "been -1.836\n",
        "if -1.657\n",
        "this -1.135\n",
        "had -0.772\n",
        "on -0.676\n",
        "given -0.380\n",
        "movie -0.312\n",
        "of -0.029\n",
        "results 0.101\n",
        "martha 0.204\n",
        "the 0.722\n",
        "time 0.730\n",
        "more 1.505\n",
        "and 2.992\n",
        "\n",
        "\n",
        "pred=0 (0.955178) truth=1 \n",
        "text=I loved this one because the worst thing in it was when one of the boys said \"stupid\". \n",
        "Top Terms:\n",
        "worst -9.203\n",
        "stupid -3.780\n",
        "thing -1.762\n",
        "was -1.557\n",
        "this -1.135\n",
        "said -0.933\n",
        "because -0.468\n",
        "of -0.029\n",
        "one 0.095\n",
        "in 0.483\n",
        "the 0.722\n",
        "boys 0.818\n",
        "when 0.825\n",
        "it 3.218\n",
        "loved 3.749\n",
        "\n",
        "\n",
        "pred=0 (0.955159) truth=1 \n",
        "text=<br /><br />The rest was done by Fragata, from the script to the dialogue, from camera work to editing. \n",
        "Top Terms:\n",
        "script -3.790\n",
        "was -1.557\n",
        "camera -1.345\n",
        "rest -1.236\n",
        "to -1.219\n",
        "editing -1.182\n",
        "dialogue -1.008\n",
        "br -0.714\n",
        "by -0.483\n",
        "from 0.119\n",
        "work 0.275\n",
        "done 0.394\n",
        "the 0.722\n",
        "\n",
        "\n",
        "pred=1 (0.955029) truth=0 \n",
        "text=She has her big moment with \"Love Is Where You Find It\" which suits her perfectly and shows off her abilities. \n",
        "Top Terms:\n",
        "off -1.953\n",
        "where -0.255\n",
        "abilities 0.063\n",
        "big 0.095\n",
        "which 0.126\n",
        "moment 0.165\n",
        "with 0.203\n",
        "suits 0.337\n",
        "her 0.510\n",
        "she 0.637\n",
        "has 0.917\n",
        "find 1.029\n",
        "is 1.359\n",
        "shows 2.223\n",
        "perfectly 2.300\n",
        "you 2.681\n",
        "and 2.992\n",
        "it 3.218\n",
        "love 3.633\n",
        "\n",
        "\n",
        "pred=0 (0.95472) truth=1 \n",
        "text=I was not disappointed. \n",
        "Top Terms:\n",
        "not -2.435\n",
        "disappointed -1.940\n",
        "was -1.557\n",
        "\n",
        "\n",
        "pred=0 (0.953221) truth=1 \n",
        "text=The ending(..explaining the old clich\u00c3\u00a9:\"It's only a movie\")couldn't work any better than it does here. \n",
        "Top Terms:\n",
        "only -2.823\n",
        "any -2.681\n",
        "couldn -2.540\n",
        "clich\u00e3 -2.240\n",
        "better -2.012\n",
        "here -1.082\n",
        "does -0.539\n",
        "old -0.446\n",
        "movie -0.312\n",
        "explaining -0.208\n",
        "than -0.207\n",
        "ending -0.045\n",
        "work 0.275\n",
        "the 0.722\n",
        "it 3.218\n",
        "\n",
        "\n",
        "pred=0 (0.95318) truth=1 \n",
        "text=Don't pay too much attention to one thing or you would be sorry. \n",
        "Top Terms:\n",
        "sorry -2.091\n",
        "would -1.990\n",
        "don -1.874\n",
        "thing -1.762\n",
        "too -1.726\n",
        "or -1.359\n",
        "much -1.225\n",
        "to -1.219\n",
        "be -1.128\n",
        "pay -0.531\n",
        "one 0.095\n",
        "attention 0.887\n",
        "you 2.681\n",
        "\n",
        "\n",
        "pred=0 (0.952402) truth=1 \n",
        "text=And Steven Dorff, hyped in the previews, makes a more than bad enough bad guy to Snipes' hero. \n",
        "Top Terms:\n",
        "bad -7.793\n",
        "enough -1.771\n",
        "guy -1.220\n",
        "to -1.219\n",
        "snipes -0.858\n",
        "hero -0.773\n",
        "hyped -0.478\n",
        "dorff -0.355\n",
        "steven -0.343\n",
        "than -0.207\n",
        "previews -0.002\n",
        "in 0.483\n",
        "the 0.722\n",
        "more 1.505\n",
        "makes 2.063\n",
        "and 2.992\n",
        "\n",
        "\n",
        "pred=0 (0.95205) truth=1 \n",
        "text=I'm assuming there were cuts in the script--I can't believe the movie just left all this open. \n",
        "Top Terms:\n",
        "script -3.790\n",
        "just -3.179\n",
        "there -1.570\n",
        "left -1.434\n",
        "were -1.291\n",
        "this -1.135\n",
        "believe -0.759\n",
        "assuming -0.479\n",
        "open -0.436\n",
        "movie -0.312\n",
        "can -0.193\n",
        "cuts 0.006\n",
        "all 0.054\n",
        "in 0.483\n",
        "the 0.722\n",
        "\n",
        "\n",
        "pred=0 (0.951186) truth=1 \n",
        "text=<br /><br />They tried to somehow recreate this movie in Masterminds, but came up short with some really bad acting. \n",
        "Top Terms:\n",
        "bad -7.793\n",
        "acting -2.073\n",
        "to -1.219\n",
        "they -1.185\n",
        "tried -1.180\n",
        "this -1.135\n",
        "somehow -0.985\n",
        "but -0.823\n",
        "br -0.714\n",
        "movie -0.312\n",
        "recreate -0.273\n",
        "up -0.272\n",
        "some -0.095\n",
        "really -0.026\n",
        "with 0.203\n",
        "in 0.483\n",
        "came 0.825\n",
        "short 0.875\n",
        "\n",
        "\n",
        "pred=0 (0.951015) truth=1 \n",
        "text=And I was trying to figure out why Hilary Swank was supposed to be South African and sounded like she was trying to put on an accent but sounded very American... as if she was making a weak attempt at putting on the accent. \n",
        "Top Terms:\n",
        "supposed -3.424\n",
        "weak -2.823\n",
        "attempt -2.581\n",
        "why -2.432\n",
        "trying -1.825\n",
        "making -1.719\n",
        "if -1.657\n",
        "was -1.557\n",
        "to -1.219\n",
        "accent -1.190\n",
        "be -1.128\n",
        "but -0.823\n",
        "at -0.747\n",
        "like -0.686\n",
        "on -0.676\n",
        "sounded -0.578\n",
        "an -0.422\n",
        "out -0.275\n",
        "putting -0.161\n",
        "figure -0.058\n",
        "swank -0.028\n",
        "put 0.173\n",
        "hilary 0.231\n",
        "african 0.390\n",
        "south 0.412\n",
        "she 0.637\n",
        "the 0.722\n",
        "american 0.852\n",
        "as 1.291\n",
        "very 2.670\n",
        "and 2.992\n",
        "\n",
        "\n",
        "pred=1 (0.950632) truth=0 \n",
        "text=The film needs to be made available on video so that the world can enjoy this terrific performance again. \n",
        "Top Terms:\n",
        "to -1.219\n",
        "this -1.135\n",
        "be -1.128\n",
        "so -0.698\n",
        "on -0.676\n",
        "video -0.431\n",
        "that -0.323\n",
        "can -0.193\n",
        "made -0.183\n",
        "needs 0.452\n",
        "the 0.722\n",
        "film 0.723\n",
        "again 0.854\n",
        "performance 1.418\n",
        "available 1.667\n",
        "terrific 1.824\n",
        "world 2.474\n",
        "enjoy 2.665\n",
        "\n"
       ]
      }
     ],
     "prompt_number": 53
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print \"EXPERT L1\"\n",
      "error_analysis(expertl1, x_test, y_test, snippets, vct.get_feature_names(), sort=True)\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "EXPERT L1\n",
        "Accuracy: 0.6685\n",
        "Test size: 10697\n",
        "\n",
        "ERRORS (P > 0.95):\n",
        "\n",
        "pred=0 (0.999998) truth=1 \n",
        "text=Don't waste your time with 1-3. \n",
        "Top Terms:\n",
        "waste -18.504\n",
        "don -2.241\n",
        "with 0.048\n",
        "time 1.216\n",
        "\n",
        "\n",
        "pred=1 (0.999996) truth=0 \n",
        "text=All excellent. \n",
        "Top Terms:\n",
        "excellent 13.631\n",
        "\n",
        "\n",
        "pred=0 (0.999974) truth=1 \n",
        "text=Not bad, not bad at all. \n",
        "Top Terms:\n",
        "bad -11.142\n",
        "not -3.455\n",
        "\n",
        "\n",
        "pred=1 (0.999934) truth=0 \n",
        "text=Try great-great-GREAT! "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Top Terms:\n",
        "try -0.475\n",
        "great 11.212\n",
        "\n",
        "\n",
        "pred=0 (0.999905) truth=1 \n",
        "text=Jane: (seriously) NO, it's not, it's awful! \n",
        "Top Terms:\n",
        "awful -17.007\n",
        "no -5.931\n",
        "not -3.455\n",
        "seriously -1.136\n",
        "it 3.874\n",
        "\n",
        "\n",
        "pred=0 (0.999594) truth=1 \n",
        "text=The film lacks in action. \n",
        "Top Terms:\n",
        "lacks -11.119\n",
        "in 0.356\n",
        "film 0.675\n",
        "the 1.026\n",
        "action 1.496\n",
        "\n",
        "\n",
        "pred=0 (0.999564) truth=1 \n",
        "text=Never a dull moment. \n",
        "Top Terms:\n",
        "dull -11.305\n",
        "\n",
        "\n",
        "pred=0 (0.999355) truth=1 \n",
        "text=I loved this one because the worst thing in it was when one of the boys said \"stupid\". \n",
        "Top Terms:\n",
        "worst -23.029\n",
        "stupid -6.148\n",
        "was -1.696\n",
        "thing -1.662\n",
        "said -1.224\n",
        "this -0.783\n",
        "when 0.038\n",
        "in 0.356\n",
        "boys 0.450\n",
        "the 1.026\n",
        "it 3.874\n",
        "loved 6.681\n",
        "\n",
        "\n",
        "pred=0 (0.999283) truth=1 \n",
        "text=So nothing much there. \n",
        "Top Terms:\n",
        "nothing -8.432\n",
        "there -1.768\n",
        "much -1.721\n",
        "\n",
        "\n",
        "pred=1 (0.999015) truth=0 \n",
        "text=I'm sure the soundtrack is wonderful, though. \n",
        "Top Terms:\n",
        "the 1.026\n",
        "soundtrack 1.550\n",
        "is 1.739\n",
        "though 1.935\n",
        "wonderful 9.805\n",
        "\n",
        "\n",
        "pred=1 (0.998791) truth=0 \n",
        "text=Not highly recommended. \n",
        "Top Terms:\n",
        "not -3.455\n",
        "recommended 4.214\n",
        "highly 7.131\n",
        "\n",
        "\n",
        "pred=1 (0.998665) truth=0 \n",
        "text=the acting is so wonderful to. \n",
        "Top Terms:\n",
        "acting -1.949\n",
        "to -0.366\n",
        "the 1.026\n",
        "is 1.739\n",
        "wonderful 9.805\n",
        "\n",
        "\n",
        "pred=0 (0.998463) truth=1 \n",
        "text=But that isn't a bad thing. \n",
        "Top Terms:\n",
        "bad -11.142\n",
        "thing -1.662\n",
        "but -0.448\n",
        "isn -0.382\n",
        "\n",
        "\n",
        "pred=0 (0.998182) truth=1 \n",
        "text=Unfortunately, it didn't last. \n",
        "Top Terms:\n",
        "unfortunately -9.639\n",
        "didn -2.266\n",
        "last 0.961\n",
        "it 3.874\n",
        "\n",
        "\n",
        "pred=0 (0.998065) truth=1 \n",
        "text=A recent book, the Worst Movies of All Time, includes Heaven's Gate. \n",
        "Top Terms:\n",
        "worst -23.029\n",
        "book -2.081\n",
        "movies 0.429\n",
        "the 1.026\n",
        "time 1.216\n",
        "\n",
        "\n",
        "pred=1 (0.998044) truth=0 \n",
        "text=You will be surprised at how miserable you become watching this especially if you loved the series. \n",
        "Top Terms:\n",
        "if -2.407\n",
        "be -0.801\n",
        "this -0.783\n",
        "watching -0.745\n",
        "become 0.015\n",
        "the 1.026\n",
        "will 2.462\n",
        "series 2.527\n",
        "you 3.110\n",
        "especially 3.917\n",
        "surprised 4.657\n",
        "loved 6.681\n",
        "\n",
        "\n",
        "pred=1 (0.99763) truth=0 \n",
        "text=THAT is GREAT ACTING. \n",
        "Top Terms:\n",
        "acting -1.949\n",
        "is 1.739\n",
        "great 11.212\n",
        "\n",
        "\n",
        "pred=0 (0.997607) truth=1 \n",
        "text=No. \n",
        "Top Terms:\n",
        "no -5.931\n",
        "\n",
        "\n",
        "pred=0 (0.997607) truth=1 \n",
        "text=Answerve: No! \n",
        "Top Terms:\n",
        "no -5.931\n",
        "\n",
        "\n",
        "pred=1 (0.997532) truth=0 \n",
        "text=The film needs to be made available on video so that the world can enjoy this terrific performance again. \n",
        "Top Terms:\n",
        "be -0.801\n",
        "this -0.783\n",
        "on -0.533\n",
        "to -0.366\n",
        "video -0.180\n",
        "again 0.401\n",
        "film 0.675\n",
        "the 1.026\n",
        "performance 1.831\n",
        "available 3.649\n",
        "enjoy 4.149\n",
        "world 4.363\n",
        "terrific 4.383\n",
        "\n",
        "\n",
        "pred=0 (0.997301) truth=1 \n",
        "text=There is so much emotions happening even in small moments that the plot breezes by; nothing seems wasted or placed on screen due to a lack of editing. \n",
        "Top Terms:\n",
        "nothing -8.432\n",
        "wasted -5.068\n",
        "even -4.536\n",
        "seems -4.165\n",
        "lack -3.883\n",
        "plot -3.591\n",
        "there -1.768\n",
        "much -1.721\n",
        "editing -0.825\n",
        "or -0.724\n",
        "by -0.656\n",
        "on -0.533\n",
        "to -0.366\n",
        "in 0.356\n",
        "small 0.798\n",
        "the 1.026\n",
        "is 1.739\n",
        "emotions 2.039\n",
        "\n",
        "\n",
        "pred=1 (0.996828) truth=0 \n",
        "text=Not the best. \n",
        "Top Terms:\n",
        "not -3.455\n",
        "the 1.026\n",
        "best 8.713\n",
        "\n",
        "\n",
        "pred=1 (0.995774) truth=0 \n",
        "text=Efremova is great and Goldblum is very good. \n",
        "Top Terms:\n",
        "is 1.739\n",
        "very 3.139\n",
        "good 3.393\n",
        "and 3.417\n",
        "great 11.212\n",
        "\n",
        "\n",
        "pred=0 (0.995762) truth=1 \n",
        "text=Of course, no one because it was meant to sound ridiculous! \n",
        "Top Terms:\n",
        "ridiculous -9.343\n",
        "no -5.931\n",
        "was -1.696\n",
        "to -0.366\n",
        "course 0.341\n",
        "it 3.874\n",
        "\n",
        "\n",
        "pred=0 (0.995522) truth=1 \n",
        "text=It had a script, too! \n",
        "Top Terms:\n",
        "script -6.492\n",
        "too -2.844\n",
        "had -0.635\n",
        "it 3.874\n",
        "\n",
        "\n",
        "pred=1 (0.995487) truth=0 \n",
        "text=I enjoyed the beautiful scenery in this movie the first time I saw it when I was 9 . \n",
        "Top Terms:\n",
        "was -1.696\n",
        "this -0.783\n",
        "movie -0.251\n",
        "when 0.038\n",
        "in 0.356\n",
        "saw 0.787\n",
        "the 1.026\n",
        "time 1.216\n",
        "first 1.327\n",
        "it 3.874\n",
        "beautiful 4.827\n",
        "enjoyed 5.895\n",
        "\n",
        "\n",
        "pred=1 (0.995327) truth=0 \n",
        "text=And while I haven't seen all of their other movies, I've always enjoyed their performances until now. \n",
        "Top Terms:\n",
        "until 0.159\n",
        "movies 0.429\n",
        "while 0.609\n",
        "other 0.630\n",
        "now 1.449\n",
        "performances 2.374\n",
        "always 3.198\n",
        "and 3.417\n",
        "seen 3.747\n",
        "enjoyed 5.895\n",
        "\n",
        "\n",
        "pred=1 (0.995195) truth=0 \n",
        "text=I caught this movie a few years ago one night, and it was one of the funniest movies I have ever seen. \n",
        "Top Terms:\n",
        "was -1.696\n",
        "have -1.112\n",
        "this -0.783\n",
        "movie -0.251\n",
        "movies 0.429\n",
        "ever 0.810\n",
        "the 1.026\n",
        "years 1.790\n",
        "caught 2.347\n",
        "and 3.417\n",
        "seen 3.747\n",
        "it 3.874\n",
        "funniest 6.032\n",
        "\n",
        "\n",
        "pred=0 (0.995092) truth=1 \n",
        "text=I had no problem with any of them in the end. \n",
        "Top Terms:\n",
        "no -5.931\n",
        "problem -4.215\n",
        "any -3.091\n",
        "had -0.635\n",
        "with 0.048\n",
        "in 0.356\n",
        "the 1.026\n",
        "\n",
        "\n",
        "pred=0 (0.995027) truth=1 \n",
        "text=Oh, yes! \n",
        "Top Terms:\n",
        "oh -7.797\n",
        "yes 0.505\n",
        "\n",
        "\n",
        "pred=0 (0.995027) truth=1 \n",
        "text=Oh, yes! \n",
        "Top Terms:\n",
        "oh -7.797\n",
        "yes 0.505\n",
        "\n",
        "\n",
        "pred=0 (0.994585) truth=1 \n",
        "text=<br /><br />The love interest almost totally lacks subtlety and yet strangely..... almost totally lacks charm also. \n",
        "Top Terms:\n",
        "lacks -11.119\n",
        "interest -2.054\n",
        "br -0.720\n",
        "yet 0.589\n",
        "the 1.026\n",
        "and 3.417\n",
        "also 3.955\n",
        "love 4.753\n",
        "\n",
        "\n",
        "pred=0 (0.994247) truth=1 \n",
        "text=Peter because he is rude, obnoxious, and just doesn't give a crap. \n",
        "Top Terms:\n",
        "obnoxious -5.245\n",
        "crap -4.603\n",
        "just -4.475\n",
        "doesn -3.109\n",
        "he 0.176\n",
        "is 1.739\n",
        "and 3.417\n",
        "\n",
        "\n",
        "pred=1 (0.994038) truth=0 \n",
        "text=and, i must say, this is the single best movie i have ever seen. \n",
        "Top Terms:\n",
        "have -1.112\n",
        "this -0.783\n",
        "movie -0.251\n",
        "single -0.139\n",
        "ever 0.810\n",
        "the 1.026\n",
        "must 1.593\n",
        "is 1.739\n",
        "and 3.417\n",
        "seen 3.747\n",
        "best 8.713\n",
        "\n",
        "\n",
        "pred=1 (0.993632) truth=0 \n",
        "text=How is it beautiful?? \n",
        "Top Terms:\n",
        "is 1.739\n",
        "it 3.874\n",
        "beautiful 4.827\n",
        "\n",
        "\n",
        "pred=1 (0.993577) truth=0 \n",
        "text=Incredible. \n",
        "Top Terms:\n",
        "incredible 5.143\n",
        "\n",
        "\n",
        "pred=0 (0.993182) truth=1 \n",
        "text=Just by looking at the trailer it looked stupid, to me anyway. \n",
        "Top Terms:\n",
        "stupid -6.148\n",
        "just -4.475\n",
        "looked -3.269\n",
        "looking -2.478\n",
        "by -0.656\n",
        "to -0.366\n",
        "the 1.026\n",
        "it 3.874\n",
        "\n",
        "\n",
        "pred=1 (0.993165) truth=0 \n",
        "text=The serial had a solid Edmund, in an actor who was best at likable saps, and the perfect, i.e. \n",
        "Top Terms:\n",
        "actor -2.136\n",
        "was -1.696\n",
        "had -0.635\n",
        "an -0.177\n",
        "likable 0.084\n",
        "in 0.356\n",
        "who 0.707\n",
        "the 1.026\n",
        "and 3.417\n",
        "solid 4.032\n",
        "best 8.713\n",
        "perfect 11.472\n",
        "\n",
        "\n",
        "pred=0 (0.992467) truth=1 \n",
        "text=Everything is just out of the blue, and nothing seems to make sense. \n",
        "Top Terms:\n",
        "nothing -8.432\n",
        "just -4.475\n",
        "seems -4.165\n",
        "make -2.389\n",
        "to -0.366\n",
        "everything 0.311\n",
        "the 1.026\n",
        "is 1.739\n",
        "and 3.417\n",
        "\n",
        "\n",
        "pred=0 (0.992048) truth=1 \n",
        "text=Basically, Richard and Justin kill a young woman, because they have nothing better to do on a school night. \n",
        "Top Terms:\n",
        "nothing -8.432\n",
        "basically -6.392\n",
        "better -2.650\n",
        "do -1.122\n",
        "have -1.112\n",
        "they -1.039\n",
        "woman -0.918\n",
        "on -0.533\n",
        "to -0.366\n",
        "young 0.331\n",
        "and 3.417\n",
        "\n",
        "\n",
        "pred=0 (0.991265) truth=1 \n",
        "text=Three spies did the worst damage to our national security in the '70s and '80s. \n",
        "Top Terms:\n",
        "worst -23.029\n",
        "did -1.220\n",
        "three -1.205\n",
        "to -0.366\n",
        "in 0.356\n",
        "our 0.821\n",
        "the 1.026\n",
        "and 3.417\n",
        "\n",
        "\n",
        "pred=0 (0.990049) truth=1 \n",
        "text=BUt I don't have that problem with this movie. \n",
        "Top Terms:\n",
        "problem -4.215\n",
        "don -2.241\n",
        "have -1.112\n",
        "this -0.783\n",
        "but -0.448\n",
        "movie -0.251\n",
        "with 0.048\n",
        "\n",
        "\n",
        "pred=0 (0.989971) truth=1 \n",
        "text=I was not disappointed. \n",
        "Top Terms:\n",
        "not -3.455\n",
        "disappointed -3.222\n",
        "was -1.696\n",
        "\n",
        "\n",
        "pred=0 (0.989682) truth=1 \n",
        "text=Not that Grey's novel is a bad one; I just like the movie story better. \n",
        "Top Terms:\n",
        "bad -11.142\n",
        "just -4.475\n",
        "not -3.455\n",
        "better -2.650\n",
        "movie -0.251\n",
        "story 0.515\n",
        "the 1.026\n",
        "is 1.739\n",
        "\n",
        "\n",
        "pred=0 (0.98959) truth=1 \n",
        "text=I enjoyed this film, at the beginning I thought it would be the worst movie I've seen, but then as it went on it got better, and I couldn't turn away. \n",
        "Top Terms:\n",
        "worst -23.029\n",
        "couldn -4.714\n",
        "then -2.987\n",
        "would -2.940\n",
        "better -2.650\n",
        "be -0.801\n",
        "this -0.783\n",
        "on -0.533\n",
        "away -0.504\n",
        "but -0.448\n",
        "movie -0.251\n",
        "beginning 0.096\n",
        "got 0.450\n",
        "film 0.675\n",
        "the 1.026\n",
        "as 1.083\n",
        "thought 1.735\n",
        "and 3.417\n",
        "seen 3.747\n",
        "it 3.874\n",
        "enjoyed 5.895\n",
        "\n",
        "\n",
        "pred=0 (0.989291) truth=1 \n",
        "text=This statement may offend some of you who may think that this movie is nothing more than a waste of film. \n",
        "Top Terms:\n",
        "waste -18.504\n",
        "nothing -8.432\n",
        "this -0.783\n",
        "movie -0.251\n",
        "film 0.675\n",
        "who 0.707\n",
        "is 1.739\n",
        "more 1.783\n",
        "think 1.814\n",
        "you 3.110\n",
        "may 3.231\n",
        "\n",
        "\n",
        "pred=0 (0.989009) truth=1 \n",
        "text=Short of wearing a huge \"W\" (for 'whore') on her cardigan, she walks around like a pathetic mess for most of her screen time. \n",
        "Top Terms:\n",
        "mess -11.635\n",
        "pathetic -6.748\n",
        "on -0.533\n",
        "for -0.150\n",
        "her 0.205\n",
        "she 0.891\n",
        "time 1.216\n",
        "short 1.267\n",
        "most 2.944\n",
        "\n",
        "\n",
        "pred=0 (0.988766) truth=1 \n",
        "text=We also have some that are so 'good' they suck, and then, we have some that are so bad they are just bad. \n",
        "Top Terms:\n",
        "bad -11.142\n",
        "just -4.475\n",
        "then -2.987\n",
        "have -1.112\n",
        "they -1.039\n",
        "are -0.261\n",
        "good 3.393\n",
        "and 3.417\n",
        "also 3.955\n",
        "\n",
        "\n",
        "pred=0 (0.988674) truth=1 \n",
        "text=And I was trying to figure out why Hilary Swank was supposed to be South African and sounded like she was trying to put on an accent but sounded very American... as if she was making a weak attempt at putting on the accent. \n",
        "Top Terms:\n",
        "supposed -7.324\n",
        "weak -5.962\n",
        "attempt -5.243\n",
        "why -3.251\n",
        "trying -2.674\n",
        "if -2.407\n",
        "making -2.361\n",
        "was -1.696\n",
        "accent -1.139\n",
        "be -0.801\n",
        "on -0.533\n",
        "but -0.448\n",
        "to -0.366\n",
        "an -0.177\n",
        "she 0.891\n",
        "american 0.944\n",
        "the 1.026\n",
        "as 1.083\n",
        "very 3.139\n",
        "and 3.417\n",
        "\n",
        "\n",
        "pred=0 (0.9885) truth=1 \n",
        "text=What's worse, Matthau doesn't even know how to dance. \n",
        "Top Terms:\n",
        "worse -10.117\n",
        "even -4.536\n",
        "doesn -3.109\n",
        "to -0.366\n",
        "what 0.399\n",
        "know 0.604\n",
        "matthau 1.394\n",
        "\n",
        "\n",
        "pred=0 (0.986981) truth=1 \n",
        "text=The ending(..explaining the old clich\u00c3\u00a9:\"It's only a movie\")couldn't work any better than it does here. \n",
        "Top Terms:\n",
        "couldn -4.714\n",
        "clich\u00e3 -4.050\n",
        "only -3.154\n",
        "any -3.091\n",
        "better -2.650\n",
        "here -0.995\n",
        "does -0.578\n",
        "movie -0.251\n",
        "old -0.240\n",
        "the 1.026\n",
        "it 3.874\n",
        "\n",
        "\n",
        "pred=0 (0.986971) truth=1 \n",
        "text=Oh, well. \n",
        "Top Terms:\n",
        "oh -7.797\n",
        "well 5.405\n",
        "\n",
        "\n",
        "pred=0 (0.986782) truth=1 \n",
        "text=There isn't a wasted scene in this movie. \n",
        "Top Terms:\n",
        "wasted -5.068\n",
        "there -1.768\n",
        "this -0.783\n",
        "isn -0.382\n",
        "movie -0.251\n",
        "in 0.356\n",
        "\n",
        "\n",
        "pred=1 (0.986633) truth=0 \n",
        "text=Well considering that there are a lot of people that enjoyed this film... \n",
        "Top Terms:\n",
        "there -1.768\n",
        "this -0.783\n",
        "are -0.261\n",
        "people 0.381\n",
        "film 0.675\n",
        "lot 1.694\n",
        "well 5.405\n",
        "enjoyed 5.895\n",
        "\n",
        "\n",
        "pred=0 (0.986456) truth=1 \n",
        "text=Expecting the worst, \"Hitch\" proved to be a pleasant experience because of the three principals in it. \n",
        "Top Terms:\n",
        "worst -23.029\n",
        "three -1.205\n",
        "be -0.801\n",
        "to -0.366\n",
        "experience 0.206\n",
        "in 0.356\n",
        "the 1.026\n",
        "expecting 1.932\n",
        "it 3.874\n",
        "\n",
        "\n",
        "pred=0 (0.986216) truth=1 \n",
        "text=The plot was acceptable for a martial arts movie.<br /><br />Having said that, I must tell you Richard Sun is one of the worst actors from Hong Kong I have ever watched. \n",
        "Top Terms:\n",
        "worst -23.029\n",
        "plot -3.591\n",
        "was -1.696\n",
        "said -1.224\n",
        "actors -1.221\n",
        "have -1.112\n",
        "br -0.720\n",
        "movie -0.251\n",
        "for -0.150\n",
        "ever 0.810\n",
        "the 1.026\n",
        "hong 1.060\n",
        "must 1.593\n",
        "is 1.739\n",
        "you 3.110\n",
        "\n",
        "\n",
        "pred=0 (0.985724) truth=1 \n",
        "text=James LeGros has nothing to do. \n",
        "Top Terms:\n",
        "nothing -8.432\n",
        "do -1.122\n",
        "to -0.366\n",
        "has 1.253\n",
        "\n",
        "\n",
        "pred=0 (0.985619) truth=1 \n",
        "text=He tries everything that is possible in his hands to save the child's eye. \n",
        "Top Terms:\n",
        "save -8.437\n",
        "tries -4.957\n",
        "to -0.366\n",
        "eye 0.110\n",
        "he 0.176\n",
        "everything 0.311\n",
        "in 0.356\n",
        "the 1.026\n",
        "his 1.558\n",
        "is 1.739\n",
        "\n",
        "\n",
        "pred=0 (0.985117) truth=1 \n",
        "text=Instead they put in a girl! \n",
        "Top Terms:\n",
        "instead -6.948\n",
        "they -1.039\n",
        "in 0.356\n",
        "\n",
        "\n",
        "pred=0 (0.98502) truth=1 \n",
        "text=It gives all potential, and to think at first I said this looks stupid. \n",
        "Top Terms:\n",
        "stupid -6.148\n",
        "looks -5.686\n",
        "potential -2.101\n",
        "said -1.224\n",
        "this -0.783\n",
        "to -0.366\n",
        "gives 0.854\n",
        "first 1.327\n",
        "think 1.814\n",
        "and 3.417\n",
        "it 3.874\n",
        "\n",
        "\n",
        "pred=1 (0.984874) truth=0 \n",
        "text=Actually Lyne almost makes a very sexy movie , JenniferBeals is very sweet and innocent looking . \n",
        "Top Terms:\n",
        "looking -2.478\n",
        "movie -0.251\n",
        "is 1.739\n",
        "sweet 2.979\n",
        "very 3.139\n",
        "innocent 3.186\n",
        "makes 3.333\n",
        "and 3.417\n",
        "\n",
        "\n",
        "pred=0 (0.984559) truth=1 \n",
        "text=Art dealers and agents then besiege him and try to make money off \"Oh Won.\" \n",
        "Top Terms:\n",
        "oh -7.797\n",
        "money -4.532\n",
        "then -2.987\n",
        "off -2.959\n",
        "make -2.389\n",
        "try -0.475\n",
        "to -0.366\n",
        "him 1.886\n",
        "and 3.417\n",
        "\n",
        "\n",
        "pred=1 (0.984555) truth=0 \n",
        "text=What's amazing and wonderful here, is how Sinatra can take a rather insipid song and make it seem special -- his phrasing and eloquence as a singer make you want to hear it again. \n",
        "Top Terms:\n",
        "make -2.389\n",
        "here -0.995\n",
        "want -0.650\n",
        "to -0.366\n",
        "what 0.399\n",
        "again 0.401\n",
        "sinatra 0.501\n",
        "as 1.083\n",
        "his 1.558\n",
        "is 1.739\n",
        "you 3.110\n",
        "and 3.417\n",
        "it 3.874\n",
        "amazing 9.253\n",
        "wonderful 9.805\n",
        "\n",
        "\n",
        "pred=0 (0.983949) truth=1 \n",
        "text=If Martha Coolidge had been given more money and time on this movie then the results would of been even better. \n",
        "Top Terms:\n",
        "even -4.536\n",
        "money -4.532\n",
        "then -2.987\n",
        "would -2.940\n",
        "better -2.650\n",
        "if -2.407\n",
        "been -2.155\n",
        "this -0.783\n",
        "had -0.635\n",
        "on -0.533\n",
        "movie -0.251\n",
        "the 1.026\n",
        "time 1.216\n",
        "more 1.783\n",
        "and 3.417\n",
        "\n",
        "\n",
        "pred=1 (0.983683) truth=0 \n",
        "text=She has her big moment with \"Love Is Where You Find It\" which suits her perfectly and shows off her abilities. \n",
        "Top Terms:\n",
        "off -2.959\n",
        "with 0.048\n",
        "her 0.205\n",
        "find 0.269\n",
        "she 0.891\n",
        "has 1.253\n",
        "is 1.739\n",
        "you 3.110\n",
        "and 3.417\n",
        "shows 3.523\n",
        "it 3.874\n",
        "love 4.753\n",
        "perfectly 5.710\n",
        "\n",
        "\n",
        "pred=0 (0.983424) truth=1 \n",
        "text=Because then you can see how silly these Christian people are. \n",
        "Top Terms:\n",
        "christian -4.394\n",
        "silly -3.958\n",
        "then -2.987\n",
        "are -0.261\n",
        "people 0.381\n",
        "see 2.441\n",
        "you 3.110\n",
        "\n",
        "\n",
        "pred=1 (0.98322) truth=0 \n",
        "text=Well hopefully one day this type of movies will not be released but then hey where will all the Low Budget actors go :-) <br /><br />The movie also contains many Bloops but that I will leave to you to find because it adds quite a bit of fun while watching and also if you a bit of a perfectionist it will bother you ;-) Cheers! \n",
        "Top Terms:\n",
        "not -3.455\n",
        "then -2.987\n",
        "if -2.407\n",
        "low -1.586\n",
        "actors -1.221\n",
        "be -0.801\n",
        "this -0.783\n",
        "watching -0.745\n",
        "br -0.720\n",
        "bother -0.572\n",
        "but -0.448\n",
        "to -0.366\n",
        "movie -0.251\n",
        "released 0.108\n",
        "find 0.269\n",
        "movies 0.429\n",
        "while 0.609\n",
        "many 0.744\n",
        "the 1.026\n",
        "quite 1.282\n",
        "day 1.612\n",
        "will 2.462\n",
        "you 3.110\n",
        "and 3.417\n",
        "it 3.874\n",
        "also 3.955\n",
        "bit 4.964\n",
        "well 5.405\n",
        "fun 5.440\n",
        "\n",
        "\n",
        "pred=1 (0.982829) truth=0 \n",
        "text=Enjoy :) \n",
        "Top Terms:\n",
        "enjoy 4.149\n",
        "\n",
        "\n",
        "pred=1 (0.982772) truth=0 \n",
        "text=The perfect example is Julia Koschitz: She changes her eating habits from one talk to the other, on one talk she does not drink alcohol on the next she is allergic to champagne, she feels too beautiful for most people (in fact she is) but still ends up with the \"perfect\" fit concerning the looks, and refuses to give some more \"realistic\" guys a chance, and so on... \n",
        "Top Terms:\n",
        "looks -5.686\n",
        "not -3.455\n",
        "too -2.844\n",
        "example -1.420\n",
        "does -0.578\n",
        "on -0.533\n",
        "but -0.448\n",
        "to -0.366\n",
        "for -0.150\n",
        "ends -0.069\n",
        "with 0.048\n",
        "her 0.205\n",
        "in 0.356\n",
        "people 0.381\n",
        "chance 0.422\n",
        "guys 0.524\n",
        "other 0.630\n",
        "she 0.891\n",
        "the 1.026\n",
        "is 1.739\n",
        "more 1.783\n",
        "most 2.944\n",
        "and 3.417\n",
        "realistic 3.491\n",
        "still 4.419\n",
        "beautiful 4.827\n",
        "perfect 11.472\n",
        "\n",
        "\n",
        "pred=0 (0.982446) truth=1 \n",
        "text=Basically, the show was never given any chance. \n",
        "Top Terms:\n",
        "basically -6.392\n",
        "any -3.091\n",
        "was -1.696\n",
        "show 0.345\n",
        "chance 0.422\n",
        "the 1.026\n",
        "\n",
        "\n",
        "pred=1 (0.982192) truth=0 \n",
        "text=It's fascinating and weird. \n",
        "Top Terms:\n",
        "and 3.417\n",
        "it 3.874\n",
        "fascinating 4.185\n",
        "\n",
        "\n",
        "pred=1 (0.982002) truth=0 \n",
        "text=The film is highly unoriginal. \n",
        "Top Terms:\n",
        "film 0.675\n",
        "the 1.026\n",
        "is 1.739\n",
        "highly 7.131\n",
        "\n",
        "\n",
        "pred=0 (0.981923) truth=1 \n",
        "text=Uh-Oh! \n",
        "Top Terms:\n",
        "oh -7.797\n",
        "\n",
        "\n",
        "pred=0 (0.981814) truth=1 \n",
        "text=Instead, like the original Jack Frost (which I thought was just as funny), this movie turned out to be a side-splitting journey into the depths of corny dialogue, bad one liners and horrible special effects. \n",
        "Top Terms:\n",
        "bad -11.142\n",
        "horrible -10.489\n",
        "instead -6.948\n",
        "just -4.475\n",
        "original -3.321\n",
        "was -1.696\n",
        "be -0.801\n",
        "this -0.783\n",
        "dialogue -0.551\n",
        "effects -0.469\n",
        "to -0.366\n",
        "movie -0.251\n",
        "the 1.026\n",
        "as 1.083\n",
        "thought 1.735\n",
        "jack 2.238\n",
        "journey 3.301\n",
        "and 3.417\n",
        "\n",
        "\n",
        "pred=0 (0.981745) truth=1 \n",
        "text=When in 1982, \"The Thing\" came out to theaters everywhere, it had a cold reception and very poor box-office results, becoming almost a failure in John Carpenter's career as a horror director; however, time has proved that \"The Thing\" was definitely not a failed project and that the disappointing commercial results were not the film's fault. \n",
        "Top Terms:\n",
        "poor -10.917\n",
        "disappointing -10.467\n",
        "failed -4.291\n",
        "not -3.455\n",
        "director -3.353\n",
        "failure -1.822\n",
        "was -1.696\n",
        "thing -1.662\n",
        "were -1.537\n",
        "box -0.857\n",
        "had -0.635\n",
        "horror -0.370\n",
        "to -0.366\n",
        "however -0.235\n",
        "when 0.038\n",
        "in 0.356\n",
        "came 0.609\n",
        "film 0.675\n",
        "the 1.026\n",
        "as 1.083\n",
        "time 1.216\n",
        "has 1.253\n",
        "very 3.139\n",
        "and 3.417\n",
        "it 3.874\n",
        "definitely 5.848\n",
        "\n",
        "\n",
        "pred=0 (0.981599) truth=1 \n",
        "text=(or, at least, they don't seem to care). \n",
        "Top Terms:\n",
        "least -4.097\n",
        "don -2.241\n",
        "care -1.685\n",
        "they -1.039\n",
        "or -0.724\n",
        "to -0.366\n",
        "\n",
        "\n",
        "pred=1 (0.980986) truth=0 \n",
        "text=And that's it. \n",
        "Top Terms:\n",
        "and 3.417\n",
        "it 3.874\n",
        "\n",
        "\n",
        "pred=0 (0.98063) truth=1 \n",
        "text=And don't count the awful Mr. Magoo reworked for live action. \n",
        "Top Terms:\n",
        "awful -17.007\n",
        "don -2.241\n",
        "for -0.150\n",
        "the 1.026\n",
        "action 1.496\n",
        "and 3.417\n",
        "\n",
        "\n",
        "pred=0 (0.980453) truth=1 \n",
        "text=Don't expect to be bored by this film. \n",
        "Top Terms:\n",
        "bored -4.281\n",
        "don -2.241\n",
        "be -0.801\n",
        "this -0.783\n",
        "by -0.656\n",
        "to -0.366\n",
        "film 0.675\n",
        "\n",
        "\n",
        "pred=1 (0.980314) truth=0 \n",
        "text=He played very well and convincing for his age... \n",
        "Top Terms:\n",
        "for -0.150\n",
        "he 0.176\n",
        "age 0.810\n",
        "his 1.558\n",
        "played 1.709\n",
        "very 3.139\n",
        "and 3.417\n",
        "well 5.405\n",
        "\n",
        "\n",
        "pred=1 (0.980206) truth=0 \n",
        "text=I'll start with the good points..., It's got stylish direction for a DTV movie and has wonderful scenry... That's it! \n",
        "Top Terms:\n",
        "movie -0.251\n",
        "start -0.235\n",
        "for -0.150\n",
        "ll -0.094\n",
        "with 0.048\n",
        "got 0.450\n",
        "the 1.026\n",
        "has 1.253\n",
        "good 3.393\n",
        "and 3.417\n",
        "it 3.874\n",
        "wonderful 9.805\n",
        "\n",
        "\n",
        "pred=1 (0.980004) truth=0 \n",
        "text=).<br /><br />When I watched it I was pleasantly surprised. \n",
        "Top Terms:\n",
        "was -1.696\n",
        "br -0.720\n",
        "when 0.038\n",
        "pleasantly 2.705\n",
        "it 3.874\n",
        "surprised 4.657\n",
        "\n",
        "\n",
        "pred=1 (0.979747) truth=0 \n",
        "text=All over the place and almost good fun. \n",
        "Top Terms:\n",
        "over -0.668\n",
        "the 1.026\n",
        "good 3.393\n",
        "and 3.417\n",
        "fun 5.440\n",
        "\n",
        "\n",
        "pred=1 (0.979612) truth=0 \n",
        "text=It is cloyed. \n",
        "Top Terms:\n",
        "is 1.739\n",
        "it 3.874\n",
        "\n",
        "\n",
        "pred=0 (0.979266) truth=1 \n",
        "text=<br /><br />He, Oh Won, becomes a Jesus figure. \n",
        "Top Terms:\n",
        "oh -7.797\n",
        "jesus -1.247\n",
        "br -0.720\n",
        "he 0.176\n",
        "\n",
        "\n",
        "pred=0 (0.979191) truth=1 \n",
        "text=Though this movie lacks character development, this story is still understandable. \n",
        "Top Terms:\n",
        "lacks -11.119\n",
        "this -0.783\n",
        "development -0.561\n",
        "movie -0.251\n",
        "story 0.515\n",
        "is 1.739\n",
        "though 1.935\n",
        "still 4.419\n",
        "\n",
        "\n",
        "pred=1 (0.979151) truth=0 \n",
        "text=I agree, she's a great actress. \n",
        "Top Terms:\n",
        "actress -0.055\n",
        "she 0.891\n",
        "great 11.212\n",
        "\n",
        "\n",
        "pred=1 (0.979139) truth=0 \n",
        "text=The best thing about the movie? \n",
        "Top Terms:\n",
        "thing -1.662\n",
        "movie -0.251\n",
        "the 1.026\n",
        "best 8.713\n",
        "\n",
        "\n",
        "pred=0 (0.978226) truth=1 \n",
        "text=Don't pay too much attention to one thing or you would be sorry. \n",
        "Top Terms:\n",
        "sorry -3.355\n",
        "would -2.940\n",
        "too -2.844\n",
        "don -2.241\n",
        "much -1.721\n",
        "thing -1.662\n",
        "be -0.801\n",
        "or -0.724\n",
        "to -0.366\n",
        "attention 0.590\n",
        "you 3.110\n",
        "\n",
        "\n",
        "pred=1 (0.97782) truth=0 \n",
        "text=Even though Atwill often played in these cheap movies, his excellent style of acting always made the films seem a lot better, as his screen persona was great (his real life is also quite interesting\u00c2\u0097sort of like a bizarre soap opera). \n",
        "Top Terms:\n",
        "even -4.536\n",
        "cheap -4.398\n",
        "better -2.650\n",
        "bizarre -2.264\n",
        "acting -1.949\n",
        "was -1.696\n",
        "opera -0.966\n",
        "sort -0.964\n",
        "soap -0.402\n",
        "in 0.356\n",
        "movies 0.429\n",
        "real 0.508\n",
        "the 1.026\n",
        "as 1.083\n",
        "quite 1.282\n",
        "his 1.558\n",
        "lot 1.694\n",
        "played 1.709\n",
        "is 1.739\n",
        "though 1.935\n",
        "often 2.074\n",
        "always 3.198\n",
        "life 3.448\n",
        "also 3.955\n",
        "great 11.212\n",
        "excellent 13.631\n",
        "\n",
        "\n",
        "pred=1 (0.97752) truth=0 \n",
        "text=It's o.k. \n",
        "Top Terms:\n",
        "it 3.874\n",
        "\n",
        "\n",
        "pred=0 (0.976991) truth=1 \n",
        "text=And not as so many ignorant people would have you believe, a pointless lesbian romp. \n",
        "Top Terms:\n",
        "pointless -10.093\n",
        "not -3.455\n",
        "would -2.940\n",
        "have -1.112\n",
        "people 0.381\n",
        "many 0.744\n",
        "as 1.083\n",
        "you 3.110\n",
        "and 3.417\n",
        "\n",
        "\n",
        "pred=0 (0.976575) truth=1 \n",
        "text=There's basically not one bad song and the dances go full force (and at one point stop traffic--literally!). \n",
        "Top Terms:\n",
        "bad -11.142\n",
        "basically -6.392\n",
        "not -3.455\n",
        "there -1.768\n",
        "point -0.914\n",
        "the 1.026\n",
        "and 3.417\n",
        "\n",
        "\n",
        "pred=1 (0.97647) truth=0 \n",
        "text=But buy the soundtrack CD; the music is great. \n",
        "Top Terms:\n",
        "but -0.448\n",
        "buy 0.728\n",
        "the 1.026\n",
        "soundtrack 1.550\n",
        "is 1.739\n",
        "great 11.212\n",
        "\n",
        "\n",
        "pred=1 (0.976463) truth=0 \n",
        "text=Plain and simple. \n",
        "Top Terms:\n",
        "and 3.417\n",
        "simple 5.003\n",
        "\n",
        "\n",
        "pred=1 (0.976463) truth=0 \n",
        "text=Plain and simple. \n",
        "Top Terms:\n",
        "and 3.417\n",
        "simple 5.003\n",
        "\n",
        "\n",
        "pred=0 (0.976429) truth=1 \n",
        "text=I just wonder what he's doing now. \n",
        "Top Terms:\n",
        "wonder -5.436\n",
        "just -4.475\n",
        "he 0.176\n",
        "what 0.399\n",
        "now 1.449\n",
        "\n",
        "\n",
        "pred=0 (0.976283) truth=1 \n",
        "text=All of which has nothing to do with why all three are actually IN those jobs. \n",
        "Top Terms:\n",
        "nothing -8.432\n",
        "why -3.251\n",
        "three -1.205\n",
        "do -1.122\n",
        "to -0.366\n",
        "are -0.261\n",
        "with 0.048\n",
        "those 0.167\n",
        "in 0.356\n",
        "has 1.253\n",
        "\n",
        "\n",
        "pred=1 (0.975761) truth=0 \n",
        "text=You can either say to yourself a) \"Let's make a movie that kids today will love!\" \n",
        "Top Terms:\n",
        "make -2.389\n",
        "either -1.458\n",
        "let -1.335\n",
        "to -0.366\n",
        "movie -0.251\n",
        "kids -0.022\n",
        "will 2.462\n",
        "you 3.110\n",
        "love 4.753\n",
        "today 8.088\n",
        "\n",
        "\n",
        "pred=1 (0.975662) truth=0 \n",
        "text=Excellent!<br /><br />However, I was in for a rude awakening. \n",
        "Top Terms:\n",
        "was -1.696\n",
        "br -0.720\n",
        "however -0.235\n",
        "for -0.150\n",
        "in 0.356\n",
        "excellent 13.631\n",
        "\n",
        "\n",
        "pred=1 (0.975662) truth=0 \n",
        "text=Well, it's not! \n",
        "Top Terms:\n",
        "not -3.455\n",
        "it 3.874\n",
        "well 5.405\n",
        "\n",
        "\n",
        "pred=0 (0.975497) truth=1 \n",
        "text=Much better than the original.<br /><br />In \"Caddyshack\", Rodney Dangerfield is funny, but obnoxious. \n",
        "Top Terms:\n",
        "obnoxious -5.245\n",
        "original -3.321\n",
        "better -2.650\n",
        "much -1.721\n",
        "br -0.720\n",
        "but -0.448\n",
        "in 0.356\n",
        "the 1.026\n",
        "is 1.739\n",
        "\n",
        "\n",
        "pred=1 (0.975021) truth=0 \n",
        "text=It beats me how anyone can rate this film very highly. \n",
        "Top Terms:\n",
        "this -0.783\n",
        "film 0.675\n",
        "very 3.139\n",
        "it 3.874\n",
        "highly 7.131\n",
        "\n",
        "\n",
        "pred=0 (0.974373) truth=1 \n",
        "text=or was shooting her only problem?! \n",
        "Top Terms:\n",
        "problem -4.215\n",
        "only -3.154\n",
        "was -1.696\n",
        "or -0.724\n",
        "her 0.205\n",
        "\n",
        "\n",
        "pred=1 (0.974347) truth=0 \n",
        "text=overall i'd say this is the single greatest film of the genre, nay, in the world! \n",
        "Top Terms:\n",
        "this -0.783\n",
        "single -0.139\n",
        "in 0.356\n",
        "film 0.675\n",
        "the 1.026\n",
        "overall 1.696\n",
        "is 1.739\n",
        "genre 2.296\n",
        "greatest 3.210\n",
        "world 4.363\n",
        "\n",
        "\n",
        "pred=1 (0.974262) truth=0 \n",
        "text=I heard good things about its beauty, and how touching it was and decided why not? \n",
        "Top Terms:\n",
        "not -3.455\n",
        "why -3.251\n",
        "was -1.696\n",
        "its 0.594\n",
        "things 1.189\n",
        "beauty 2.174\n",
        "good 3.393\n",
        "and 3.417\n",
        "it 3.874\n",
        "touching 5.247\n",
        "\n",
        "\n",
        "pred=0 (0.973931) truth=1 \n",
        "text=murray plays his great, annoying, chatty character with obvious improv skill and is loveable- yet annoying. \n",
        "Top Terms:\n",
        "annoying -9.692\n",
        "obvious -3.723\n",
        "murray -1.819\n",
        "with 0.048\n",
        "plays 0.302\n",
        "yet 0.589\n",
        "his 1.558\n",
        "is 1.739\n",
        "and 3.417\n",
        "great 11.212\n",
        "\n",
        "\n",
        "pred=0 (0.973813) truth=1 \n",
        "text=This movie could be a bit boring for some people, but I find this film<br /><br />very interesting in terms of an attempt to reveal a tradition.<br /><br />The director, Lim, has made two films about traditional music in Korea before this film. \n",
        "Top Terms:\n",
        "boring -12.988\n",
        "attempt -5.243\n",
        "director -3.353\n",
        "interesting -2.837\n",
        "could -1.451\n",
        "be -0.801\n",
        "this -0.783\n",
        "br -0.720\n",
        "but -0.448\n",
        "to -0.366\n",
        "movie -0.251\n",
        "an -0.177\n",
        "for -0.150\n",
        "find 0.269\n",
        "in 0.356\n",
        "people 0.381\n",
        "traditional 0.575\n",
        "film 0.675\n",
        "the 1.026\n",
        "has 1.253\n",
        "very 3.139\n",
        "bit 4.964\n",
        "\n",
        "\n",
        "pred=0 (0.97372) truth=1 \n",
        "text=But when they're suppose to be \"creepy\", it mostly gets pathetic. \n",
        "Top Terms:\n",
        "pathetic -6.748\n",
        "re -1.896\n",
        "they -1.039\n",
        "be -0.801\n",
        "but -0.448\n",
        "to -0.366\n",
        "gets -0.103\n",
        "suppose -0.002\n",
        "when 0.038\n",
        "it 3.874\n",
        "\n",
        "\n",
        "pred=1 (0.973394) truth=0 \n",
        "text=Its rapid-fire jokes, incredible star power and tight script made it one of the most fun caper films I have ever seen. \n",
        "Top Terms:\n",
        "script -6.492\n",
        "have -1.112\n",
        "its 0.594\n",
        "ever 0.810\n",
        "the 1.026\n",
        "tight 2.664\n",
        "most 2.944\n",
        "and 3.417\n",
        "seen 3.747\n",
        "it 3.874\n",
        "incredible 5.143\n",
        "fun 5.440\n",
        "\n",
        "\n",
        "pred=1 (0.972844) truth=0 \n",
        "text=Touching hey? \n",
        "Top Terms:\n",
        "touching 5.247\n",
        "\n",
        "\n",
        "pred=0 (0.972778) truth=1 \n",
        "text=(... And I'm not talking of the \"bad dream\" sequence.) \n",
        "Top Terms:\n",
        "bad -11.142\n",
        "not -3.455\n",
        "talking -1.007\n",
        "dream 0.457\n",
        "the 1.026\n",
        "and 3.417\n",
        "\n",
        "\n",
        "pred=0 (0.972763) truth=1 \n",
        "text=One line by itself, is not so bad but this movie borrows so much from so many movies it becomes a bad risk.<br /><br />BUT...<br /><br />See The Movie! \n",
        "Top Terms:\n",
        "bad -11.142\n",
        "not -3.455\n",
        "much -1.721\n",
        "this -0.783\n",
        "br -0.720\n",
        "by -0.656\n",
        "line -0.503\n",
        "but -0.448\n",
        "movie -0.251\n",
        "movies 0.429\n",
        "many 0.744\n",
        "the 1.026\n",
        "is 1.739\n",
        "see 2.441\n",
        "it 3.874\n",
        "\n",
        "\n",
        "pred=1 (0.972647) truth=0 \n",
        "text=I think she is Irish in gene pool, (my favorite female DNA) so it makes some sense that she would resemble the most beautiful Irish American. \n",
        "Top Terms:\n",
        "would -2.940\n",
        "female -0.868\n",
        "in 0.356\n",
        "she 0.891\n",
        "american 0.944\n",
        "the 1.026\n",
        "is 1.739\n",
        "think 1.814\n",
        "my 1.827\n",
        "most 2.944\n",
        "makes 3.333\n",
        "it 3.874\n",
        "beautiful 4.827\n",
        "favorite 7.755\n",
        "\n",
        "\n",
        "pred=1 (0.972464) truth=0 \n",
        "text=The soundtrack is quite well done, featuring a nice 'Ventures' style bass/drum riff that keeps things moving and saxophones and brass charts that pep things up quite a bit. \n",
        "Top Terms:\n",
        "the 1.026\n",
        "things 1.189\n",
        "quite 1.282\n",
        "soundtrack 1.550\n",
        "is 1.739\n",
        "nice 2.972\n",
        "and 3.417\n",
        "moving 4.211\n",
        "bit 4.964\n",
        "well 5.405\n",
        "\n",
        "\n",
        "pred=0 (0.971948) truth=1 \n",
        "text=The scene in which Aschenbach decides to leave Venice is immediately followed by a clip of Alfred telling him that he is weak, alienated and lacks feelings. \n",
        "Top Terms:\n",
        "lacks -11.119\n",
        "weak -5.962\n",
        "by -0.656\n",
        "to -0.366\n",
        "he 0.176\n",
        "in 0.356\n",
        "the 1.026\n",
        "is 1.739\n",
        "him 1.886\n",
        "and 3.417\n",
        "\n",
        "\n",
        "pred=1 (0.971204) truth=0 \n",
        "text=Well, that's perfectly explainable. \n",
        "Top Terms:\n",
        "well 5.405\n",
        "perfectly 5.710\n",
        "\n",
        "\n",
        "pred=1 (0.971204) truth=0 \n",
        "text=Well, that's perfectly explainable. \n",
        "Top Terms:\n",
        "well 5.405\n",
        "perfectly 5.710\n",
        "\n",
        "\n",
        "pred=0 (0.971169) truth=1 \n",
        "text=Unfortunately, he might be starring in a lot of those direct-to-video flicks. \n",
        "Top Terms:\n",
        "unfortunately -9.639\n",
        "might -2.213\n",
        "be -0.801\n",
        "to -0.366\n",
        "video -0.180\n",
        "those 0.167\n",
        "he 0.176\n",
        "in 0.356\n",
        "lot 1.694\n",
        "\n",
        "\n",
        "pred=0 (0.971043) truth=1 \n",
        "text=Soon after he gets glasses because of poor vision. \n",
        "Top Terms:\n",
        "poor -10.917\n",
        "gets -0.103\n",
        "he 0.176\n",
        "soon 0.321\n",
        "\n",
        "\n",
        "pred=0 (0.970806) truth=1 \n",
        "text=So many early British sound films that I've seen on video suffer from either poor print transfer quality or poor sound or both. \n",
        "Top Terms:\n",
        "poor -10.917\n",
        "either -1.458\n",
        "or -0.724\n",
        "on -0.533\n",
        "video -0.180\n",
        "many 0.744\n",
        "seen 3.747\n",
        "both 4.128\n",
        "\n",
        "\n",
        "pred=1 (0.970679) truth=0 \n",
        "text=And why cast a great lead character who can actually act, and then cut away from him whenever he is building up to a great performance? \n",
        "Top Terms:\n",
        "why -3.251\n",
        "then -2.987\n",
        "away -0.504\n",
        "act -0.456\n",
        "to -0.366\n",
        "he 0.176\n",
        "who 0.707\n",
        "is 1.739\n",
        "performance 1.831\n",
        "him 1.886\n",
        "and 3.417\n",
        "great 11.212\n",
        "\n",
        "\n",
        "pred=1 (0.970627) truth=0 \n",
        "text=I'll give this one star because Aaliyah actually tried her best in this movie and the soundtrack is pretty good. \n",
        "Top Terms:\n",
        "this -0.783\n",
        "movie -0.251\n",
        "pretty -0.100\n",
        "ll -0.094\n",
        "her 0.205\n",
        "in 0.356\n",
        "the 1.026\n",
        "soundtrack 1.550\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "is 1.739\n",
        "good 3.393\n",
        "and 3.417\n",
        "best 8.713\n",
        "\n",
        "\n",
        "pred=0 (0.970305) truth=1 \n",
        "text=\"Head\", instead, was said to be a cynical, dark movie. \n",
        "Top Terms:\n",
        "instead -6.948\n",
        "was -1.696\n",
        "said -1.224\n",
        "be -0.801\n",
        "to -0.366\n",
        "head -0.284\n",
        "movie -0.251\n",
        "dark 0.091\n",
        "\n",
        "\n",
        "pred=1 (0.970012) truth=0 \n",
        "text=Actually strike that, Cyborg 2 is an often lovely looking movie, it's shot with excellent style and the visual detail make this easy on the eye. \n",
        "Top Terms:\n",
        "looking -2.478\n",
        "make -2.389\n",
        "this -0.783\n",
        "on -0.533\n",
        "movie -0.251\n",
        "an -0.177\n",
        "with 0.048\n",
        "eye 0.110\n",
        "the 1.026\n",
        "is 1.739\n",
        "often 2.074\n",
        "easy 2.355\n",
        "and 3.417\n",
        "it 3.874\n",
        "excellent 13.631\n",
        "\n",
        "\n",
        "pred=1 (0.969815) truth=0 \n",
        "text=Nevertheless, Michalkovs unique talent in delivering amazingly beautiful pictures is still there. \n",
        "Top Terms:\n",
        "there -1.768\n",
        "in 0.356\n",
        "pictures 0.509\n",
        "is 1.739\n",
        "unique 4.208\n",
        "still 4.419\n",
        "beautiful 4.827\n",
        "\n",
        "\n",
        "pred=0 (0.969358) truth=1 \n",
        "text=Director S.F. \n",
        "Top Terms:\n",
        "director -3.353\n",
        "\n",
        "\n",
        "pred=0 (0.969086) truth=1 \n",
        "text=It can seem dull and minimalistic (pretty much like every film to come out of Japan bar Mangas) if you don't know what to look for. \n",
        "Top Terms:\n",
        "dull -11.305\n",
        "if -2.407\n",
        "don -2.241\n",
        "much -1.721\n",
        "every -0.634\n",
        "look -0.585\n",
        "to -0.366\n",
        "for -0.150\n",
        "pretty -0.100\n",
        "what 0.399\n",
        "know 0.604\n",
        "film 0.675\n",
        "you 3.110\n",
        "and 3.417\n",
        "it 3.874\n",
        "\n",
        "\n",
        "pred=0 (0.967987) truth=1 \n",
        "text=I'm assuming there were cuts in the script--I can't believe the movie just left all this open. \n",
        "Top Terms:\n",
        "script -6.492\n",
        "just -4.475\n",
        "left -1.983\n",
        "there -1.768\n",
        "were -1.537\n",
        "this -0.783\n",
        "movie -0.251\n",
        "in 0.356\n",
        "the 1.026\n",
        "\n",
        "\n",
        "pred=1 (0.967193) truth=0 \n",
        "text=The photography is amazing, though, with the sublime use of shadows and darkness. \n",
        "Top Terms:\n",
        "use -0.441\n",
        "with 0.048\n",
        "the 1.026\n",
        "is 1.739\n",
        "though 1.935\n",
        "and 3.417\n",
        "amazing 9.253\n",
        "\n",
        "\n",
        "pred=0 (0.967094) truth=1 \n",
        "text=80s script? \n",
        "Top Terms:\n",
        "script -6.492\n",
        "\n",
        "\n",
        "pred=0 (0.966943) truth=1 \n",
        "text=Low-budget but memorable would-be shocker that instead emerges as theater of the bizarre. \n",
        "Top Terms:\n",
        "instead -6.948\n",
        "would -2.940\n",
        "bizarre -2.264\n",
        "low -1.586\n",
        "be -0.801\n",
        "but -0.448\n",
        "theater -0.358\n",
        "the 1.026\n",
        "as 1.083\n",
        "\n",
        "\n",
        "pred=0 (0.966464) truth=1 \n",
        "text=second of all, players cant paint their faces with colours and play like that, again FIFA rules not mine.<br /><br />and don't get me started on the way they scored goals its was ridiculous completely unrealistic. \n",
        "Top Terms:\n",
        "ridiculous -9.343\n",
        "not -3.455\n",
        "unrealistic -2.411\n",
        "don -2.241\n",
        "paint -1.734\n",
        "was -1.696\n",
        "completely -1.294\n",
        "they -1.039\n",
        "br -0.720\n",
        "on -0.533\n",
        "with 0.048\n",
        "way 0.070\n",
        "get 0.356\n",
        "again 0.401\n",
        "its 0.594\n",
        "the 1.026\n",
        "and 3.417\n",
        "\n",
        "\n",
        "pred=0 (0.966385) truth=1 \n",
        "text=<br /><br />The rest was done by Fragata, from the script to the dialogue, from camera work to editing. \n",
        "Top Terms:\n",
        "script -6.492\n",
        "was -1.696\n",
        "rest -1.067\n",
        "camera -0.835\n",
        "editing -0.825\n",
        "br -0.720\n",
        "by -0.656\n",
        "dialogue -0.551\n",
        "to -0.366\n",
        "the 1.026\n",
        "\n",
        "\n",
        "pred=0 (0.966202) truth=1 \n",
        "text=I am not a footie fan by any means but watched this with a friend as there wasn't anything else on the box at the time. \n",
        "Top Terms:\n",
        "not -3.455\n",
        "any -3.091\n",
        "anything -2.562\n",
        "am -2.135\n",
        "there -1.768\n",
        "wasn -1.570\n",
        "else -1.010\n",
        "box -0.857\n",
        "this -0.783\n",
        "by -0.656\n",
        "on -0.533\n",
        "but -0.448\n",
        "with 0.048\n",
        "the 1.026\n",
        "as 1.083\n",
        "time 1.216\n",
        "\n",
        "\n",
        "pred=0 (0.966183) truth=1 \n",
        "text=Why? \n",
        "Top Terms:\n",
        "why -3.251\n",
        "\n",
        "\n",
        "pred=0 (0.966183) truth=1 \n",
        "text=Why? \n",
        "Top Terms:\n",
        "why -3.251\n",
        "\n",
        "\n",
        "pred=0 (0.966183) truth=1 \n",
        "text=Why? \n",
        "Top Terms:\n",
        "why -3.251\n",
        "\n",
        "\n",
        "pred=0 (0.966183) truth=1 \n",
        "text=Why? \n",
        "Top Terms:\n",
        "why -3.251\n",
        "\n",
        "\n",
        "pred=0 (0.96579) truth=1 \n",
        "text=Too bad, because that scene just lays there now, another victim of music licensing Hell. \n",
        "Top Terms:\n",
        "bad -11.142\n",
        "just -4.475\n",
        "too -2.844\n",
        "there -1.768\n",
        "now 1.449\n",
        "\n",
        "\n",
        "pred=0 (0.965597) truth=1 \n",
        "text=Avoid the TV version which abysmally overdubs it. \n",
        "Top Terms:\n",
        "avoid -9.134\n",
        "tv -0.145\n",
        "the 1.026\n",
        "it 3.874\n",
        "\n",
        "\n",
        "pred=0 (0.965559) truth=1 \n",
        "text=GRADE: B \n",
        "Top Terms:\n",
        "grade -3.232\n",
        "\n",
        "\n",
        "pred=0 (0.965411) truth=1 \n",
        "text=Okay, I'm not sure if this counts as a spoiler so i just ticked the box anyway to save the hassle.<br /><br />I've noticed that the opinions on this film seem to be a fair split. \n",
        "Top Terms:\n",
        "save -8.437\n",
        "just -4.475\n",
        "not -3.455\n",
        "okay -3.039\n",
        "if -2.407\n",
        "box -0.857\n",
        "be -0.801\n",
        "this -0.783\n",
        "br -0.720\n",
        "on -0.533\n",
        "to -0.366\n",
        "film 0.675\n",
        "the 1.026\n",
        "as 1.083\n",
        "\n",
        "\n",
        "pred=0 (0.965097) truth=1 \n",
        "text=It shows how a old grandfather tries to save his grandsons eye. \n",
        "Top Terms:\n",
        "save -8.437\n",
        "tries -4.957\n",
        "to -0.366\n",
        "old -0.240\n",
        "eye 0.110\n",
        "his 1.558\n",
        "shows 3.523\n",
        "it 3.874\n",
        "\n",
        "\n",
        "pred=1 (0.964966) truth=0 \n",
        "text=And eviscerations. \n",
        "Top Terms:\n",
        "and 3.417\n",
        "\n",
        "\n",
        "pred=1 (0.964966) truth=0 \n",
        "text=And Louisa! \n",
        "Top Terms:\n",
        "and 3.417\n",
        "\n",
        "\n",
        "pred=1 (0.964142) truth=0 \n",
        "text=I think because my great uncle, Buddy Baer, was the giant in this movie and my father-in-law thought I'd like to see it. \n",
        "Top Terms:\n",
        "was -1.696\n",
        "giant -1.491\n",
        "this -0.783\n",
        "to -0.366\n",
        "movie -0.251\n",
        "father 0.352\n",
        "in 0.356\n",
        "the 1.026\n",
        "thought 1.735\n",
        "think 1.814\n",
        "my 1.827\n",
        "see 2.441\n",
        "and 3.417\n",
        "it 3.874\n",
        "great 11.212\n",
        "\n",
        "\n",
        "pred=1 (0.963852) truth=0 \n",
        "text=To be perfectly honest the episodes of the series that I've seen work better a single episodes where we're not expecting as much. \n",
        "Top Terms:\n",
        "not -3.455\n",
        "better -2.650\n",
        "re -1.896\n",
        "much -1.721\n",
        "be -0.801\n",
        "to -0.366\n",
        "single -0.139\n",
        "honest 0.206\n",
        "the 1.026\n",
        "as 1.083\n",
        "expecting 1.932\n",
        "episodes 2.070\n",
        "series 2.527\n",
        "seen 3.747\n",
        "perfectly 5.710\n",
        "\n",
        "\n",
        "pred=1 (0.963711) truth=0 \n",
        "text=then you might actually find it enjoyable and totally cool. \n",
        "Top Terms:\n",
        "then -2.987\n",
        "might -2.213\n",
        "find 0.269\n",
        "cool 0.999\n",
        "you 3.110\n",
        "and 3.417\n",
        "it 3.874\n",
        "enjoyable 6.699\n",
        "\n",
        "\n",
        "pred=0 (0.963685) truth=1 \n",
        "text=Some of the parts are pointless and random, but that's what makes them so amusing. \n",
        "Top Terms:\n",
        "pointless -10.093\n",
        "but -0.448\n",
        "are -0.261\n",
        "what 0.399\n",
        "the 1.026\n",
        "makes 3.333\n",
        "and 3.417\n",
        "\n",
        "\n",
        "pred=0 (0.962616) truth=1 \n",
        "text=But, there's something more than just sorrow...<br /><br />Such a life as Titta's would obviously seem to be utterly boring, and it actually is from many perspectives. \n",
        "Top Terms:\n",
        "boring -12.988\n",
        "just -4.475\n",
        "would -2.940\n",
        "there -1.768\n",
        "something -1.390\n",
        "be -0.801\n",
        "br -0.720\n",
        "but -0.448\n",
        "to -0.366\n",
        "such -0.360\n",
        "obviously -0.156\n",
        "many 0.744\n",
        "as 1.083\n",
        "is 1.739\n",
        "more 1.783\n",
        "and 3.417\n",
        "life 3.448\n",
        "it 3.874\n",
        "\n",
        "\n",
        "pred=0 (0.962492) truth=1 \n",
        "text=I could see myself in this same predicament - passively allowing things to happen around me, not standing up for the right and decent thing, just trying to avoid trouble. \n",
        "Top Terms:\n",
        "avoid -9.134\n",
        "just -4.475\n",
        "not -3.455\n",
        "trying -2.674\n",
        "thing -1.662\n",
        "could -1.451\n",
        "decent -1.110\n",
        "same -0.930\n",
        "this -0.783\n",
        "to -0.366\n",
        "for -0.150\n",
        "in 0.356\n",
        "the 1.026\n",
        "things 1.189\n",
        "right 1.439\n",
        "see 2.441\n",
        "and 3.417\n",
        "\n",
        "\n",
        "pred=1 (0.962276) truth=0 \n",
        "text=And the climactic scene has elements drawn shamelessly from \"The Perfect Storm\" and \"Dead Calm.\" \n",
        "Top Terms:\n",
        "the 1.026\n",
        "has 1.253\n",
        "and 3.417\n",
        "perfect 11.472\n",
        "\n",
        "\n",
        "pred=1 (0.961826) truth=0 \n",
        "text=The masses may argue that it is \"cool\" and that Clooney and Pitt put in great performances but these are the same people who have a subscription to \"Hello\" magazine and think that David Beckham has the potential to be a great actor. \n",
        "Top Terms:\n",
        "actor -2.136\n",
        "potential -2.101\n",
        "have -1.112\n",
        "same -0.930\n",
        "be -0.801\n",
        "but -0.448\n",
        "to -0.366\n",
        "are -0.261\n",
        "in 0.356\n",
        "pitt 0.378\n",
        "people 0.381\n",
        "who 0.707\n",
        "cool 0.999\n",
        "the 1.026\n",
        "has 1.253\n",
        "is 1.739\n",
        "think 1.814\n",
        "performances 2.374\n",
        "may 3.231\n",
        "and 3.417\n",
        "it 3.874\n",
        "great 11.212\n",
        "\n",
        "\n",
        "pred=0 (0.961271) truth=1 \n",
        "text=Even worse, she is not given the courtesy of having it all 'tied up', one way or the other, at the end. \n",
        "Top Terms:\n",
        "worse -10.117\n",
        "even -4.536\n",
        "not -3.455\n",
        "or -0.724\n",
        "way 0.070\n",
        "other 0.630\n",
        "she 0.891\n",
        "the 1.026\n",
        "is 1.739\n",
        "it 3.874\n",
        "\n",
        "\n",
        "pred=1 (0.960825) truth=0 \n",
        "text=While the cast are to old for the characters they are playing, the acting is actually pretty good with both Brett Halsey and Jack Elam giving solid performances. \n",
        "Top Terms:\n",
        "acting -1.949\n",
        "they -1.039\n",
        "to -0.366\n",
        "are -0.261\n",
        "old -0.240\n",
        "for -0.150\n",
        "pretty -0.100\n",
        "characters -0.002\n",
        "with 0.048\n",
        "while 0.609\n",
        "the 1.026\n",
        "is 1.739\n",
        "jack 2.238\n",
        "performances 2.374\n",
        "good 3.393\n",
        "and 3.417\n",
        "solid 4.032\n",
        "both 4.128\n",
        "\n",
        "\n",
        "pred=0 (0.960392) truth=1 \n",
        "text=Okay, I know the acting sucked but that's not what was important. \n",
        "Top Terms:\n",
        "not -3.455\n",
        "okay -3.039\n",
        "acting -1.949\n",
        "was -1.696\n",
        "sucked -1.185\n",
        "but -0.448\n",
        "what 0.399\n",
        "know 0.604\n",
        "the 1.026\n",
        "\n",
        "\n",
        "pred=0 (0.960319) truth=1 \n",
        "text=The Japanese did treat the Australians very poorly in Changi and to represent it as otherwise would be very misleading indeed. \n",
        "Top Terms:\n",
        "poorly -13.624\n",
        "would -2.940\n",
        "otherwise -1.792\n",
        "did -1.220\n",
        "be -0.801\n",
        "to -0.366\n",
        "in 0.356\n",
        "treat 0.592\n",
        "the 1.026\n",
        "as 1.083\n",
        "very 3.139\n",
        "and 3.417\n",
        "it 3.874\n",
        "\n",
        "\n",
        "pred=1 (0.960158) truth=0 \n",
        "text=I LOVED the Cousin Eddie character from the other Vacation movies...but he only works well as a supporting character. \n",
        "Top Terms:\n",
        "only -3.154\n",
        "but -0.448\n",
        "he 0.176\n",
        "movies 0.429\n",
        "eddie 0.603\n",
        "other 0.630\n",
        "the 1.026\n",
        "as 1.083\n",
        "works 1.991\n",
        "well 5.405\n",
        "loved 6.681\n",
        "\n",
        "\n",
        "pred=0 (0.959866) truth=1 \n",
        "text=Not pretty enough. \n",
        "Top Terms:\n",
        "not -3.455\n",
        "enough -2.826\n",
        "pretty -0.100\n",
        "\n",
        "\n",
        "pred=1 (0.959804) truth=0 \n",
        "text=He could be as solid as a rock but also as impassive as one, and in this film his Frederick seems an impersonation of the Great Stone Face. \n",
        "Top Terms:\n",
        "seems -4.165\n",
        "could -1.451\n",
        "be -0.801\n",
        "this -0.783\n",
        "but -0.448\n",
        "an -0.177\n",
        "stone 0.022\n",
        "he 0.176\n",
        "in 0.356\n",
        "film 0.675\n",
        "the 1.026\n",
        "as 1.083\n",
        "rock 1.253\n",
        "his 1.558\n",
        "and 3.417\n",
        "also 3.955\n",
        "solid 4.032\n",
        "great 11.212\n",
        "\n",
        "\n",
        "pred=1 (0.959663) truth=0 \n",
        "text=i work in the industry and yes these films are fun to work on, but rarely ever entertaining to actually watch. \n",
        "Top Terms:\n",
        "on -0.533\n",
        "but -0.448\n",
        "to -0.366\n",
        "are -0.261\n",
        "in 0.356\n",
        "yes 0.505\n",
        "watch 0.508\n",
        "ever 0.810\n",
        "the 1.026\n",
        "and 3.417\n",
        "entertaining 4.643\n",
        "fun 5.440\n",
        "\n",
        "\n",
        "pred=0 (0.959503) truth=1 \n",
        "text=The movie is somewhat predictable, I knew once the wife was killed that she would be sharing a brain with her killer. \n",
        "Top Terms:\n",
        "predictable -5.153\n",
        "brain -4.061\n",
        "would -2.940\n",
        "was -1.696\n",
        "be -0.801\n",
        "wife -0.700\n",
        "movie -0.251\n",
        "killer -0.139\n",
        "with 0.048\n",
        "her 0.205\n",
        "once 0.350\n",
        "somewhat 0.749\n",
        "she 0.891\n",
        "the 1.026\n",
        "is 1.739\n",
        "\n",
        "\n",
        "pred=0 (0.959322) truth=1 \n",
        "text=I knew nothing about the movie before watching it. \n",
        "Top Terms:\n",
        "nothing -8.432\n",
        "watching -0.745\n",
        "movie -0.251\n",
        "the 1.026\n",
        "it 3.874\n",
        "\n",
        "\n",
        "pred=1 (0.958762) truth=0 \n",
        "text=So the gems are of great value not only because of their quality and size, but also because of the tie to the Greatest conquerer the world has ever known. \n",
        "Top Terms:\n",
        "not -3.455\n",
        "only -3.154\n",
        "value -1.243\n",
        "but -0.448\n",
        "to -0.366\n",
        "are -0.261\n",
        "ever 0.810\n",
        "the 1.026\n",
        "has 1.253\n",
        "greatest 3.210\n",
        "and 3.417\n",
        "also 3.955\n",
        "world 4.363\n",
        "great 11.212\n",
        "\n",
        "\n",
        "pred=0 (0.958619) truth=1 \n",
        "text=With that in mind, I'm sure the screenwriter knew that was weak, but needed something. \n",
        "Top Terms:\n",
        "weak -5.962\n",
        "was -1.696\n",
        "something -1.390\n",
        "screenwriter -0.620\n",
        "but -0.448\n",
        "with 0.048\n",
        "in 0.356\n",
        "the 1.026\n",
        "\n",
        "\n",
        "pred=1 (0.95847) truth=0 \n",
        "text=The locations and scenery are great, but Vane lacked the necessary funds to provide his film with a proper continuity and editing-job. \n",
        "Top Terms:\n",
        "editing -0.825\n",
        "but -0.448\n",
        "to -0.366\n",
        "are -0.261\n",
        "with 0.048\n",
        "film 0.675\n",
        "the 1.026\n",
        "his 1.558\n",
        "necessary 1.640\n",
        "and 3.417\n",
        "job 4.682\n",
        "great 11.212\n",
        "\n",
        "\n",
        "pred=0 (0.958283) truth=1 \n",
        "text=However, for the life of me, I have no idea why Fritz Lang was assigned to direct this film--after all, he knew nothing about Westerns. \n",
        "Top Terms:\n",
        "nothing -8.432\n",
        "no -5.931\n",
        "idea -3.671\n",
        "why -3.251\n",
        "was -1.696\n",
        "have -1.112\n",
        "this -0.783\n",
        "to -0.366\n",
        "however -0.235\n",
        "for -0.150\n",
        "he 0.176\n",
        "film 0.675\n",
        "the 1.026\n",
        "life 3.448\n",
        "\n",
        "\n",
        "pred=1 (0.958154) truth=0 \n",
        "text=Not here.<br /><br />It's always fun seeing the Pathmark guy though. \n",
        "Top Terms:\n",
        "not -3.455\n",
        "here -0.995\n",
        "guy -0.934\n",
        "br -0.720\n",
        "seeing 0.433\n",
        "the 1.026\n",
        "though 1.935\n",
        "always 3.198\n",
        "it 3.874\n",
        "fun 5.440\n",
        "\n",
        "\n",
        "pred=1 (0.957841) truth=0 \n",
        "text=Just incredible. \n",
        "Top Terms:\n",
        "just -4.475\n",
        "incredible 5.143\n",
        "\n",
        "\n",
        "pred=1 (0.957342) truth=0 \n",
        "text=it's difficult to film in the dark, and sometimes darkness is a great vehicle in a film that's suppose to have tension. \n",
        "Top Terms:\n",
        "have -1.112\n",
        "to -0.366\n",
        "suppose -0.002\n",
        "dark 0.091\n",
        "in 0.356\n",
        "film 0.675\n",
        "the 1.026\n",
        "is 1.739\n",
        "sometimes 1.998\n",
        "and 3.417\n",
        "it 3.874\n",
        "great 11.212\n",
        "\n",
        "\n",
        "pred=1 (0.956751) truth=0 \n",
        "text=That said, the production value is definitely here, with great zombie effects and it's edited quite nicely, with very effective sound design. \n",
        "Top Terms:\n",
        "production -1.623\n",
        "value -1.243\n",
        "said -1.224\n",
        "here -0.995\n",
        "effects -0.469\n",
        "with 0.048\n",
        "effective 0.824\n",
        "the 1.026\n",
        "quite 1.282\n",
        "is 1.739\n",
        "very 3.139\n",
        "and 3.417\n",
        "it 3.874\n",
        "definitely 5.848\n",
        "great 11.212\n",
        "\n",
        "\n",
        "pred=0 (0.956622) truth=1 \n",
        "text=There wasn't much we didn't like about this one. \n",
        "Top Terms:\n",
        "didn -2.266\n",
        "there -1.768\n",
        "much -1.721\n",
        "wasn -1.570\n",
        "this -0.783\n",
        "\n",
        "\n",
        "pred=1 (0.956563) truth=0 \n",
        "text=Now, you may think you've seen the bottom of the barrel. \n",
        "Top Terms:\n",
        "bottom -0.888\n",
        "the 1.026\n",
        "now 1.449\n",
        "think 1.814\n",
        "you 3.110\n",
        "may 3.231\n",
        "seen 3.747\n",
        "\n",
        "\n",
        "pred=1 (0.955924) truth=0 \n",
        "text=The amazing part of this is that somebody actually believes he is a philosopher!!! \n",
        "Top Terms:\n",
        "this -0.783\n",
        "he 0.176\n",
        "the 1.026\n",
        "is 1.739\n",
        "amazing 9.253\n",
        "\n",
        "\n",
        "pred=1 (0.955788) truth=0 \n",
        "text=I like both Hollywood action and slower moving character development. \n",
        "Top Terms:\n",
        "development -0.561\n",
        "action 1.496\n",
        "and 3.417\n",
        "both 4.128\n",
        "moving 4.211\n",
        "\n",
        "\n",
        "pred=1 (0.954984) truth=0 \n",
        "text=That said, back to the beginning, still this guy has his own things to say and says them well. \n",
        "Top Terms:\n",
        "said -1.224\n",
        "guy -0.934\n",
        "this -0.783\n",
        "to -0.366\n",
        "beginning 0.096\n",
        "the 1.026\n",
        "things 1.189\n",
        "has 1.253\n",
        "his 1.558\n",
        "own 2.225\n",
        "and 3.417\n",
        "still 4.419\n",
        "well 5.405\n",
        "\n",
        "\n",
        "pred=0 (0.95483) truth=1 \n",
        "text=And there's a mildly surprising epilogue. \n",
        "Top Terms:\n",
        "mildly -5.807\n",
        "there -1.768\n",
        "surprising 0.037\n",
        "and 3.417\n",
        "\n",
        "\n",
        "pred=0 (0.954273) truth=1 \n",
        "text=It perhaps would have made a more interesting film had he not been killed off. \n",
        "Top Terms:\n",
        "not -3.455\n",
        "off -2.959\n",
        "would -2.940\n",
        "interesting -2.837\n",
        "been -2.155\n",
        "have -1.112\n",
        "had -0.635\n",
        "he 0.176\n",
        "film 0.675\n",
        "more 1.783\n",
        "it 3.874\n",
        "\n",
        "\n",
        "pred=0 (0.953949) truth=1 \n",
        "text=The comic-relief is the weakest aspect of this film, but these scenes are not common and are swallowed up in the tremendous sweep of the film.<br /><br />I've read much criticism of Wayne's performance\u00c2\u0097some even going so far as to blame his \"wooden acting\" for the failure of the film at the box-office. \n",
        "Top Terms:\n",
        "wooden -7.171\n",
        "even -4.536\n",
        "not -3.455\n",
        "acting -1.949\n",
        "failure -1.822\n",
        "far -1.778\n",
        "blame -1.730\n",
        "much -1.721\n",
        "read -1.148\n",
        "box -0.857\n",
        "this -0.783\n",
        "br -0.720\n",
        "scenes -0.655\n",
        "but -0.448\n",
        "to -0.366\n",
        "are -0.261\n",
        "for -0.150\n",
        "in 0.356\n",
        "comic 0.502\n",
        "film 0.675\n",
        "the 1.026\n",
        "as 1.083\n",
        "his 1.558\n",
        "is 1.739\n",
        "and 3.417\n",
        "\n",
        "\n",
        "pred=1 (0.95327) truth=0 \n",
        "text=Again, some great lines -- some laugh-out-loud funny -- but as a movie overall it's a fail. \n",
        "Top Terms:\n",
        "but -0.448\n",
        "movie -0.251\n",
        "lines -0.202\n",
        "again 0.401\n",
        "as 1.083\n",
        "overall 1.696\n",
        "it 3.874\n",
        "great 11.212\n",
        "\n",
        "\n",
        "pred=1 (0.952753) truth=0 \n",
        "text=I love the fact that it is getting attention after all these years. \n",
        "Top Terms:\n",
        "attention 0.590\n",
        "the 1.026\n",
        "is 1.739\n",
        "years 1.790\n",
        "it 3.874\n",
        "love 4.753\n",
        "\n",
        "\n",
        "pred=0 (0.952196) truth=1 \n",
        "text=It will mess with your mind and leave you with images that take a while to forget. \n",
        "Top Terms:\n",
        "mess -11.635\n",
        "to -0.366\n",
        "with 0.048\n",
        "while 0.609\n",
        "will 2.462\n",
        "you 3.110\n",
        "and 3.417\n",
        "it 3.874\n",
        "\n",
        "\n",
        "pred=0 (0.951918) truth=1 \n",
        "text=If LucasArts were to make a movie/cartoon of Monkey Island, this would probably be what it would look like, and sound like. \n",
        "Top Terms:\n",
        "would -2.940\n",
        "if -2.407\n",
        "make -2.389\n",
        "monkey -1.571\n",
        "were -1.537\n",
        "island -1.454\n",
        "be -0.801\n",
        "this -0.783\n",
        "look -0.585\n",
        "to -0.366\n",
        "movie -0.251\n",
        "what 0.399\n",
        "and 3.417\n",
        "it 3.874\n",
        "\n",
        "\n",
        "pred=0 (0.951781) truth=1 \n",
        "text=(Though several comments expressed disappointment in his rather limited screen time.) \n",
        "Top Terms:\n",
        "disappointment -12.430\n",
        "in 0.356\n",
        "several 0.540\n",
        "time 1.216\n",
        "his 1.558\n",
        "though 1.935\n",
        "comments 2.587\n",
        "\n",
        "\n",
        "pred=0 (0.951535) truth=1 \n",
        "text=(Pardon my bad grammar,) but I'm making a point here. \n",
        "Top Terms:\n",
        "bad -11.142\n",
        "making -2.361\n",
        "here -0.995\n",
        "point -0.914\n",
        "but -0.448\n",
        "my 1.827\n",
        "\n",
        "\n",
        "pred=0 (0.951503) truth=1 \n",
        "text=The dean of the school read the script and said there was way too much swearing in the film. \n",
        "Top Terms:\n",
        "script -6.492\n",
        "too -2.844\n",
        "there -1.768\n",
        "much -1.721\n",
        "was -1.696\n",
        "said -1.224\n",
        "read -1.148\n",
        "dean -0.331\n",
        "way 0.070\n",
        "in 0.356\n",
        "film 0.675\n",
        "the 1.026\n",
        "and 3.417\n",
        "\n",
        "\n",
        "pred=0 (0.950954) truth=1 \n",
        "text=Oh, for those polaroid lenses again. \n",
        "Top Terms:\n",
        "oh -7.797\n",
        "for -0.150\n",
        "those 0.167\n",
        "again 0.401\n",
        "\n",
        "\n",
        "pred=0 (0.950723) truth=1 \n",
        "text=I can think of a half dozen better endings off the top of my head that would have worked better for the writer's obvious goals and not been so contrived. \n",
        "Top Terms:\n",
        "half -3.948\n",
        "obvious -3.723\n",
        "not -3.455\n",
        "off -2.959\n",
        "would -2.940\n",
        "better -2.650\n",
        "been -2.155\n",
        "have -1.112\n",
        "head -0.284\n",
        "for -0.150\n",
        "the 1.026\n",
        "top 1.321\n",
        "think 1.814\n",
        "my 1.827\n",
        "and 3.417\n",
        "\n",
        "\n",
        "pred=0 (0.950462) truth=1 \n",
        "text=But some of these characters were used too much.<br /><br />From here on out I can only nit-pick so I will save you the wear and tear. \n",
        "Top Terms:\n",
        "save -8.437\n",
        "only -3.154\n",
        "too -2.844\n",
        "much -1.721\n",
        "were -1.537\n",
        "here -0.995\n",
        "br -0.720\n",
        "on -0.533\n",
        "but -0.448\n",
        "characters -0.002\n",
        "the 1.026\n",
        "will 2.462\n",
        "you 3.110\n",
        "and 3.417\n",
        "\n",
        "\n",
        "pred=0 (0.950262) truth=1 \n",
        "text=Ms. Bissett was just too breathy for me. \n",
        "Top Terms:\n",
        "just -4.475\n",
        "too -2.844\n",
        "was -1.696\n",
        "ms -0.358\n",
        "for -0.150\n",
        "\n",
        "\n",
        "pred=1 (0.950187) truth=0 \n",
        "text=After all, Ocean's 11 was a truly great Hollywood product. \n",
        "Top Terms:\n",
        "was -1.696\n",
        "11 1.302\n",
        "truly 1.665\n",
        "great 11.212\n",
        "\n"
       ]
      }
     ],
     "prompt_number": 54
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "##4. Other Datasets: SRAA Analysis\n",
      "\n",
      "Setting data and expert "
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "sraa, vct = load_data('sraa', SRAA_DATA)\n",
      "\n",
      "expertl2 = exputil.get_classifier('lrl2', parameter=1)\n",
      "expertl1 = exputil.get_classifier('lr', parameter=1)\n",
      "\n",
      "expertl2.fit(sraa.train.bow, sraa.train.target)\n",
      "expertl1.fit(sraa.train.bow, sraa.train.target)\n",
      "\n",
      "sent_tk = nltk.data.load('tokenizers/punkt/english.pickle')\n",
      "\n",
      "## Get Test data ready\n",
      "test_docs = rnd.permutation(len(sraa.test.target))\n",
      "\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 56
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### SRAA Top Terms\n",
      "\n",
      "We tested L1 and L2 models to check the differences "
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "sent = sent_tk.tokenize_sents(sraa.test.data[test_docs[:n]])\n",
      "snippets, y_test = _sentences(sent, sraa.test.target[test_docs[:n]])\n",
      "x_test = vct.transform(snippets)\n",
      "\n",
      "print \"Number testing of documents:\", len(sent)\n",
      "print \"Number of sentences:\", len(snippets)\n",
      "print \"Number of features:\", x_test.shape[1]\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Number testing of documents: 1000\n",
        "Number of sentences: 9690\n",
        "Number of features: 26636\n"
       ]
      }
     ],
     "prompt_number": 57
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "terms = vct.get_feature_names()\n",
      "print \"Classes\", sraa.train.target_names\n",
      "\n",
      "#L2 Expert\n",
      "print_top_terms(expertl2, np.array(terms))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Classes ['auto', 'aviation']\n",
        "\n",
        "Top Coefficients\n",
        "Class-0 Terms:\n",
        "flight (11.6494)\n",
        "fs98 (11.3587)\n",
        "fly (9.05536)\n",
        "flying (8.10588)\n",
        "plane (8.0934)\n",
        "pilot (8.03292)\n",
        "aviation (7.45972)\n",
        "aircraft (7.25487)\n",
        "scenery (5.98665)\n",
        "fs (5.18738)\n",
        "cfi (4.70788)\n",
        "landing (4.67269)\n",
        "airport (4.62844)\n",
        "pilots (4.47923)\n",
        "flightsim (4.2835)\n",
        "airplane (4.21479)\n",
        "student (4.08262)\n",
        "solo (4.07698)\n",
        "rudder (4.0595)\n",
        "faa (4.01031)\n",
        "\n",
        "Class-1 Terms:\n",
        "gpl (-13.0117)\n",
        "car (-10.5758)\n",
        "racing (-8.56109)\n",
        "wheel (-7.27949)\n",
        "cars (-6.78129)\n",
        "race (-6.76253)\n",
        "game (-5.58429)\n",
        "nascar (-5.31047)\n",
        "track (-5.23633)\n",
        "demo (-4.32791)\n",
        "driving (-4.18562)\n",
        "tracks (-3.82102)\n",
        "n2 (-3.74804)\n",
        "gp2 (-3.71927)\n",
        "drive (-3.38365)\n",
        "lap (-3.36408)\n",
        "f1rs (-3.33363)\n",
        "rendition (-3.30443)\n",
        "ford (-3.13272)\n",
        "brake (-3.0039)\n",
        "\n",
        "intercept=-0.595686\n"
       ]
      }
     ],
     "prompt_number": 58
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#L1 Expert\n",
      "print_top_terms(expertl1, np.array(terms))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Top Coefficients\n",
        "Class-0 Terms:\n",
        "fs98 (40.3343)\n",
        "flight (30.6681)\n",
        "aviation (30.4355)\n",
        "fly (26.0591)\n",
        "pilot (24.5901)\n",
        "plane (24.2045)\n",
        "flying (21.1497)\n",
        "aircraft (20.8583)\n",
        "scenery (17.404)\n",
        "regish (17.3508)\n",
        "fs (16.9234)\n",
        "cfi (16.5759)\n",
        "pilots (16.0843)\n",
        "landing (15.4031)\n",
        "cfs (14.3282)\n",
        "flightsim (14.0341)\n",
        "altitude (13.9521)\n",
        "airplane (13.642)\n",
        "rudder (13.5013)\n",
        "atc (13.3727)\n",
        "\n",
        "Class-1 Terms:\n",
        "gpl (-52.9577)\n",
        "racing (-31.7369)\n",
        "car (-24.0842)\n",
        "race (-21.945)\n",
        "wheel (-17.4299)\n",
        "cars (-16.9993)\n",
        "nascar (-13.4513)\n",
        "track (-12.5175)\n",
        "n2 (-10.684)\n",
        "driving (-10.5728)\n",
        "f1rs (-9.97689)\n",
        "gp2 (-9.91462)\n",
        "tracks (-9.70323)\n",
        "rendition (-8.3895)\n",
        "demo (-8.08296)\n",
        "brake (-7.67451)\n",
        "game (-7.66311)\n",
        "auto (-7.63241)\n",
        "ford (-7.58885)\n",
        "rally (-7.2246)\n",
        "\n",
        "intercept=-0.871348\n"
       ]
      }
     ],
     "prompt_number": 59
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### SRAA Expert Error Analysis"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print \"EXPERT L2\"\n",
      "error_analysis(expertl2, x_test, y_test, snippets, vct.get_feature_names(), sort=True)\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "EXPERT L2\n",
        "Accuracy: 0.8165\n",
        "Test size: 9690\n",
        "\n",
        "ERRORS (P > 0.95):\n",
        "\n",
        "pred=1 (0.994102) truth=0 \n",
        "text=I love flying their plane, I'm just no good at it! \n",
        "Top Terms:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "it -1.222\n",
        "no -1.088\n",
        "their -0.708\n",
        "just -0.498\n",
        "at -0.446\n",
        "love -0.150\n",
        "good 0.509\n",
        "plane 8.093\n",
        "flying 8.106\n",
        "\n",
        "\n",
        "pred=1 (0.990348) truth=0 \n",
        "text=You have to talk to the tower, taxi, request\n",
        ">landing permission, adjust flaps and even start the plane up. \n",
        "Top Terms:\n",
        "start -0.796\n",
        "even -0.491\n",
        "up -0.120\n",
        "have -0.005\n",
        "the 0.003\n",
        "permission 0.017\n",
        "adjust 0.183\n",
        "request 0.292\n",
        "talk 0.345\n",
        "you 0.703\n",
        "and 1.016\n",
        "to 1.100\n",
        "taxi 1.133\n",
        "tower 2.244\n",
        "flaps 3.337\n",
        "landing 4.673\n",
        "plane 8.093\n",
        "\n",
        "\n",
        "pred=1 (0.978951) truth=0 \n",
        "text=Don't get me\n",
        "wrong, I think MS FS and the like have potential and for a FLIGHT sim seem\n",
        "fairly realistic, but... \n",
        "Top Terms:\n",
        "sim -1.515\n",
        "but -0.754\n",
        "don -0.624\n",
        "get -0.478\n",
        "wrong -0.305\n",
        "like -0.072\n",
        "think -0.055\n",
        "seem -0.044\n",
        "have -0.005\n",
        "the 0.003\n",
        "potential 0.059\n",
        "realistic 0.182\n",
        "fairly 0.212\n",
        "for 0.272\n",
        "me 0.421\n",
        "and 1.016\n",
        "ms 1.449\n",
        "fs 5.187\n",
        "flight 11.649\n",
        "\n",
        "\n",
        "pred=1 (0.967901) truth=0 \n",
        "text=I once had a flight sim that   wouldn't display the cockpit above 64x480. \n",
        "Top Terms:\n",
        "sim -1.515\n",
        "wouldn -0.492\n",
        "the 0.003\n",
        "cockpit 0.199\n",
        "that 0.351\n",
        "had 0.551\n",
        "once 0.986\n",
        "above 1.033\n",
        "display 1.044\n",
        "flight 11.649\n",
        "\n",
        "\n",
        "pred=0 (0.96528) truth=1 \n",
        "text=Anything that anyone would car\n",
        "to\n",
        ">> offer would be very MUCH appreciated. \n",
        "Top Terms:\n",
        "car -10.576\n",
        "be -0.760\n",
        "anything -0.538\n",
        "offer -0.346\n",
        "much -0.270\n",
        "anyone -0.121\n",
        "would 0.233\n",
        "that 0.351\n",
        "appreciated 0.478\n",
        "very 0.547\n",
        "to 1.100\n",
        "\n",
        "\n",
        "pred=1 (0.963696) truth=0 \n",
        "text=>\n",
        ">In a good flight sim like MS FlightSim98 or Flight Unlimited 2 you get\n",
        ">virtually a complete sim. \n",
        "Top Terms:\n",
        "sim -1.515\n",
        "in -0.543\n",
        "get -0.478\n",
        "or -0.476\n",
        "complete -0.358\n",
        "virtually -0.172\n",
        "flightsim98 -0.075\n",
        "like -0.072\n",
        "unlimited 0.246\n",
        "good 0.509\n",
        "you 0.703\n",
        "ms 1.449\n",
        "flight 11.649\n",
        "\n",
        "\n",
        "pred=0 (0.956274) truth=1 \n",
        "text=>\n",
        ">Cheers! \n",
        "Top Terms:\n",
        "cheers -2.489\n",
        "\n"
       ]
      }
     ],
     "prompt_number": 60
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print \"EXPERT L1\"\n",
      "error_analysis(expertl1, x_test, y_test, snippets, vct.get_feature_names(), sort=True)\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "EXPERT L1\n",
        "Accuracy: 0.7834"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Test size: 9690\n",
        "\n",
        "ERRORS (P > 0.95):\n",
        "\n",
        "pred=1 (1) truth=0 \n",
        "text=I love flying their plane, I'm just no good at it! \n",
        "Top Terms:\n",
        "it -1.316\n",
        "no -0.926\n",
        "just -0.497\n",
        "at -0.322\n",
        "their -0.287\n",
        "flying 21.150\n",
        "plane 24.205\n",
        "\n",
        "\n",
        "pred=1 (0.999993) truth=0 \n",
        "text=You have to talk to the tower, taxi, request\n",
        ">landing permission, adjust flaps and even start the plane up. \n",
        "Top Terms:\n",
        "the 0.133\n",
        "to 0.507\n",
        "and 0.700\n",
        "you 1.057\n",
        "tower 3.045\n",
        "flaps 8.799\n",
        "landing 15.403\n",
        "plane 24.205\n",
        "\n",
        "\n",
        "pred=1 (0.99999) truth=0 \n",
        "text=Don't get me\n",
        "wrong, I think MS FS and the like have potential and for a FLIGHT sim seem\n",
        "fairly realistic, but... \n",
        "Top Terms:\n",
        "sim -1.563\n",
        "don -0.504\n",
        "the 0.133\n",
        "ms 0.580\n",
        "me 0.694\n",
        "and 0.700\n",
        "fs 16.923\n",
        "flight 30.668\n",
        "\n",
        "\n",
        "pred=1 (0.999943) truth=0 \n",
        "text=>\n",
        ">In a good flight sim like MS FlightSim98 or Flight Unlimited 2 you get\n",
        ">virtually a complete sim. \n",
        "Top Terms:\n",
        "sim -1.563\n",
        "in -0.813\n",
        "ms 0.580\n",
        "you 1.057\n",
        "flight 30.668\n",
        "\n",
        "\n",
        "pred=1 (0.999786) truth=0 \n",
        "text=Guess\n",
        "the same is true of flight sims fans. \n",
        "Top Terms:\n",
        "same -0.630\n",
        "the 0.133\n",
        "of 1.164\n",
        "flight 30.668\n",
        "\n",
        "\n",
        "pred=1 (0.999784) truth=0 \n",
        "text=Most of\n",
        ">the details are there that a pilot has to go through. \n",
        "Top Terms:\n",
        "through -0.451\n",
        "that 0.101\n",
        "the 0.133\n",
        "to 0.507\n",
        "there 1.074\n",
        "of 1.164\n",
        "pilot 24.590\n",
        "\n",
        "\n",
        "pred=1 (0.999501) truth=0 \n",
        "text=I once had a flight sim that   wouldn't display the cockpit above 64x480. \n",
        "Top Terms:\n",
        "sim -1.563\n",
        "that 0.101\n",
        "the 0.133\n",
        "had 0.138\n",
        "display 0.203\n",
        "once 0.479\n",
        "above 0.642\n",
        "flight 30.668\n",
        "\n",
        "\n",
        "pred=1 (0.999418) truth=0 \n",
        "text=That is what it\n",
        "takes to fly first class in the sim biz. \n",
        "Top Terms:\n",
        "sim -1.563\n",
        "it -1.316\n",
        "in -0.813\n",
        "that 0.101\n",
        "the 0.133\n",
        "to 0.507\n",
        "class 5.555\n",
        "fly 26.059\n",
        "\n",
        "\n",
        "pred=0 (0.999328) truth=1 \n",
        "text=Anything that anyone would car\n",
        "to\n",
        ">> offer would be very MUCH appreciated. \n",
        "Top Terms:\n",
        "car -24.084\n",
        "anything -0.584\n",
        "be -0.161\n",
        "anyone 0.048\n",
        "that 0.101\n",
        "to 0.507\n",
        "\n",
        "\n",
        "pred=0 (0.999321) truth=1 \n",
        "text=> As you apply power in your car, you will increase the speed. \n",
        "Top Terms:\n",
        "car -24.084\n",
        "will -1.518\n",
        "speed -1.503\n",
        "in -0.813\n",
        "power 0.084\n",
        "the 0.133\n",
        "you 1.057\n",
        "as 1.259\n",
        "your 1.361\n",
        "\n",
        "\n",
        "pred=0 (0.998323) truth=1 \n",
        "text=For a little while, anyway...\n",
        "\n",
        "> > As you apply power in your car, you will increase the speed. \n",
        "Top Terms:\n",
        "car -24.084\n",
        "will -1.518\n",
        "speed -1.503\n",
        "in -0.813\n",
        "power 0.084\n",
        "the 0.133\n",
        "you 1.057\n",
        "as 1.259\n",
        "your 1.361\n",
        "\n",
        "\n",
        "pred=1 (0.997773) truth=0 \n",
        "text=<shrug>)\n",
        ">\n",
        ">Also making ones way from the paddock to pit lane should be implemented\n",
        ">just like you need to taxi in a plane to the runway. \n",
        "Top Terms:\n",
        "need -1.845\n",
        "in -0.813\n",
        "should -0.705\n",
        "just -0.497\n",
        "be -0.161\n",
        "making -0.076\n",
        "the 0.133\n",
        "also 0.173\n",
        "from 0.481\n",
        "to 0.507\n",
        "you 1.057\n",
        "runway 12.330\n",
        "plane 24.205\n",
        "\n",
        "\n",
        "pred=1 (0.997762) truth=0 \n",
        "text=>\n",
        ">Well, to follow that premise, you would advocate that the aircraft\n",
        ">represented in an historical WW1 flight simulation should be able to be\n",
        ">equipped with Sidewinder missiles? \n",
        "Top Terms:\n",
        "well -0.949\n",
        "in -0.813\n",
        "should -0.705\n",
        "able -0.239\n",
        "be -0.161\n",
        "that 0.101\n",
        "the 0.133\n",
        "to 0.507\n",
        "you 1.057\n",
        "an 1.261\n",
        "aircraft 20.858\n",
        "flight 30.668\n",
        "\n",
        "\n",
        "pred=0 (0.997527) truth=1 \n",
        "text=>\n",
        ">Cheers! \n",
        "Top Terms:\n",
        "cheers -5.129\n",
        "\n",
        "\n",
        "pred=0 (0.997275) truth=1 \n",
        "text=> \n",
        "> So now the question is, WHICH aluminum wheel to use? \n",
        "Top Terms:\n",
        "wheel -17.430\n",
        "so -2.120\n",
        "the 0.133\n",
        "to 0.507\n",
        "which 0.626\n",
        "question 2.060\n",
        "\n",
        "\n",
        "pred=1 (0.997193) truth=0 \n",
        "text=Maybe I should just use my palm to pilot something else... \n",
        "Top Terms:\n",
        "something -1.181\n",
        "else -0.726\n",
        "should -0.705\n",
        "just -0.497\n",
        "to 0.507\n",
        "pilot 24.590\n",
        "\n",
        "\n",
        "pred=1 (0.997102) truth=0 \n",
        "text=I would have had to fly\n",
        ">to the other coast to buy a Jetta from him. \n",
        "Top Terms:\n",
        "the 0.133\n",
        "had 0.138\n",
        "from 0.481\n",
        "to 0.507\n",
        "other 1.199\n",
        "fly 26.059\n",
        "\n",
        "\n",
        "pred=1 (0.995532) truth=0 \n",
        "text=>> I agree that if someone is flying up behind you that you should move\n",
        "over. \n",
        "Top Terms:\n",
        "should -0.705\n",
        "that 0.101\n",
        "you 1.057\n",
        "flying 21.150\n",
        "\n",
        "\n",
        "pred=1 (0.993577) truth=0 \n",
        "text=>roy\n",
        "\n",
        "\n",
        " \n",
        "Top Terms:\n",
        "roy 5.913\n",
        "\n",
        "\n",
        "pred=1 (0.991412) truth=0 \n",
        "text=  \"Gary Derian\" <gderian@cybergate.net> wrote:\n",
        "> Window tint film can only bend in one plane. \n",
        "Top Terms:\n",
        "wrote -1.183\n",
        "in -0.813\n",
        "only -0.115\n",
        "can 0.082\n",
        "window 0.576\n",
        "one 1.262\n",
        "plane 24.205\n",
        "\n",
        "\n",
        "pred=1 (0.988969) truth=0 \n",
        "text=Throw three switches on the CH Pedals - change Car/Plane to Plane,\n",
        "and switch my two custom DPDT switches down to reverse operation. \n",
        "Top Terms:\n",
        "car -24.084\n",
        "change -0.279\n",
        "the 0.133\n",
        "to 0.507\n",
        "and 0.700\n",
        "ch 2.011\n",
        "plane 24.205\n",
        "\n",
        "\n",
        "pred=1 (0.987476) truth=0 \n",
        "text=The hardcore flight \n",
        "sim crowd (\"Yes, we'd like to put a complete texture map of France \n",
        "in the game and ship it on 3 DVDs. \n",
        "Top Terms:\n",
        "game -7.663\n",
        "sim -1.563\n",
        "it -1.316\n",
        "in -0.813\n",
        "yes -0.546\n",
        "the 0.133\n",
        "to 0.507\n",
        "and 0.700\n",
        "of 1.164\n",
        "map 5.445\n",
        "flight 30.668\n",
        "\n",
        "\n",
        "pred=1 (0.980727) truth=0 \n",
        "text=Hello? \n",
        "Top Terms:\n",
        "hello 4.801\n",
        "\n",
        "\n",
        "pred=1 (0.979065) truth=0 \n",
        "text=>\n",
        ">I can't imagine running/flying around and shooting monsters/people as\n",
        ">entertainment. \n",
        "Top Terms:\n",
        "people -0.177\n",
        "can 0.082\n",
        "and 0.700\n",
        "as 1.259\n",
        "flying 21.150\n",
        "\n",
        "\n",
        "pred=0 (0.979054) truth=1 \n",
        "text=Cheers,\n",
        "Jay.\n",
        "\n",
        "\n",
        "\n",
        " \n",
        "Top Terms:\n",
        "cheers -5.129\n",
        "jay -0.226\n",
        "\n",
        "\n",
        "pred=0 (0.977342) truth=1 \n",
        "text=Rob\n",
        " \n",
        "Top Terms:\n",
        "rob -2.893\n",
        "\n",
        "\n",
        "pred=1 (0.975373) truth=0 \n",
        "text=Thats one\n",
        ">source...also personal experiences with friends who had experiences in\n",
        ">both fields....and stories from others in the flight sim group. \n",
        "Top Terms:\n",
        "sim -1.563\n",
        "in -0.813\n",
        "the 0.133\n",
        "had 0.138\n",
        "also 0.173\n",
        "from 0.481\n",
        "and 0.700\n",
        "one 1.262\n",
        "flight 30.668\n",
        "\n",
        "\n",
        "pred=0 (0.971681) truth=1 \n",
        "text=>Oh yes, and we should probably call this the Orbiter Vehicle. \n",
        "Top Terms:\n",
        "vehicle -6.071\n",
        "should -0.705\n",
        "yes -0.546\n",
        "this -0.300\n",
        "the 0.133\n",
        "and 0.700\n",
        "\n",
        "\n",
        "pred=1 (0.968556) truth=0 \n",
        "text=--\n",
        "\n",
        "all opinions expressed while drunk, stoned and flying through clouds. \n",
        "Top Terms:\n",
        "through -0.451\n",
        "and 0.700\n",
        "flying 21.150\n",
        "\n",
        "\n",
        "pred=0 (0.966008) truth=1 \n",
        "text=It will\n",
        "be about the only graphic intense game I plan to run on this machine. \n",
        "Top Terms:\n",
        "game -7.663\n",
        "run -2.007\n",
        "will -1.518\n",
        "it -1.316\n",
        "this -0.300\n",
        "be -0.161\n",
        "only -0.115\n",
        "the 0.133\n",
        "about 0.269\n",
        "to 0.507\n",
        "\n",
        "\n",
        "pred=0 (0.965779) truth=1 \n",
        "text=I just could not get the flare and\n",
        "> hold off right, more often than not I would balloon then come down hard or try\n",
        "> to dig the nose wheel in. \n",
        "Top Terms:\n",
        "wheel -17.430\n",
        "could -1.172\n",
        "in -0.813\n",
        "just -0.497\n",
        "come -0.295\n",
        "then -0.067\n",
        "the 0.133\n",
        "not 0.473\n",
        "to 0.507\n",
        "and 0.700\n",
        "nose 3.137\n",
        "\n",
        "\n",
        "pred=1 (0.964297) truth=0 \n",
        "text=> >>It looks like I'm gonna have to give up on the stick shifter :(\n",
        "> >>Paul..\n",
        "> >>\n",
        "> >\n",
        "> >\n",
        "\n",
        "--\n",
        "Regards\n",
        "\n",
        "Sunny Chow\n",
        "--------------------------------------------------------------\n",
        "mailto:sunnyc@singnet.com.sg\n",
        "HomePage: http://web.singnet.com.sg/~sunnyc\n",
        "\n",
        "mailto:airscapes@flight2000.com\n",
        "Aviation Art webpage: http://www.flight2000.com/airscapes\n",
        "--------------------------------------------------------------\n",
        "\n",
        "\n",
        " \n",
        "Top Terms:\n",
        "paul -3.162\n",
        "it -1.316\n",
        "com -0.271\n",
        "the 0.133\n",
        "sg 0.464\n",
        "to 0.507\n",
        "give 1.360\n",
        "web 1.875\n",
        "stick 1.946\n",
        "regards 3.331\n",
        "aviation 30.436\n",
        "\n",
        "\n",
        "pred=1 (0.960913) truth=0 \n",
        "text=This is how I approach this type of issue. \n",
        "Top Terms:\n",
        "this -0.300\n",
        "of 1.164\n",
        "approach 8.133\n",
        "\n",
        "\n",
        "pred=1 (0.960842) truth=0 \n",
        "text=Sam\n",
        " \n",
        "Top Terms:\n",
        "sam 4.072\n",
        "\n",
        "\n",
        "pred=0 (0.960452) truth=1 \n",
        "text=Hey guys! \n",
        "Top Terms:\n",
        "guys -3.410\n",
        "\n",
        "\n",
        "pred=0 (0.95569) truth=1 \n",
        "text=If so, pass on it as HAB seems to only produce simulators, not games. \n",
        "Top Terms:\n",
        "games -6.295\n",
        "so -2.120\n",
        "it -1.316\n",
        "only -0.115\n",
        "not 0.473\n",
        "to 0.507\n",
        "as 1.259\n",
        "\n",
        "\n",
        "pred=1 (0.955001) truth=0 \n",
        "text=>\n",
        ">--\n",
        ">James P Picotte\n",
        ">Michigan State University\n",
        ">College of Human Medicine\n",
        ">picotte1@pilot.msu.edu\n",
        ">\n",
        ">\n",
        "\n",
        "\n",
        " \n",
        "Top Terms:\n",
        "of 1.164\n",
        "edu 1.222\n",
        "pilot 24.590\n",
        "\n",
        "\n",
        "pred=0 (0.954435) truth=1 \n",
        "text=With a quartering\n",
        "headwind, turn the wheel towards the wind and pull back. \n",
        "Top Terms:\n",
        "wheel -17.430\n",
        "back -0.033\n",
        "towards 0.060\n",
        "the 0.133\n",
        "and 0.700\n",
        "wind 4.816\n",
        "\n"
       ]
      }
     ],
     "prompt_number": 61
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "##5. Other Datasets: Twitter \n",
      "\n",
      "We use tweets as the snippets for this dataset "
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "\n",
      "twitter, vct = load_data('twitter', TWITTER_DATA)\n",
      "\n",
      "expertl2 = exputil.get_classifier('lrl2', parameter=1)\n",
      "expertl1 = exputil.get_classifier('lr', parameter=1)\n",
      "\n",
      "expertl2.fit(twitter.train.bow, twitter.train.target)\n",
      "expertl1.fit(twitter.train.bow, twitter.train.target)\n",
      "\n",
      "sent_tk = exputil.get_tokenizer('tweets')\n",
      "\n",
      "## Get Test data ready\n",
      "test_docs = rnd.permutation(len(twitter.test.target))\n",
      "\n",
      "sent = sent_tk.tokenize_sents(twitter.test.data[test_docs[:n]])\n",
      "snippets, y_test = _sentences(sent, twitter.test.target[test_docs[:n]])\n",
      "x_test = vct.transform(snippets)\n",
      "\n",
      "print \"Number testing of documents:\", len(sent)\n",
      "print \"Number of sentences:\", len(snippets)\n",
      "print \"Number of features:\", x_test.shape[1]\n",
      "\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "\n",
      "terms = vct.get_feature_names()\n",
      "print \"Classes\", twitter.train.target_names\n",
      "print_top_terms(expertl2, np.array(terms))\n",
      "\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print_top_terms(expertl1, np.array(terms))\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print \"EXPERT L2\"\n",
      "error_analysis(expertl2, x_test, y_test, snippets, vct.get_feature_names(), sort=True)\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print \"EXPERT L1\"\n",
      "error_analysis(expertl1, x_test, y_test, snippets, vct.get_feature_names(), sort=True)\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "st = sent_tk.tokenize_sents(['I love flying. I use fs98', 'I have a chevy and it has been reliable. I am thinking of changing to a mini'])\n",
      "nips, lbs = _sentences(st, np.array([1,0]))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 66
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print st"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[['I love flying.', 'I use fs98'], ['I have a chevy and it has been reliable.', 'I am thinking of changing to a mini']]\n"
       ]
      }
     ],
     "prompt_number": 67
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print zip(nips, lbs)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[('I love flying.', 1), ('I use fs98', 1), ('I have a chevy and it has been reliable.', 0), ('I am thinking of changing to a mini', 0)]\n"
       ]
      }
     ],
     "prompt_number": 69
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "bw = vct.transform(nips)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 71
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "expertl2.predict(bw)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 72,
       "text": [
        "array([1, 1, 0, 0])"
       ]
      }
     ],
     "prompt_number": 72
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "expertl1.predict(bw)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 73,
       "text": [
        "array([1, 1, 0, 0])"
       ]
      }
     ],
     "prompt_number": 73
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "expertl2._classes"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "ename": "AttributeError",
       "evalue": "'LogisticRegression' object has no attribute '_classes'",
       "output_type": "pyerr",
       "traceback": [
        "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
        "\u001b[0;32m<ipython-input-74-203f78962ff4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mexpertl2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_classes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
        "\u001b[0;31mAttributeError\u001b[0m: 'LogisticRegression' object has no attribute '_classes'"
       ]
      }
     ],
     "prompt_number": 74
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "snippets[32:50]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 83,
       "text": [
        "[u'>> -= May the Downforce be with you...\\n>>\\n>> \"People think it must be fun to be a super genius, but they don\\'t realise\\n>> how hard it is to put up with all the idiots in the world.\"',\n",
        " u'>\\n\\n\\n',\n",
        " u'On 11 Dec 1998 19:59:18 GMT, xcr650@aol.com (XCR650) wrote:\\n\\n><< provided they have not\\n>  : conspired with other manufacturers to fix prices?>>\\n>\\n>\\n>  Who has proof that they havent?',\n",
        " u\"Lack of proof conveys innocence in the U.S.  No winks or grins,\\nthat;s the way it is and that's the way it should be.\\n\",\n",
        " u'Yes the bottom of the pedal base does come off (6 or so screws) - you should\\nhave sufficient access without remove the pedals themselves (2 screws per\\npedal) - as I have been able to change the springs without removing the\\npedals.',\n",
        " u'Whether compressed air is sufficient is open for debate - it may shift the\\ndirt, but electrical spray may be needed.',\n",
        " u'I have successfully used WD40 for other devices in the past, but I think\\nthis may cause dirt to cling due to its lubricant properties - no doubt\\nsomeone on this group will know the facts.',\n",
        " u'Cheers\\n\\nTony\\n\\nGraeme Nash wrote in message ...\\n>Hi,\\n>\\n>Firstly, many thanks to everyone who helped me out on my pedal problem\\n>that I posted earlier in the week.',\n",
        " u\">\\n>Anyhow, today I finally managed to get some electronics cleaner\\n>(compressed air) but I'm not sure how I go about cleaning the insides of\\n>my TM NASCAR Pro / Formula 1 setup.\",\n",
        " u'>\\n>Does the bottom come completely off?',\n",
        " u\"I had a go earlier and couldn't see\\n>any way for it to come off.\",\n",
        " u'If so, is there a really specific way for\\n>getting to the pedals?',\n",
        " u\">\\n>I've actually had a couple of trouble free days but today my problem has\\n>come back.\",\n",
        " u'The brake pedal has developed a life of its own and obviously\\n>needs some cleaning.',\n",
        " u'>\\n>Very grateful for any help,\\n>Graeme Nash\\n>\\n>GJNash@karisma1.demon.co.uk\\n>http://www.karisma1.demon.co.uk\\n>ICQ# 11257824\\n>\\n>1998 Xoom GP2 League Champion\\n\\n\\n',\n",
        " u'Peter B wrote:\\n\\n> Just do a full installation of GPL and you will not require the CD to play.',\n",
        " u'> Peter\\n\\nI have a full installation of GPL (British/European whatever version) and it\\nonly lets me\\nplay multiplayer games without the CD.',\n",
        " u'No Training, No racing against AI, No\\nview\\nreplays, just multiplayer.']"
       ]
      }
     ],
     "prompt_number": 83
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "y_test[32:50]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 84,
       "text": [
        "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])"
       ]
      }
     ],
     "prompt_number": 84
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print [len(x) for x in sent][:10]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[34, 2, 11, 4, 1, 11, 2, 11, 12, 25]\n"
       ]
      }
     ],
     "prompt_number": 82
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print 1. * sraa.train.target.sum() / sraa.train.target.shape[0]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "0.371702965963\n"
       ]
      }
     ],
     "prompt_number": 89
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "expertl1.classes_"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 91,
       "text": [
        "array([0, 1])"
       ]
      }
     ],
     "prompt_number": 91
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}