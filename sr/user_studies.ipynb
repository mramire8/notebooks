{
 "metadata": {
  "name": "",
  "signature": "sha256:739da2ba6ea66c6b54d05dbc6ba6a6fc492b241707670a8fda772b82eaba0df0"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# Structured Reading: User Studies\n",
      "\n",
      "## This Notebook\n",
      "\n",
      "The objective is to prepare the users studies data and test some configurations\n",
      "\n",
      "## Test Configuration\n",
      "\n",
      "* Set experiment\n",
      "* Load data\n",
      "* Select documents\n",
      "* Select snippets\n",
      "* Save data in a file"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "## Imports \n",
      "%matplotlib inline\n",
      "\n",
      "STRUCTURED = '/Users/maru/MyCode/structured'\n",
      "IMDB_DATA='/Users/maru/MyCode/data/imdb'\n",
      "SRAA_DATA='/Users/maru/MyCode/data/imdb'\n",
      "TWIITER_DATA = ''\n",
      "\n",
      "STRUCTURED = '../structured'\n",
      "IMDB_DATA = 'C:/Users/mramire8/Documents/Research/Oracle confidence and Interruption/dataset/aclImdb/raw-data'\n",
      "SRAA_DATA = 'C:/Users/mramire8/Documents/Research/Oracle confidence and Interruption/dataset/sraa/sraa/sraa/partition1/data'\n",
      "\n",
      "# STRUCTURED = '/Users/maru/My Code/structured'\n",
      "# IMDB_DATA='/Users/maru/Dataset/aclImdb'\n",
      "# SRAA_DATA='/Users/maru/Dataset/aviation/data'\n",
      "# TWIITER_DATA = '/Users/maru/Dataset/twitter'\n",
      "\n",
      "import sys\n",
      "import os\n",
      "sys.path.append(os.path.abspath(STRUCTURED))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import utilities.experimentutils as exputil\n",
      "import utilities.datautils as datautil\n",
      "import numpy as np\n",
      "import nltk\n",
      "from sklearn import metrics\n",
      "import matplotlib.pyplot as plt\n",
      "import matplotlib as mpl\n",
      "\n",
      "mpl.style.use('bmh')\n",
      "\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 2
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Loading Data\n",
      "vct = exputil.get_vectorizer({'vectorizer':\"tfidf\", 'limit':None, 'min_size':None})\n",
      "# Sentence tokenizers\n",
      "sent_tk = nltk.data.load('tokenizers/punkt/english.pickle')\n",
      "\n",
      "def load_data(dataname, path, categories=None):\n",
      "    import pickle\n",
      "\n",
      "    DATA_PKL = path + '/data.pkl'\n",
      "\n",
      "    if os.path.isfile(DATA_PKL):\n",
      "        vct, data = pickle.load(open(DATA_PKL, 'rb'))\n",
      "    else:\n",
      "        vct = exputil.get_vectorizer({'vectorizer':\"tfidf\", 'limit':None, 'min_size':None})\n",
      "        data = datautil.load_dataset(dataname, path, categories=categories, rnd=5463, shuffle=True)\n",
      "        data.train.data = np.array(data.train.data, dtype=object)\n",
      "        data.test.data = np.array(data.test.data, dtype=object)\n",
      "        data.train.bow = vct.fit_transform(data.train.data)\n",
      "        data.test.bow = vct.transform(data.test.data)\n",
      "#         pickle.dump((vct, data), open(DATA_PKL, 'wb'))\n",
      "\n",
      "    return data, vct\n",
      "\n",
      "\n",
      "\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 10
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Get the sentences for testing\n",
      "def _sentences(docs, doc_labels, sent_tk):\n",
      "    data = []\n",
      "    true_labels = []\n",
      "    sent = sent_tk.tokenize_sents(docs)\n",
      "    for sentences, doc_label in zip(sent, doc_labels):\n",
      "        data.extend(sentences)\n",
      "        true_labels.extend([doc_label] * len(sentences))\n",
      "    return data, np.array(true_labels)\n",
      "\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 4
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# select random snippets\n",
      "def select_random_snippets(data, rnd, sent_tk, n=1000):\n",
      "    rnd_docs = rnd.permutation(len(data.target))\n",
      "    docs_text = data.data[rnd_docs[:n]]\n",
      "    docs_lbl  = data.target[rnd_docs[:n]]\n",
      "    docs_sent = sent_tk.tokenize_sents(docs_text)\n",
      "    # docs_sents = _sentences(cost_text, docs_lbl, sent_tk)\n",
      "    rnd_st = np.random.RandomState(543210)\n",
      "    selected = []\n",
      "    for lbl, sents in zip(docs_lbl, docs_sent):\n",
      "        if len(sents) > 1:\n",
      "            picked = np.random.random_integers(len(sents)-1)\n",
      "        else:\n",
      "            picked = 0\n",
      "        selected.append(sents[picked])\n",
      "    return docs_text, docs_lbl, selected    \n",
      "\n",
      "# print snippets into a file\n",
      "def output_test(name, doc, lbl, snip):\n",
      "    file_name = \"./output/rnd_\" + name + \".txt\"\n",
      "    if not os.path.exists(\"./output/\"):\n",
      "        os.makedirs(\"./output\")\n",
      "    f = open(file_name, \"w\")\n",
      "    f.write(\"LABEL\\tSENT\\tDOC\\n\")\n",
      "    for a, b, c in zip(lbl, snip, doc):\n",
      "#         print \"{}\\t{}\\t{}\\n\".format(a, b, c)\n",
      "        f.write(\"{}\\t{}\\t{}\\n\".format(a, b.encode('utf-8'), c.encode('utf-8').replace(\"\\n\",\". \")))\n",
      "    f.close()\n",
      "\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 35
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# Create User Study Samples\n",
      "\n",
      "For all dataset we :\n",
      "\n",
      "* Load data\n",
      "* Sample 1k documents\n",
      "* Sample a random snippet per document\n",
      "* Save selected documents into a file"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Load the dataset\n",
      "imdb, vct = load_data('imdb', IMDB_DATA)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# get testing files for IMDB\n",
      "rnd = np.random.RandomState(2345)\n",
      "# Get the sampled snippets\n",
      "docs, lbl, snip = select_random_snippets(imdb.train, rnd, sent_tk, n=1000)\n",
      "output_test(\"imdb\", docs,lbl, snip)\n",
      "\n",
      "\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 42
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "\"this is a sentence.\\n This is the other sentence.\".replace(\"\\n\", \". \")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 35,
       "text": [
        "'this is a sentence..  This is the other sentence.'"
       ]
      }
     ],
     "prompt_number": 35
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Load the dataset\n",
      "rnd = np.random.RandomState(2345)\n",
      "sraa, vct = load_data('sraa', SRAA_DATA)\n",
      "docs, lbl, snip = select_random_snippets(sraa.train, rnd, sent_tk, n=1000)\n",
      "output_test2(\"sraa\", docs,lbl, snip)\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 221
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Load the dataset\n",
      "twitter, vct = load_data('twitter', TWITTER_DATA)\n",
      "tw_tk = exputil.get_tokenizer('tweets')\n",
      "docs, lbl, snip = select_random_snippets(twitter.train, rnd, tw_tk, n=1000)\n",
      "output_test(\"twitter\", docs,lbl, snip)\n",
      "\n",
      "\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 39
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Load the dataset\n",
      "rnd = np.random.RandomState(2345)\n",
      "hardw, vct = load_data('20news', \"\", categories='hardware')\n",
      "docs, lbl, snip = select_random_snippets(hardw.train, rnd, sent_tk, n=1000)\n",
      "output_test(\"hardware20ng\", docs,lbl, snip)\n",
      "\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 11
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "output_test2(\"hardware20ng_v2\", docs,lbl, snip)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 36
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# User Labeled Data"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Testing Models on User Study Data: IMDB\n",
      "\n",
      "* Load documents\n",
      "* Train expert\n",
      "* Test expert on documents\n",
      "\n",
      "We train the expert on the test split so it does not see the snippets used for the study. The models are L1 and L2 with various values of C penalty. \n",
      "\n",
      "Threshold for neutral values is set manually. We tested T=.4 and .35"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def load_study(filename):\n",
      "    f = open(filename)\n",
      "    with f:\n",
      "        lines = f.readlines() \n",
      "    data =  [l.strip().split(\"\\t\") for l in lines[1:]] #discard first line\n",
      "    data = np.array(data, dtype=object)\n",
      "    return data\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 13
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "imdb, vct = load_data('imdb', IMDB_DATA)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 45
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Get the snippets from the saved file\n",
      "docs_study = load_study('./output/rnd_imdb.txt')\n",
      "lbl = [float(d[0]) for d in docs_study]\n",
      "snippets = [d[1] for d in docs_study]\n",
      "snip_bow = vct.transform(snippets)\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 57
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#Get Human oracle labels\n",
      "f = open(\"./output/user1_rnd_imdb_labels.txt\")\n",
      "user_labels = np.loadtxt(f)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 81
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "## Get the expert data and snippets\n",
      "exp_sent, exp_lbl = _sentences(imdb.test.data, imdb.test.target, sent_tk)\n",
      "exp_sent_bow = vct.transform(exp_sent)\n",
      "print \"Sentences:\", len(exp_sent), len(exp_lbl)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Sentences: 265781 265781\n"
       ]
      }
     ],
     "prompt_number": 60
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from collections import defaultdict\n",
      "\n",
      "def neutral_label(threshold, p, lbl):\n",
      "    ''' Labels are $\\{0, 1, 2\\}$ where 2 is neutral ''' \n",
      "    return lbl if (1 - p.max()) < threshold else 2\n",
      "\n",
      "def test_parameters(clf_str, C, data, threshold, name=\"noname\"):\n",
      "    # print predicted values of the expert on the study snippets\n",
      "    print \"Parameters for %s and T > %s\" %(clf_str, threshold)\n",
      "    results = defaultdict(lambda: [])\n",
      "    for c in C: \n",
      "        print \"Testing ... C=\", c\n",
      "#         expert = exputil.get_classifier('lrl2', parameter=c)\n",
      "        expert = eval(clf_str.format(c))\n",
      "        expert.fit(data['bow'], data['target'])\n",
      "        pred = expert.predict(snip_bow)\n",
      "        prob = expert.predict_proba(snip_bow)\n",
      "        results[c] = [neutral_label(threshold, p, t) for t, p in zip(pred,prob)]\n",
      "    return results\n",
      "\n",
      "def print_results(results, C, name=\"noname\"):\n",
      "    print \"\\t\".join(\"{}-C={}\".format(name, k) for k in results.keys())\n",
      "    for i in range(len(results[C[0]])):\n",
      "        print \"\\t\".join(\"{}\".format(results[c][i]) for c in C)\n",
      "\n",
      "        \n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 215
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "## See test predictions \n",
      "print_results(results, C)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "noname-C=1\tnoname-C=10\tnoname-C=100\tnoname-C=0.1\tnoname-C=0.01\n",
        "2\t2\t0\t0\t2\n",
        "2\t2\t2\t2\t2\n",
        "0\t0\t0\t0\t0\n",
        "2\t0\t0\t0\t0\n",
        "2\t2\t1\t1\t1\n",
        "2\t1\t1\t1\t1\n",
        "1\t1\t1\t1\t1\n",
        "2\t2\t1\t1\t1\n",
        "2\t1\t1\t2\t2\n",
        "2\t2\t0\t0\t0\n",
        "0\t0\t0\t0\t0\n",
        "0\t0\t0\t0\t0\n",
        "2\t2\t0\t0\t0\n",
        "2\t2\t2\t2\t2\n",
        "2\t2\t1\t1\t1\n",
        "1\t1\t1\t1\t1\n",
        "2\t1\t2\t0\t0\n",
        "2\t2\t2\t2\t2\n",
        "2\t2\t2\t2\t2\n",
        "2\t0\t0\t0\t0\n",
        "0\t0\t0\t0\t0\n",
        "2\t1\t1\t1\t1\n",
        "0\t0\t0\t0\t0\n",
        "0\t0\t0\t0\t0\n",
        "1\t1\t1\t1\t1\n",
        "2\t2\t1\t1\t2\n",
        "2\t2\t2\t1\t1\n",
        "0\t0\t0\t0\t0\n",
        "2\t1\t1\t1\t1\n",
        "2\t2\t2\t1\t1\n",
        "2\t0\t0\t0\t0\n",
        "2\t2\t2\t2\t2\n",
        "2\t0\t0\t0\t0\n",
        "2\t1\t1\t0\t0\n",
        "0\t0\t0\t0\t0\n",
        "2\t2\t2\t0\t0\n",
        "1\t1\t1\t1\t1\n",
        "2\t2\t1\t1\t1\n",
        "2\t0\t0\t0\t0\n",
        "0\t0\t0\t0\t0\n",
        "1\t1\t1\t1\t1\n",
        "2\t2\t0\t0\t0\n",
        "2\t1\t1\t1\t1\n",
        "2\t1\t1\t2\t2\n",
        "2\t2\t2\t0\t0\n",
        "2\t0\t0\t0\t0\n",
        "1\t1\t1\t1\t1\n",
        "2\t2\t1\t1\t1\n",
        "2\t0\t0\t0\t0\n",
        "2\t2\t2\t2\t2\n",
        "2\t2\t0\t2\t1\n",
        "2\t2\t2\t2\t1\n",
        "2\t1\t1\t1\t1\n",
        "2\t1\t1\t1\t1\n",
        "2\t2\t2\t2\t0\n",
        "0\t0\t0\t0\t0\n",
        "2\t2\t2\t2\t0\n",
        "2\t0\t2\t1\t1\n",
        "2\t1\t1\t1\t1\n",
        "2\t2\t2\t2\t2\n",
        "2\t2\t2\t2\t2\n",
        "2\t2\t1\t1\t1\n",
        "2\t0\t0\t0\t0\n",
        "2\t1\t1\t1\t1\n",
        "2\t1\t1\t1\t1\n",
        "2\t2\t0\t0\t0\n",
        "0\t0\t0\t0\t0\n",
        "2\t0\t0\t0\t0\n",
        "2\t1\t1\t1\t1\n",
        "2\t2\t2\t2\t2\n",
        "2\t1\t1\t1\t1\n",
        "2\t0\t0\t0\t0\n",
        "2\t1\t1\t1\t1\n",
        "0\t0\t0\t0\t0\n",
        "2\t2\t2\t0\t0\n",
        "2\t1\t1\t1\t1\n",
        "0\t0\t0\t1\t1\n",
        "2\t2\t0\t0\t0\n",
        "2\t2\t2\t2\t2\n",
        "2\t2\t2\t2\t2\n",
        "2\t2\t1\t1\t1\n",
        "2\t2\t2\t2\t1\n",
        "1\t1\t1\t1\t1\n",
        "2\t2\t1\t1\t1\n",
        "2\t2\t2\t2\t2\n",
        "2\t2\t0\t0\t0\n",
        "0\t0\t0\t0\t0\n",
        "0\t0\t0\t0\t0\n",
        "2\t0\t0\t0\t0\n",
        "2\t2\t1\t1\t1\n",
        "0\t0\t0\t0\t0\n",
        "0\t0\t0\t0\t0\n",
        "2\t2\t2\t2\t0\n",
        "1\t1\t1\t1\t2\n",
        "2\t1\t1\t1\t1\n",
        "2\t1\t2\t2\t2\n",
        "0\t0\t0\t0\t0\n",
        "2\t2\t2\t1\t1\n",
        "2\t2\t1\t1\t1\n",
        "2\t2\t2\t2\t1\n",
        "0\t0\t0\t0\t0\n",
        "2\t0\t0\t0\t0\n",
        "2\t0\t2\t1\t1\n",
        "2\t2\t1\t1\t1\n",
        "1\t1\t1\t1\t1\n",
        "2\t0\t0\t0\t0\n",
        "2\t0\t0\t0\t0\n",
        "1\t1\t1\t1\t1\n",
        "2\t2\t1\t1\t1\n",
        "1\t1\t1\t1\t1\n",
        "2\t0\t0\t0\t0\n",
        "0\t0\t0\t0\t0\n",
        "2\t2\t2\t2\t2\n",
        "2\t0\t2\t1\t1\n",
        "0\t0\t0\t0\t0\n",
        "2\t1\t1\t1\t1\n",
        "2\t2\t2\t2\t2\n",
        "2\t0\t0\t0\t0\n",
        "2\t1\t1\t1\t1\n",
        "2\t0\t2\t1\t1\n",
        "2\t1\t1\t1\t1\n",
        "1\t1\t1\t1\t1\n",
        "2\t2\t0\t0\t0\n",
        "2\t2\t2\t2\t0\n",
        "0\t0\t0\t0\t0\n",
        "1\t1\t1\t1\t1\n",
        "2\t2\t2\t2\t2\n",
        "2\t2\t2\t1\t1\n",
        "2\t2\t0\t0\t0\n",
        "0\t0\t0\t0\t0\n",
        "2\t1\t1\t1\t1\n",
        "2\t2\t2\t2\t2\n",
        "2\t2\t2\t0\t0\n",
        "2\t0\t0\t0\t0\n",
        "2\t2\t2\t0\t0\n",
        "2\t1\t1\t1\t1\n",
        "0\t0\t0\t0\t0\n",
        "1\t1\t1\t1\t1\n",
        "2\t2\t0\t2\t1\n",
        "2\t1\t1\t1\t1\n",
        "2\t1\t1\t1\t1\n",
        "2\t2\t2\t2\t0\n",
        "2\t1\t1\t1\t1\n",
        "2\t1\t1\t2\t0\n",
        "2\t2\t2\t0\t0\n",
        "2\t1\t1\t1\t1\n",
        "2\t1\t1\t2\t0\n",
        "2\t2\t2\t2\t2\n",
        "2\t0\t0\t0\t0\n",
        "2\t0\t0\t1\t1\n",
        "2\t2\t2\t2\t2\n",
        "2\t2\t2\t2\t2\n",
        "0\t0\t0\t2\t1\n",
        "0\t0\t0\t0\t0\n",
        "2\t0\t0\t0\t2\n",
        "2\t0\t0\t0\t0\n",
        "2\t0\t0\t0\t0\n",
        "2\t0\t0\t0\t0\n",
        "2\t2\t2\t1\t1\n",
        "2\t2\t0\t0\t0\n",
        "2\t2\t2\t0\t0\n",
        "2\t0\t0\t0\t0\n",
        "2\t2\t2\t2\t2\n",
        "0\t0\t0\t0\t0\n",
        "0\t0\t0\t0\t0\n",
        "2\t2\t0\t0\t0\n",
        "2\t2\t2\t2\t0\n",
        "1\t1\t1\t1\t1\n",
        "0\t0\t0\t0\t0\n",
        "1\t1\t1\t1\t1\n",
        "2\t2\t2\t2\t2\n",
        "2\t2\t1\t1\t1\n",
        "2\t1\t1\t1\t1\n",
        "2\t0\t0\t0\t0\n",
        "2\t0\t0\t0\t0\n",
        "2\t2\t2\t2\t2\n",
        "2\t1\t1\t1\t1\n",
        "2\t1\t1\t1\t1\n",
        "2\t1\t1\t1\t1\n",
        "2\t1\t1\t1\t1\n",
        "2\t2\t0\t0\t0\n",
        "2\t1\t1\t1\t1\n",
        "2\t2\t2\t2\t2\n",
        "2\t0\t0\t0\t0\n",
        "2\t1\t1\t1\t1\n",
        "1\t1\t1\t1\t1\n",
        "2\t1\t1\t1\t1\n",
        "2\t2\t0\t0\t0\n",
        "2\t0\t2\t1\t1\n",
        "2\t2\t2\t2\t0\n",
        "2\t0\t0\t2\t2\n",
        "2\t2\t1\t1\t1\n",
        "2\t1\t1\t1\t1\n",
        "1\t1\t1\t1\t1\n",
        "2\t0\t0\t0\t0\n",
        "2\t1\t1\t1\t1\n",
        "2\t2\t0\t0\t0\n",
        "2\t0\t0\t0\t0\n",
        "2\t1\t1\t0\t0\n",
        "2\t2\t1\t1\t1\n",
        "2\t0\t0\t0\t0\n",
        "2\t2\t2\t2\t2\n",
        "2\t1\t1\t1\t1\n",
        "2\t2\t0\t0\t0\n",
        "2\t2\t2\t2\t0\n",
        "2\t2\t1\t1\t1\n",
        "2\t0\t0\t0\t0\n",
        "2\t2\t0\t0\t0\n",
        "0\t0\t0\t0\t0\n",
        "2\t2\t2\t1\t1\n",
        "2\t0\t2\t2\t1\n",
        "2\t0\t0\t0\t0\n",
        "2\t0\t0\t0\t0\n",
        "2\t2\t2\t2\t2\n",
        "2\t2\t2\t2\t1\n",
        "1\t1\t1\t1\t1\n",
        "2\t1\t1\t2\t2\n",
        "2\t1\t1\t2\t0\n",
        "2\t2\t0\t0\t0\n",
        "0\t0\t2\t2\t2\n",
        "2\t2\t1\t1\t1\n",
        "2\t1\t1\t1\t1\n",
        "2\t1\t2\t2\t2\n",
        "2\t0\t0\t0\t0\n",
        "2\t1\t1\t1\t1\n",
        "2\t2\t0\t0\t0\n",
        "2\t2\t2\t2\t1\n",
        "2\t2\t0\t0\t0\n",
        "2\t1\t1\t1\t1\n",
        "2\t2\t1\t1\t1\n",
        "2\t1\t1\t1\t1\n",
        "2\t2\t2\t2\t2\n",
        "2\t2\t2\t0\t0\n",
        "0\t0\t0\t2\t2\n",
        "2\t2\t2\t2\t2\n",
        "2\t1\t1\t1\t1\n",
        "2\t1\t1\t1\t1\n",
        "2\t2\t2\t1\t1\n",
        "2\t0\t0\t0\t0\n",
        "0\t0\t0\t0\t0\n",
        "0\t0\t0\t0\t0\n",
        "2\t2\t2\t2\t2\n",
        "2\t2\t2\t1\t1\n",
        "2\t2\t2\t2\t2\n",
        "2\t0\t0\t0\t0\n",
        "2\t2\t2\t1\t1\n",
        "2\t1\t2\t2\t2\n",
        "2\t0\t0\t0\t0\n",
        "0\t0\t0\t0\t0\n",
        "0\t0\t0\t0\t0\n",
        "0\t0\t0\t0\t0\n",
        "2\t2\t2\t2\t2\n",
        "0\t0\t0\t0\t0\n",
        "2\t2\t2\t2\t1\n",
        "2\t2\t0\t0\t0\n",
        "2\t2\t0\t2\t1\n",
        "2\t0\t0\t0\t0\n",
        "2\t2\t0\t0\t0\n",
        "1\t1\t1\t1\t1\n",
        "0\t0\t0\t2\t2\n",
        "2\t2\t1\t2\t2\n",
        "2\t1\t1\t1\t1\n",
        "0\t0\t0\t0\t0\n",
        "2\t1\t1\t1\t1\n",
        "2\t2\t2\t2\t0\n",
        "2\t1\t1\t1\t1\n",
        "2\t2\t1\t1\t0\n",
        "2\t1\t1\t1\t1\n",
        "2\t0\t0\t2\t2\n",
        "2\t2\t2\t2\t1\n",
        "0\t0\t0\t0\t0\n",
        "2\t2\t0\t0\t0\n",
        "2\t0\t0\t0\t0\n",
        "2\t0\t0\t0\t0\n",
        "2\t0\t0\t0\t0\n",
        "1\t1\t1\t1\t1\n",
        "2\t2\t2\t2\t2\n",
        "2\t0\t0\t0\t0\n",
        "2\t2\t2\t0\t0\n",
        "2\t1\t1\t1\t1\n",
        "0\t0\t0\t0\t0\n",
        "0\t0\t0\t0\t0\n",
        "2\t1\t1\t1\t1\n",
        "2\t2\t2\t2\t2\n",
        "2\t0\t0\t0\t2\n",
        "2\t1\t1\t1\t1\n",
        "0\t0\t0\t0\t0\n",
        "2\t2\t0\t0\t0\n",
        "2\t1\t1\t1\t1\n",
        "2\t0\t0\t0\t0\n",
        "2\t1\t1\t1\t1\n",
        "2\t2\t0\t0\t0\n",
        "0\t0\t0\t0\t0\n",
        "2\t0\t0\t0\t0\n",
        "2\t2\t2\t2\t2\n",
        "0\t0\t2\t2\t2\n",
        "0\t0\t0\t0\t0\n",
        "1\t1\t1\t1\t1\n",
        "2\t1\t1\t1\t1\n",
        "2\t2\t1\t1\t1\n",
        "0\t0\t0\t0\t0\n",
        "2\t2\t1\t1\t1\n",
        "2\t2\t2\t2\t0\n",
        "2\t2\t2\t0\t0\n",
        "2\t1\t1\t2\t2\n",
        "2\t2\t1\t1\t1\n",
        "0\t0\t0\t0\t0\n",
        "2\t1\t2\t0\t0\n",
        "0\t0\t0\t0\t0\n",
        "2\t2\t2\t2\t2\n",
        "2\t1\t1\t1\t2\n",
        "2\t0\t0\t2\t2\n",
        "1\t1\t1\t1\t1\n",
        "2\t2\t2\t2\t2\n",
        "2\t1\t1\t1\t1\n",
        "0\t0\t0\t0\t0\n",
        "2\t2\t2\t2\t0\n",
        "2\t1\t1\t1\t1\n",
        "2\t2\t1\t1\t1\n",
        "1\t1\t1\t1\t1\n",
        "2\t0\t0\t0\t0\n",
        "0\t0\t2\t2\t2\n",
        "2\t1\t1\t1\t1\n",
        "2\t2\t2\t2\t2\n",
        "2\t2\t2\t2\t1\n",
        "2\t0\t0\t0\t0\n",
        "2\t2\t2\t2\t2\n",
        "1\t1\t1\t2\t2\n",
        "1\t1\t1\t1\t1\n",
        "0\t0\t0\t0\t0\n",
        "2\t2\t2\t2\t0\n",
        "0\t0\t0\t0\t0\n",
        "2\t2\t2\t2\t2\n",
        "2\t2\t0\t0\t0\n",
        "2\t0\t0\t0\t0\n",
        "1\t1\t1\t1\t1\n",
        "2\t0\t0\t2\t2\n",
        "1\t1\t1\t1\t1\n",
        "2\t0\t0\t2\t2\n",
        "2\t1\t1\t1\t1\n",
        "2\t1\t1\t1\t1\n",
        "2\t1\t1\t1\t1\n",
        "2\t2\t0\t2\t1\n",
        "2\t2\t0\t2\t2\n",
        "2\t1\t1\t1\t1\n",
        "0\t0\t0\t0\t0\n",
        "2\t2\t2\t1\t1\n",
        "1\t1\t1\t1\t1\n",
        "2\t2\t0\t0\t0\n",
        "2\t0\t0\t0\t0\n",
        "2\t1\t1\t1\t1\n",
        "0\t0\t0\t2\t2\n",
        "2\t0\t0\t0\t0\n",
        "2\t2\t2\t2\t2\n",
        "2\t0\t0\t0\t0\n",
        "0\t0\t0\t0\t0\n",
        "0\t0\t0\t0\t0\n",
        "2\t0\t0\t0\t0\n",
        "2\t2\t1\t1\t2\n",
        "0\t0\t0\t0\t0\n",
        "2\t2\t0\t0\t0\n",
        "2\t2\t1\t1\t1\n",
        "0\t0\t0\t0\t0\n",
        "2\t2\t0\t2\t2\n",
        "2\t0\t0\t0\t0\n",
        "2\t2\t2\t0\t0\n",
        "2\t2\t2\t0\t0\n",
        "2\t1\t1\t1\t1\n",
        "2\t0\t0\t0\t0\n",
        "1\t1\t1\t1\t1\n",
        "2\t2\t2\t2\t2\n",
        "0\t0\t0\t0\t0\n",
        "2\t1\t1\t2\t0\n",
        "0\t0\t0\t0\t0\n",
        "2\t1\t1\t1\t1\n",
        "2\t1\t1\t1\t1\n",
        "2\t0\t0\t0\t0\n",
        "2\t0\t0\t2\t2\n",
        "0\t0\t0\t0\t0\n",
        "0\t0\t0\t0\t0\n",
        "1\t1\t1\t1\t1\n",
        "2\t0\t2\t2\t2\n",
        "2\t1\t1\t1\t1\n",
        "2\t2\t1\t1\t1\n",
        "2\t1\t1\t1\t1\n",
        "2\t2\t2\t2\t2\n",
        "2\t0\t0\t0\t0\n",
        "2\t2\t2\t2\t2\n",
        "2\t2\t1\t1\t1\n",
        "1\t1\t1\t1\t1\n",
        "2\t2\t2\t0\t0\n",
        "2\t2\t2\t1\t1\n",
        "2\t1\t1\t1\t1\n",
        "2\t0\t0\t0\t0\n",
        "2\t2\t0\t0\t0\n",
        "2\t2\t2\t2\t2\n",
        "2\t2\t2\t2\t0\n",
        "0\t0\t0\t0\t0\n",
        "2\t0\t0\t0\t0\n",
        "2\t0\t0\t0\t0\n",
        "0\t0\t0\t0\t0\n",
        "2\t0\t0\t0\t0\n",
        "1\t1\t1\t1\t1\n",
        "2\t1\t1\t1\t1\n",
        "2\t0\t0\t0\t0\n",
        "2\t1\t1\t1\t1\n",
        "0\t0\t0\t0\t0\n",
        "2\t1\t1\t1\t1\n",
        "0\t0\t0\t0\t0\n",
        "2\t0\t0\t1\t1\n",
        "0\t0\t0\t0\t0\n",
        "1\t1\t1\t1\t1\n",
        "0\t0\t0\t0\t0\n",
        "2\t2\t0\t0\t0\n",
        "2\t2\t2\t2\t2\n",
        "2\t2\t0\t0\t0\n",
        "1\t1\t1\t1\t1\n",
        "2\t1\t1\t2\t2\n",
        "2\t1\t1\t1\t1\n",
        "1\t1\t1\t1\t1\n",
        "2\t0\t0\t0\t0\n",
        "2\t2\t1\t1\t1\n",
        "2\t1\t1\t2\t2\n",
        "1\t1\t1\t1\t1\n",
        "0\t0\t0\t0\t0\n",
        "2\t2\t0\t0\t0\n",
        "2\t2\t2\t2\t2\n",
        "2\t1\t1\t1\t1\n",
        "2\t0\t0\t0\t0\n",
        "2\t2\t1\t1\t1\n",
        "1\t1\t1\t1\t1\n",
        "0\t0\t0\t0\t0\n",
        "2\t1\t1\t1\t1\n",
        "2\t2\t1\t1\t1\n",
        "2\t2\t2\t0\t0\n",
        "2\t2\t2\t2\t2\n",
        "2\t2\t2\t2\t2\n",
        "2\t1\t1\t1\t1\n",
        "2\t0\t0\t0\t0\n",
        "2\t2\t1\t1\t1\n",
        "2\t0\t0\t2\t2\n",
        "2\t2\t0\t0\t0\n",
        "2\t2\t2\t2\t2\n",
        "0\t0\t0\t0\t0\n",
        "2\t2\t0\t0\t0\n",
        "2\t2\t1\t1\t1\n",
        "0\t0\t0\t0\t0\n",
        "2\t1\t1\t1\t1\n",
        "0\t0\t0\t0\t0\n",
        "2\t1\t1\t1\t1\n",
        "2\t0\t0\t0\t0\n",
        "2\t2\t0\t0\t0\n",
        "0\t0\t0\t0\t0\n",
        "0\t0\t0\t0\t0\n",
        "2\t2\t2\t1\t1\n",
        "2\t2\t2\t2\t2\n",
        "2\t0\t0\t0\t0\n",
        "2\t2\t2\t2\t2\n",
        "2\t0\t0\t0\t0\n",
        "2\t2\t0\t0\t0\n",
        "1\t1\t1\t1\t1\n",
        "0\t0\t0\t0\t0\n",
        "0\t0\t0\t0\t0\n",
        "1\t1\t1\t1\t1\n",
        "2\t2\t2\t2\t2\n",
        "2\t2\t0\t0\t0\n",
        "2\t1\t2\t0\t0\n",
        "2\t2\t2\t2\t1\n",
        "2\t0\t0\t0\t0\n",
        "0\t0\t0\t0\t0\n",
        "2\t2\t2\t2\t2\n",
        "2\t1\t1\t1\t1\n",
        "1\t1\t1\t1\t1\n",
        "2\t1\t1\t1\t1\n",
        "2\t2\t2\t2\t2\n",
        "2\t2\t0\t0\t0\n",
        "2\t2\t2\t2\t1\n",
        "1\t1\t1\t1\t1\n",
        "2\t2\t1\t1\t1\n",
        "2\t1\t1\t1\t1\n",
        "1\t1\t1\t1\t1\n",
        "2\t2\t1\t1\t1\n",
        "2\t0\t0\t0\t0\n",
        "2\t2\t2\t0\t0\n",
        "2\t2\t1\t1\t1\n",
        "2\t2\t2\t2\t0\n",
        "0\t0\t0\t0\t0\n",
        "2\t2\t1\t1\t1\n",
        "2\t2\t1\t1\t1\n",
        "2\t1\t1\t1\t1\n",
        "2\t2\t0\t0\t0\n",
        "2\t1\t1\t1\t1\n",
        "2\t0\t0\t2\t2\n",
        "2\t2\t0\t0\t0\n",
        "0\t0\t0\t0\t0\n",
        "2\t1\t1\t1\t1\n",
        "2\t2\t2\t2\t0\n",
        "2\t0\t0\t0\t0\n",
        "0\t0\t0\t0\t0\n",
        "2\t0\t0\t2\t1\n",
        "2\t2\t0\t0\t0\n",
        "2\t1\t1\t1\t1\n",
        "2\t0\t0\t0\t0\n",
        "2\t2\t2\t0\t0\n",
        "1\t1\t1\t1\t1\n",
        "2\t0\t0\t0\t0\n",
        "2\t0\t0\t0\t2\n",
        "2\t1\t2\t0\t0\n",
        "2\t1\t1\t1\t1\n",
        "2\t0\t0\t0\t0\n",
        "2\t2\t2\t2\t2\n",
        "0\t0\t0\t0\t0\n",
        "2\t2\t2\t0\t0\n",
        "2\t0\t0\t0\t0\n",
        "2\t2\t2\t0\t0\n",
        "2\t1\t1\t2\t0\n",
        "2\t2\t0\t0\t2\n",
        "0\t0\t0\t0\t0\n",
        "2\t1\t1\t1\t1\n",
        "1\t1\t1\t1\t1\n",
        "2\t2\t0\t0\t0\n",
        "2\t2\t0\t0\t0\n",
        "2\t1\t1\t2\t2\n",
        "2\t2\t2\t2\t2\n",
        "2\t0\t0\t0\t0\n",
        "2\t1\t1\t1\t1\n",
        "2\t2\t2\t2\t2\n",
        "2\t2\t2\t2\t2\n",
        "2\t2\t2\t0\t0\n",
        "0\t0\t0\t0\t0\n",
        "2\t2\t2\t0\t0\n",
        "2\t0\t0\t0\t0\n",
        "2\t1\t1\t1\t1\n",
        "0\t0\t0\t0\t0\n",
        "2\t2\t2\t1\t1\n",
        "2\t2\t1\t1\t1\n",
        "2\t2\t2\t2\t2\n",
        "2\t2\t1\t1\t1\n",
        "2\t0\t0\t0\t0\n",
        "1\t1\t1\t1\t1\n",
        "0\t0\t0\t0\t0\n",
        "2\t1\t1\t1\t1\n",
        "2\t0\t0\t0\t0\n",
        "1\t1\t1\t1\t1\n",
        "0\t0\t0\t0\t0\n",
        "2\t1\t1\t1\t1\n",
        "1\t1\t1\t1\t1\n",
        "2\t2\t1\t1\t1\n",
        "2\t2\t2\t2\t2\n",
        "2\t2\t0\t0\t0\n",
        "2\t2\t2\t1\t1\n",
        "0\t0\t0\t0\t0\n",
        "2\t1\t1\t1\t1\n",
        "2\t2\t0\t0\t0\n",
        "2\t0\t0\t0\t0\n",
        "2\t2\t2\t2\t2\n",
        "1\t1\t1\t1\t1\n",
        "2\t2\t2\t2\t0\n",
        "2\t1\t1\t1\t1\n",
        "2\t2\t2\t1\t1\n",
        "2\t1\t1\t1\t1\n",
        "2\t2\t0\t0\t0\n",
        "2\t2\t2\t2\t2\n",
        "2\t2\t2\t0\t0\n",
        "2\t2\t0\t0\t0\n",
        "0\t0\t0\t0\t0\n",
        "2\t2\t2\t2\t0\n",
        "2\t2\t2\t2\t2\n",
        "2\t1\t1\t1\t1\n",
        "2\t1\t1\t1\t1\n",
        "2\t2\t2\t1\t1\n",
        "2\t1\t1\t1\t1\n",
        "2\t1\t1\t1\t1\n",
        "2\t1\t1\t1\t1\n",
        "0\t0\t0\t0\t0\n",
        "2\t2\t2\t2\t2\n",
        "2\t1\t1\t2\t0\n",
        "2\t0\t0\t0\t0\n",
        "0\t0\t0\t0\t0\n",
        "2\t2\t1\t1\t1\n",
        "0\t0\t0\t0\t0\n",
        "2\t1\t1\t1\t1\n",
        "2\t1\t1\t1\t1\n",
        "2\t0\t0\t0\t0\n",
        "2\t0\t0\t0\t0\n",
        "1\t1\t1\t1\t1\n",
        "0\t0\t0\t0\t0\n",
        "2\t0\t0\t0\t0\n",
        "0\t0\t0\t0\t0\n",
        "2\t2\t1\t2\t0\n",
        "2\t0\t0\t0\t0\n",
        "1\t1\t1\t1\t1\n",
        "2\t2\t0\t0\t0\n",
        "0\t0\t0\t0\t0\n",
        "2\t2\t2\t2\t2\n",
        "2\t0\t0\t2\t1\n",
        "0\t0\t0\t0\t0\n",
        "2\t2\t2\t1\t1\n",
        "2\t2\t0\t0\t0\n",
        "2\t2\t2\t2\t2\n",
        "2\t2\t2\t2\t2\n",
        "2\t2\t2\t2\t2\n",
        "2\t1\t1\t2\t2\n",
        "1\t1\t1\t1\t1\n",
        "2\t0\t0\t0\t0\n",
        "2\t1\t1\t1\t1\n",
        "0\t0\t0\t0\t0\n",
        "2\t1\t1\t1\t1\n",
        "2\t0\t0\t0\t0\n",
        "2\t1\t2\t2\t2\n",
        "2\t2\t2\t2\t0\n",
        "2\t2\t1\t1\t1\n",
        "2\t1\t1\t1\t1\n",
        "2\t2\t2\t2\t2\n",
        "1\t1\t1\t1\t1\n",
        "2\t2\t2\t2\t2\n",
        "2\t1\t1\t1\t1\n",
        "2\t2\t0\t0\t0\n",
        "1\t1\t1\t1\t1\n",
        "2\t1\t1\t1\t1\n",
        "2\t2\t2\t2\t2\n",
        "2\t2\t2\t2\t2\n",
        "2\t1\t1\t1\t1\n",
        "0\t0\t0\t0\t0\n",
        "2\t0\t0\t0\t0\n",
        "0\t0\t0\t0\t0\n",
        "2\t2\t0\t0\t0\n",
        "0\t0\t0\t0\t0\n",
        "2\t0\t0\t0\t0\n",
        "1\t1\t1\t1\t1\n",
        "2\t0\t0\t0\t0\n",
        "2\t0\t0\t0\t0\n",
        "2\t2\t2\t2\t2\n",
        "2\t2\t2\t1\t1\n",
        "2\t1\t2\t2\t2\n",
        "2\t0\t0\t0\t0\n",
        "2\t2\t0\t2\t2\n",
        "2\t1\t1\t1\t1\n",
        "1\t1\t1\t1\t1\n",
        "2\t0\t0\t0\t2\n",
        "2\t0\t0\t0\t0\n",
        "2\t2\t2\t2\t2\n",
        "2\t0\t0\t0\t0\n",
        "0\t0\t0\t0\t0\n",
        "2\t1\t1\t1\t2\n",
        "2\t2\t2\t2\t2\n",
        "2\t2\t1\t2\t0\n",
        "2\t2\t1\t1\t1\n",
        "2\t1\t1\t1\t1\n",
        "2\t2\t2\t2\t0\n",
        "0\t0\t0\t0\t0\n",
        "0\t0\t0\t0\t0\n",
        "0\t0\t0\t0\t0\n",
        "2\t2\t1\t1\t1\n",
        "2\t2\t0\t0\t0\n",
        "2\t2\t0\t0\t0\n",
        "2\t2\t2\t0\t0\n",
        "2\t2\t2\t2\t1\n",
        "2\t0\t0\t0\t0\n",
        "2\t2\t0\t0\t0\n",
        "2\t2\t2\t1\t1\n",
        "2\t0\t0\t0\t0\n",
        "2\t0\t0\t0\t0\n",
        "1\t1\t1\t2\t2\n",
        "2\t0\t2\t1\t1\n",
        "0\t0\t0\t0\t0\n",
        "2\t2\t2\t1\t1\n",
        "2\t2\t0\t0\t0\n",
        "2\t0\t0\t0\t0\n",
        "0\t0\t0\t0\t0\n",
        "0\t0\t0\t0\t0\n",
        "2\t1\t1\t1\t1\n",
        "0\t0\t0\t0\t0\n",
        "2\t2\t2\t2\t2\n",
        "1\t1\t1\t1\t1\n",
        "2\t2\t2\t2\t2\n",
        "2\t2\t0\t0\t0\n",
        "2\t1\t1\t1\t1\n",
        "2\t2\t1\t1\t1\n",
        "2\t2\t1\t1\t1\n",
        "2\t2\t2\t0\t0\n",
        "2\t1\t1\t1\t1\n",
        "2\t0\t0\t0\t0\n",
        "2\t2\t0\t0\t0\n",
        "2\t1\t1\t1\t1\n",
        "2\t2\t2\t2\t1\n",
        "2\t1\t1\t1\t1\n",
        "2\t0\t0\t0\t0\n",
        "2\t2\t2\t2\t2\n",
        "2\t1\t1\t1\t1\n",
        "2\t2\t1\t2\t2\n",
        "2\t2\t2\t0\t0\n",
        "2\t1\t1\t1\t1\n",
        "1\t1\t1\t1\t1\n",
        "2\t1\t1\t1\t1\n",
        "2\t1\t1\t1\t1\n",
        "2\t2\t2\t2\t2\n",
        "1\t1\t1\t1\t1\n",
        "2\t0\t2\t2\t2\n",
        "2\t1\t1\t2\t2\n",
        "2\t2\t0\t0\t0\n",
        "2\t2\t2\t2\t2\n",
        "2\t2\t2\t0\t0\n",
        "2\t2\t2\t2\t2\n",
        "0\t0\t0\t0\t0\n",
        "2\t2\t2\t1\t1\n",
        "0\t0\t0\t0\t0\n",
        "2\t2\t2\t2\t2\n",
        "2\t0\t0\t0\t0\n",
        "2\t1\t1\t1\t1\n",
        "2\t1\t1\t1\t1\n",
        "2\t1\t1\t1\t1\n",
        "2\t2\t2\t2\t2\n",
        "2\t0\t0\t0\t0\n",
        "1\t1\t1\t1\t1\n",
        "2\t2\t2\t2\t2\n",
        "2\t2\t0\t0\t0\n",
        "2\t0\t0\t0\t0\n",
        "2\t1\t1\t1\t1\n",
        "2\t1\t1\t1\t1\n",
        "2\t2\t2\t2\t0\n",
        "2\t1\t2\t2\t0\n",
        "2\t2\t1\t1\t1\n",
        "2\t2\t1\t1\t1\n",
        "2\t1\t1\t1\t1\n",
        "2\t2\t0\t0\t0\n",
        "2\t0\t0\t0\t0\n",
        "2\t2\t2\t2\t2\n",
        "2\t1\t1\t2\t0\n",
        "2\t2\t2\t2\t0\n",
        "0\t0\t0\t0\t0\n",
        "2\t0\t0\t0\t0\n",
        "2\t2\t2\t2\t2\n",
        "0\t0\t0\t0\t0\n",
        "2\t1\t1\t1\t1\n",
        "2\t2\t2\t2\t2\n",
        "2\t0\t0\t0\t0\n",
        "2\t2\t2\t2\t2\n",
        "2\t1\t1\t1\t1\n",
        "2\t1\t1\t1\t1\n",
        "2\t0\t0\t0\t0\n",
        "0\t0\t0\t0\t0\n",
        "2\t0\t0\t0\t0\n",
        "2\t1\t1\t1\t1\n",
        "2\t2\t2\t2\t2\n",
        "2\t2\t2\t2\t2\n",
        "2\t0\t0\t0\t0\n",
        "2\t0\t0\t0\t0\n",
        "0\t0\t0\t0\t0\n",
        "2\t0\t0\t0\t0\n",
        "2\t2\t0\t0\t0\n",
        "0\t0\t0\t0\t0\n",
        "2\t0\t0\t0\t0\n",
        "0\t0\t0\t0\t0\n",
        "0\t0\t0\t0\t0\n",
        "0\t0\t0\t0\t0\n",
        "2\t2\t1\t1\t1\n",
        "2\t2\t2\t1\t1\n",
        "2\t2\t2\t2\t2\n",
        "0\t0\t0\t0\t0\n",
        "2\t2\t2\t2\t1\n",
        "2\t2\t1\t1\t1\n",
        "2\t1\t1\t1\t1\n",
        "2\t2\t2\t2\t2\n",
        "2\t2\t2\t0\t0\n",
        "2\t1\t1\t1\t1\n",
        "2\t2\t1\t1\t1\n",
        "2\t1\t1\t1\t1\n",
        "2\t2\t0\t0\t0\n",
        "1\t1\t2\t0\t0\n",
        "2\t2\t0\t0\t0\n",
        "2\t0\t0\t0\t0\n",
        "0\t0\t0\t0\t0\n",
        "0\t0\t0\t0\t0\n",
        "2\t2\t2\t2\t2\n",
        "0\t0\t0\t0\t0\n",
        "2\t2\t0\t0\t0\n",
        "1\t1\t1\t1\t1\n",
        "0\t0\t0\t0\t0\n",
        "0\t0\t0\t0\t0\n",
        "2\t2\t2\t2\t1\n",
        "2\t1\t1\t1\t1\n",
        "2\t1\t1\t2\t0\n",
        "2\t2\t1\t1\t1\n",
        "2\t0\t0\t0\t0\n",
        "2\t0\t0\t2\t0\n",
        "2\t2\t1\t1\t1\n",
        "0\t0\t0\t0\t0\n",
        "1\t1\t1\t1\t1\n",
        "2\t2\t0\t0\t2\n",
        "2\t0\t0\t0\t0\n",
        "2\t2\t2\t2\t2\n",
        "2\t1\t1\t1\t1\n",
        "0\t0\t0\t0\t0\n",
        "1\t1\t1\t1\t1\n",
        "0\t0\t0\t0\t0\n",
        "2\t1\t1\t1\t1\n",
        "2\t0\t0\t0\t0\n",
        "0\t0\t0\t0\t0\n",
        "2\t1\t1\t1\t1\n",
        "2\t1\t1\t1\t1\n",
        "1\t1\t1\t1\t1\n",
        "2\t2\t2\t2\t1\n",
        "2\t0\t0\t0\t0\n",
        "2\t2\t1\t1\t1\n",
        "2\t2\t1\t1\t1\n",
        "2\t2\t2\t2\t2\n",
        "1\t1\t1\t1\t1\n",
        "2\t2\t2\t1\t1\n",
        "2\t1\t1\t1\t1\n",
        "2\t2\t0\t0\t0\n",
        "2\t2\t0\t0\t0\n",
        "2\t1\t1\t1\t1\n",
        "2\t0\t0\t0\t0\n",
        "2\t1\t1\t1\t1\n",
        "2\t2\t2\t2\t1\n",
        "2\t1\t1\t1\t1\n",
        "2\t2\t1\t1\t1\n",
        "2\t1\t1\t1\t1\n",
        "0\t0\t0\t0\t0\n",
        "0\t0\t0\t0\t0\n",
        "2\t2\t1\t1\t1\n",
        "0\t0\t0\t0\t0\n",
        "1\t1\t1\t1\t1\n",
        "2\t0\t0\t0\t0\n",
        "0\t0\t0\t0\t0\n",
        "2\t2\t1\t1\t1\n",
        "2\t1\t1\t1\t1\n",
        "2\t2\t2\t1\t1\n",
        "0\t0\t0\t0\t0\n",
        "2\t2\t1\t1\t1\n",
        "2\t2\t1\t1\t2\n",
        "2\t0\t0\t0\t0\n",
        "2\t2\t0\t0\t0\n",
        "2\t2\t2\t2\t1\n",
        "2\t2\t2\t0\t0\n",
        "2\t2\t2\t2\t2\n",
        "1\t1\t1\t1\t1\n",
        "2\t1\t1\t2\t0\n",
        "2\t1\t1\t1\t1\n",
        "2\t2\t0\t0\t0\n",
        "2\t2\t2\t2\t0\n",
        "0\t0\t0\t0\t0\n",
        "0\t0\t0\t0\t0\n",
        "1\t1\t1\t1\t1\n",
        "2\t0\t0\t2\t2\n",
        "2\t2\t0\t0\t0\n",
        "2\t0\t0\t2\t1\n",
        "1\t1\t1\t1\t1\n",
        "2\t1\t1\t1\t1\n",
        "2\t0\t0\t0\t0\n",
        "1\t1\t1\t1\t1\n",
        "1\t1\t1\t1\t1\n",
        "1\t1\t1\t1\t1\n",
        "1\t1\t1\t1\t1\n",
        "2\t0\t2\t2\t2\n",
        "2\t2\t2\t2\t2\n",
        "2\t1\t1\t1\t1\n",
        "2\t2\t2\t2\t2\n",
        "1\t1\t1\t1\t1\n",
        "2\t0\t2\t1\t1\n",
        "2\t0\t0\t0\t0\n",
        "2\t1\t1\t1\t1\n",
        "2\t1\t1\t1\t1\n",
        "0\t0\t0\t0\t0\n",
        "2\t2\t2\t1\t1\n",
        "0\t0\t0\t0\t0\n",
        "1\t1\t1\t1\t1\n",
        "2\t2\t2\t0\t0\n",
        "2\t1\t1\t1\t1\n",
        "2\t0\t0\t0\t0\n",
        "0\t0\t0\t0\t0\n",
        "2\t1\t2\t2\t0\n",
        "2\t0\t0\t0\t0\n",
        "2\t1\t1\t1\t1\n",
        "2\t0\t0\t0\t0\n",
        "2\t2\t2\t2\t2\n",
        "2\t2\t0\t0\t0\n",
        "2\t1\t1\t1\t1\n",
        "2\t1\t1\t1\t1\n",
        "0\t0\t0\t0\t0\n",
        "2\t0\t2\t1\t1\n",
        "0\t0\t0\t0\t0\n",
        "2\t2\t2\t1\t1\n",
        "2\t1\t1\t1\t1\n",
        "0\t0\t0\t0\t0\n",
        "2\t1\t0\t0\t0\n",
        "1\t1\t1\t1\t1\n",
        "2\t1\t1\t1\t1\n",
        "2\t1\t1\t1\t1\n",
        "2\t2\t1\t1\t1\n",
        "2\t1\t1\t1\t1\n",
        "0\t0\t0\t0\t0\n",
        "2\t0\t0\t0\t0\n",
        "2\t2\t0\t0\t0\n",
        "2\t2\t1\t1\t1\n",
        "2\t2\t2\t1\t1\n",
        "1\t1\t1\t2\t0\n",
        "0\t0\t0\t0\t0\n",
        "1\t1\t1\t1\t1\n",
        "2\t2\t1\t1\t1\n",
        "2\t2\t0\t0\t0\n",
        "2\t1\t1\t1\t1\n",
        "2\t1\t1\t1\t1\n",
        "2\t2\t2\t1\t1\n",
        "0\t0\t0\t0\t0\n",
        "2\t1\t1\t1\t1\n",
        "2\t1\t1\t1\t1\n",
        "2\t2\t2\t1\t1\n",
        "2\t2\t2\t2\t2\n",
        "2\t1\t1\t1\t1\n",
        "2\t2\t2\t2\t2\n",
        "1\t1\t1\t0\t0\n",
        "1\t1\t1\t1\t1\n",
        "2\t2\t2\t0\t0\n",
        "2\t0\t0\t0\t0\n",
        "2\t2\t0\t0\t0\n",
        "0\t0\t0\t0\t0\n",
        "2\t1\t1\t1\t1\n",
        "2\t0\t0\t0\t0\n",
        "2\t0\t0\t0\t0\n",
        "2\t0\t0\t0\t0\n",
        "2\t2\t2\t2\t2\n",
        "2\t1\t1\t1\t1\n",
        "2\t1\t1\t1\t1\n",
        "1\t1\t1\t1\t1\n",
        "2\t1\t1\t1\t1\n",
        "2\t2\t2\t1\t1\n",
        "2\t2\t1\t1\t1\n",
        "2\t0\t0\t0\t0\n",
        "2\t2\t2\t2\t1\n",
        "0\t0\t0\t0\t0\n",
        "1\t1\t1\t1\t1\n",
        "2\t2\t0\t0\t0\n",
        "2\t2\t1\t1\t1\n",
        "2\t1\t1\t1\t1\n",
        "2\t1\t1\t1\t1\n",
        "2\t2\t2\t0\t0\n",
        "1\t1\t1\t1\t1\n",
        "2\t2\t0\t0\t0\n",
        "2\t2\t2\t2\t2\n",
        "1\t1\t1\t1\t2\n",
        "2\t0\t0\t0\t0\n",
        "2\t2\t2\t2\t2\n",
        "2\t0\t0\t0\t2\n",
        "2\t2\t2\t2\t2\n",
        "2\t2\t0\t0\t0\n",
        "2\t2\t0\t0\t2\n",
        "2\t0\t0\t0\t0\n",
        "2\t2\t0\t0\t0\n",
        "2\t2\t2\t2\t2\n",
        "2\t1\t1\t1\t1\n",
        "2\t2\t2\t2\t2\n",
        "2\t2\t0\t0\t0\n",
        "2\t2\t2\t2\t2\n",
        "2\t2\t1\t1\t1\n",
        "2\t0\t0\t0\t0\n",
        "2\t2\t2\t2\t2\n",
        "0\t0\t0\t0\t0\n",
        "0\t0\t0\t0\t0\n",
        "2\t2\t1\t1\t1\n",
        "2\t0\t0\t0\t0\n",
        "2\t1\t1\t1\t1\n",
        "2\t1\t1\t1\t1\n",
        "2\t0\t0\t0\t0\n",
        "2\t2\t2\t0\t0\n",
        "2\t1\t1\t1\t1\n",
        "1\t1\t1\t1\t1\n",
        "0\t0\t0\t0\t0\n",
        "2\t2\t0\t2\t2\n",
        "2\t2\t2\t1\t1\n",
        "2\t2\t2\t0\t0\n",
        "2\t2\t2\t2\t2\n",
        "2\t2\t0\t0\t0\n",
        "2\t2\t1\t1\t1\n",
        "1\t1\t1\t1\t1\n",
        "2\t1\t1\t1\t1\n",
        "2\t2\t0\t0\t0\n",
        "2\t0\t0\t0\t0\n",
        "2\t2\t2\t2\t2\n",
        "2\t1\t1\t2\t2\n",
        "2\t2\t2\t1\t1\n",
        "2\t0\t0\t0\t0\n",
        "2\t2\t2\t2\t2\n",
        "0\t0\t0\t0\t0\n",
        "2\t2\t0\t0\t0\n",
        "2\t0\t0\t0\t0\n",
        "2\t2\t2\t2\t2\n",
        "2\t2\t0\t0\t0\n",
        "2\t0\t0\t0\t0\n",
        "2\t0\t0\t0\t0\n",
        "2\t1\t1\t1\t1\n",
        "2\t0\t0\t0\t0\n",
        "2\t1\t1\t1\t1\n",
        "2\t2\t2\t2\t2\n",
        "2\t0\t0\t0\t0\n",
        "0\t0\t0\t0\t0\n",
        "2\t2\t2\t2\t0\n",
        "2\t0\t0\t0\t0\n",
        "2\t0\t0\t0\t0\n"
       ]
      }
     ],
     "prompt_number": 77
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Test Report \n",
      "\n",
      "For every classifier we test a set of parameters and produce statistics comparing predictions of the models to human oracle predictions. \n",
      "\n",
      "We report: \n",
      "\n",
      "* Accuracy\n",
      "* Confusion Matrix\n",
      "* Label distribution\n",
      "* Precision, recall, f1\n",
      "* Class 0 distribution\n"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# compute metrics\n",
      "def print_cm(cm):\n",
      "    return \"\\n\".join([\"{}\\t{}\\t{}\".format(*r) for r in cm])\n",
      "\n",
      "def print_report(user_labels, results, C, threshold, name=\"noname\"):\n",
      "    from sklearn import metrics \n",
      "    \n",
      "    for c in C:  \n",
      "        print \"\\nREPORT %s C=%s T=%s\" % (name.upper(),c, threshold)\n",
      "        print \"-\"*20\n",
      "        print \"Accuracy:\", metrics.accuracy_score(user_labels, results[c][:500])\n",
      "        print metrics.classification_report(user_labels, results[c][:500])\n",
      "        cm = metrics.confusion_matrix(user_labels, results[c][:500])\n",
      "        print \"\\nConfusion Matrix\\n%s\" % print_cm(cm)\n",
      "\n",
      "        print \"\\nDistribution (%):\"\n",
      "        print \"\\n\".join([\"Class {0}: {1:.2f}\".format(l, 1.*d/cm.sum()) for l, d in enumerate(cm.sum(0))] )\n",
      "        try:\n",
      "            print \"\\nNon-neutral distribution (C0/C0+C1): %.3f\" % (1. * cm.sum(0)[0] / (cm.sum(0)[0]+cm.sum(0)[1]))\n",
      "        except ZeroDivisionError:\n",
      "            print \"Non-neutral distribution: N/A\" \n",
      "        "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 289
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# Testing Models Trained on Sentences: IMDB\n",
      "\n",
      "We test several value of parameters per classifier. We tested: \n",
      "\n",
      "* LRL2\n",
      "* LRL1\n",
      "* LinearSVC: does not have probability estimation\n",
      "* DecisionTree: Requires dense representation\n",
      "* MNB\n",
      "\n",
      "## Testing LR-L2 over C values\n",
      "\n",
      "We tested $C=\\{10^{-2},10^{-1},10^0,10^1,10^2,\\}$ for LR classifiers, we use human expert labels as ground truth"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Test LRL2 sentences\n",
      "C = [pow(10,x) for x in range(-2,3)]\n",
      "data = {'bow':exp_sent_bow, 'target':exp_lbl}\n",
      "results = test_parameters(\"LogisticRegression(penalty='l2', C={})\", C, data, .4 )\n",
      "print print_report(user_labels, results, C, name=\"lrl2\")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Parameters for LogisticRegression(penalty='l2', C={}) and T > 0.4\n",
        "Testing ... C= 0.01\n",
        "Testing ... C="
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 0.1\n",
        "Testing ... C="
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 1\n",
        "Testing ... C="
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 10\n",
        "Testing ... C="
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 100\n",
        "\n",
        "REPORT LRL2 C=0.01"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "--------------------\n",
        "Accuracy: 0.476\n",
        "             precision    recall  f1-score   support\n",
        "\n",
        "        0.0       0.67      0.32      0.43       175\n",
        "        1.0       0.81      0.23      0.35       155\n",
        "        2.0       0.39      0.86      0.54       170\n",
        "\n",
        "avg / total       0.62      0.48      0.45       500\n",
        "\n",
        "\n",
        "Confusion Matrix\n",
        "56\t4\t115\n",
        "8\t35\t112\n",
        "19\t4\t147\n",
        "\n",
        "Distribution (%):\n",
        "Class 0: 0.17\n",
        "Class 1: 0.09\n",
        "Class 2: 0.75\n",
        "\n",
        "Non-neutral distribution (C0/C0+C1): 0.659\n",
        "\n",
        "REPORT LRL2 C=0.1\n",
        "--------------------\n",
        "Accuracy: 0.568\n",
        "             precision    recall  f1-score   support\n",
        "\n",
        "        0.0       0.64      0.62      0.63       175\n",
        "        1.0       0.62      0.57      0.59       155\n",
        "        2.0       0.47      0.52      0.49       170\n",
        "\n",
        "avg / total       0.57      0.57      0.57       500\n",
        "\n",
        "\n",
        "Confusion Matrix\n",
        "108\t16\t51\n",
        "17\t88\t50\n",
        "45\t37\t88\n",
        "\n",
        "Distribution (%):\n",
        "Class 0: 0.34\n",
        "Class 1: 0.28\n",
        "Class 2: 0.38\n",
        "\n",
        "Non-neutral distribution (C0/C0+C1): 0.547\n",
        "\n",
        "REPORT LRL2 C=1\n",
        "--------------------\n",
        "Accuracy: 0.548\n",
        "             precision    recall  f1-score   support\n",
        "\n",
        "        0.0       0.58      0.67      0.62       175\n",
        "        1.0       0.57      0.65      0.61       155\n",
        "        2.0       0.46      0.33      0.38       170\n",
        "\n",
        "avg / total       0.54      0.55      0.54       500\n",
        "\n",
        "\n",
        "Confusion Matrix\n",
        "118\t23\t34\n",
        "24\t100\t31\n",
        "63\t51\t56\n",
        "\n",
        "Distribution (%):\n",
        "Class 0: 0.41\n",
        "Class 1: 0.35\n",
        "Class 2: 0.24\n",
        "\n",
        "Non-neutral distribution (C0/C0+C1): 0.541\n",
        "\n",
        "REPORT LRL2 C=10\n",
        "--------------------\n",
        "Accuracy: 0.52\n",
        "             precision    recall  f1-score   support\n",
        "\n",
        "        0.0       0.56      0.65      0.60       175\n",
        "        1.0       0.54      0.63      0.59       155\n",
        "        2.0       0.42      0.29      0.34       170\n",
        "\n",
        "avg / total       0.51      0.52      0.51       500\n",
        "\n",
        "\n",
        "Confusion Matrix\n",
        "113\t24\t38\n",
        "27\t98\t30\n",
        "63\t58\t49\n",
        "\n",
        "Distribution (%):\n",
        "Class 0: 0.41\n",
        "Class 1: 0.36\n",
        "Class 2: 0.23\n",
        "\n",
        "Non-neutral distribution (C0/C0+C1): 0.530\n",
        "\n",
        "REPORT LRL2 C=100\n",
        "--------------------\n",
        "Accuracy: 0.5\n",
        "             precision    recall  f1-score   support\n",
        "\n",
        "        0.0       0.53      0.66      0.59       175\n",
        "        1.0       0.53      0.65      0.58       155\n",
        "        2.0       0.38      0.19      0.26       170\n",
        "\n",
        "avg / total       0.48      0.50      0.47       500\n",
        "\n",
        "\n",
        "Confusion Matrix\n",
        "116\t28\t31\n",
        "30\t101\t24\n",
        "74\t63\t33\n",
        "\n",
        "Distribution (%):\n",
        "Class 0: 0.44\n",
        "Class 1: 0.38\n",
        "Class 2: 0.18\n",
        "\n",
        "Non-neutral distribution (C0/C0+C1): 0.534\n",
        "None\n"
       ]
      }
     ],
     "prompt_number": 199
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Testing Threshold .35\n",
      "data = {'bow':exp_sent_bow, 'target':exp_lbl}\n",
      "results = test_parameters(\"LogisticRegression(penalty='l2', C={})\", C, data, .35 )\n",
      "print print_report(user_labels, results, C, name=\"lrl2\")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Testing Parameters for LogisticRegression(penalty='l2', C={}) and T > 0.35\n",
        "Testing ... C= 0.01\n",
        "Testing ... C="
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 0.1\n",
        "Testing ... C="
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 1\n",
        "Testing ... C="
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 10\n",
        "Testing ... C="
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 100\n",
        "\n",
        "REPORT LRL2 C=0.01"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "--------------------\n",
        "Accuracy: 0.402\n",
        "             precision    recall  f1-score   support\n",
        "\n",
        "        0.0       0.76      0.17      0.27       175\n",
        "        1.0       0.89      0.05      0.10       155\n",
        "        2.0       0.36      0.96      0.53       170\n",
        "\n",
        "avg / total       0.67      0.40      0.30       500\n",
        "\n",
        "\n",
        "Confusion Matrix\n",
        "29\t1\t145\n",
        "3\t8\t144\n",
        "6\t0\t164\n",
        "\n",
        "Distribution (%):\n",
        "Class 0: 0.08\n",
        "Class 1: 0.02\n",
        "Class 2: 0.91\n",
        "\n",
        "Non-neutral distribution (C0/C0+C1): 0.809\n",
        "\n",
        "REPORT LRL2 C=0.1\n",
        "--------------------\n",
        "Accuracy: 0.546\n",
        "             precision    recall  f1-score   support\n",
        "\n",
        "        0.0       0.68      0.47      0.56       175\n",
        "        1.0       0.70      0.44      0.54       155\n",
        "        2.0       0.43      0.72      0.54       170\n",
        "\n",
        "avg / total       0.60      0.55      0.55       500\n",
        "\n",
        "\n",
        "Confusion Matrix\n",
        "83\t8\t84\n",
        "12\t68\t75\n",
        "27\t21\t122\n",
        "\n",
        "Distribution (%):\n",
        "Class 0: 0.24\n",
        "Class 1: 0.19\n",
        "Class 2: 0.56\n",
        "\n",
        "Non-neutral distribution (C0/C0+C1): 0.557\n",
        "\n",
        "REPORT LRL2 C=1\n",
        "--------------------\n",
        "Accuracy: 0.558\n",
        "             precision    recall  f1-score   support\n",
        "\n",
        "        0.0       0.64      0.61      0.63       175\n",
        "        1.0       0.60      0.56      0.58       155\n",
        "        2.0       0.45      0.50      0.47       170\n",
        "\n",
        "avg / total       0.56      0.56      0.56       500\n",
        "\n",
        "\n",
        "Confusion Matrix\n",
        "107\t17\t51\n",
        "15\t87\t53\n",
        "44\t41\t85\n",
        "\n",
        "Distribution (%):\n",
        "Class 0: 0.33\n",
        "Class 1: 0.29\n",
        "Class 2: 0.38\n",
        "\n",
        "Non-neutral distribution (C0/C0+C1): 0.534\n",
        "\n",
        "REPORT LRL2 C=10\n",
        "--------------------\n",
        "Accuracy: 0.514\n",
        "             precision    recall  f1-score   support\n",
        "\n",
        "        0.0       0.57      0.61      0.59       175\n",
        "        1.0       0.56      0.58      0.57       155\n",
        "        2.0       0.40      0.36      0.38       170\n",
        "\n",
        "avg / total       0.51      0.51      0.51       500\n",
        "\n",
        "\n",
        "Confusion Matrix\n",
        "106\t20\t49\n",
        "23\t90\t42\n",
        "58\t51\t61\n",
        "\n",
        "Distribution (%):\n",
        "Class 0: 0.37\n",
        "Class 1: 0.32\n",
        "Class 2: 0.30\n",
        "\n",
        "Non-neutral distribution (C0/C0+C1): 0.537\n",
        "\n",
        "REPORT LRL2 C=100\n",
        "--------------------\n",
        "Accuracy: 0.484\n",
        "             precision    recall  f1-score   support\n",
        "\n",
        "        0.0       0.53      0.62      0.57       175\n",
        "        1.0       0.52      0.58      0.55       155\n",
        "        2.0       0.35      0.25      0.29       170\n",
        "\n",
        "avg / total       0.47      0.48      0.47       500\n",
        "\n",
        "\n",
        "Confusion Matrix\n",
        "109\t24\t42\n",
        "28\t90\t37\n",
        "68\t59\t43\n",
        "\n",
        "Distribution (%):\n",
        "Class 0: 0.41\n",
        "Class 1: 0.35\n",
        "Class 2: 0.24\n",
        "\n",
        "Non-neutral distribution (C0/C0+C1): 0.542\n",
        "None\n"
       ]
      }
     ],
     "prompt_number": 143
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "##Testing LRL1 C values"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Test LRL1 sentences\n",
      "C = [pow(10,x) for x in range(-2,3)]\n",
      "data = {'bow':exp_sent_bow, 'target':exp_lbl}\n",
      "results = test_parameters(\"LogisticRegression(penalty='l1', C={})\", C, data, .4 )\n",
      "print print_report(user_labels, results, C, name=\"lrl1\")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Testing Parameters for LogisticRegression(penalty='l1', C={}) and T > 0.4\n",
        "Testing ... C= 0.01\n",
        "Testing ... C="
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 0.1\n",
        "Testing ... C="
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 1\n",
        "Testing ... C="
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 10\n",
        "Testing ... C="
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 100\n",
        "\n",
        "REPORT LRL1 C=0.01"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "--------------------\n",
        "Accuracy: 0.414\n",
        "             precision    recall  f1-score   support\n",
        "\n",
        "        0.0       0.73      0.18      0.29       175\n",
        "        1.0       0.76      0.08      0.15       155\n",
        "        2.0       0.37      0.95      0.53       170\n",
        "\n",
        "avg / total       0.62      0.41      0.33       500\n",
        "\n",
        "\n",
        "Confusion Matrix\n",
        "32\t4\t139\n",
        "4\t13\t138\n",
        "8\t0\t162\n",
        "\n",
        "Distribution (%):\n",
        "Class 0: 0.09\n",
        "Class 1: 0.03\n",
        "Class 2: 0.88\n",
        "\n",
        "Non-neutral distribution (C0/C0+C1): 0.721\n",
        "\n",
        "REPORT LRL1 C=0.1\n",
        "--------------------\n",
        "Accuracy: 0.574\n",
        "             precision    recall  f1-score   support\n",
        "\n",
        "        0.0       0.66      0.59      0.62       175\n",
        "        1.0       0.62      0.55      0.58       155\n",
        "        2.0       0.48      0.58      0.53       170\n",
        "\n",
        "avg / total       0.59      0.57      0.58       500\n",
        "\n",
        "\n",
        "Confusion Matrix\n",
        "103\t17\t55\n",
        "17\t85\t53\n",
        "35\t36\t99\n",
        "\n",
        "Distribution (%):\n",
        "Class 0: 0.31\n",
        "Class 1: 0.28\n",
        "Class 2: 0.41\n",
        "\n",
        "Non-neutral distribution (C0/C0+C1): 0.529\n",
        "\n",
        "REPORT LRL1 C=1\n",
        "--------------------\n",
        "Accuracy: 0.562\n",
        "             precision    recall  f1-score   support\n",
        "\n",
        "        0.0       0.60      0.70      0.64       175\n",
        "        1.0       0.57      0.64      0.60       155\n",
        "        2.0       0.50      0.35      0.41       170\n",
        "\n",
        "avg / total       0.55      0.56      0.55       500\n",
        "\n",
        "\n",
        "Confusion Matrix\n",
        "122\t23\t30\n",
        "25\t99\t31\n",
        "58\t52\t60\n",
        "\n",
        "Distribution (%):\n",
        "Class 0: 0.41\n",
        "Class 1: 0.35\n",
        "Class 2: 0.24\n",
        "\n",
        "Non-neutral distribution (C0/C0+C1): 0.541\n",
        "\n",
        "REPORT LRL1 C=10\n",
        "--------------------\n",
        "Accuracy: 0.5\n",
        "             precision    recall  f1-score   support\n",
        "\n",
        "        0.0       0.54      0.65      0.59       175\n",
        "        1.0       0.52      0.65      0.57       155\n",
        "        2.0       0.38      0.21      0.27       170\n",
        "\n",
        "avg / total       0.48      0.50      0.48       500\n",
        "\n",
        "\n",
        "Confusion Matrix\n",
        "114\t28\t33\n",
        "28\t100\t27\n",
        "69\t65\t36\n",
        "\n",
        "Distribution (%):\n",
        "Class 0: 0.42\n",
        "Class 1: 0.39\n",
        "Class 2: 0.19\n",
        "\n",
        "Non-neutral distribution (C0/C0+C1): 0.522\n",
        "\n",
        "REPORT LRL1 C=100\n",
        "--------------------\n",
        "Accuracy: 0.494\n",
        "             precision    recall  f1-score   support\n",
        "\n",
        "        0.0       0.52      0.66      0.59       175\n",
        "        1.0       0.52      0.65      0.57       155\n",
        "        2.0       0.36      0.18      0.24       170\n",
        "\n",
        "avg / total       0.47      0.49      0.47       500\n",
        "\n",
        "\n",
        "Confusion Matrix\n",
        "116\t29\t30\n",
        "31\t100\t24\n",
        "74\t65\t31\n",
        "\n",
        "Distribution (%):\n",
        "Class 0: 0.44\n",
        "Class 1: 0.39\n",
        "Class 2: 0.17\n",
        "\n",
        "Non-neutral distribution (C0/C0+C1): 0.533\n",
        "None\n"
       ]
      }
     ],
     "prompt_number": 145
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "C = [pow(10,x) for x in range(-2,3)]\n",
      "data = {'bow':exp_sent_bow, 'target':exp_lbl}\n",
      "results = test_parameters(\"LogisticRegression(penalty='l1', C={})\", C, data, .35 )\n",
      "print print_report(user_labels, results, C, name=\"lrl1\")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Testing Parameters for LogisticRegression(penalty='l1', C={}) and T > 0.35\n",
        "Testing ... C= 0.01\n",
        "Testing ... C="
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 0.1\n",
        "Testing ... C="
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 1\n",
        "Testing ... C="
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 10\n",
        "Testing ... C="
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 100\n",
        "\n",
        "REPORT LRL1 C=0.01"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "--------------------\n",
        "Accuracy: 0.374\n",
        "             precision    recall  f1-score   support\n",
        "\n",
        "        0.0       0.74      0.10      0.17       175\n",
        "        1.0       0.80      0.03      0.05       155\n",
        "        2.0       0.35      0.98      0.52       170\n",
        "\n",
        "avg / total       0.63      0.37      0.25       500\n",
        "\n",
        "\n",
        "Confusion Matrix\n",
        "17\t1\t157\n",
        "2\t4\t149\n",
        "4\t0\t166\n",
        "\n",
        "Distribution (%):\n",
        "Class 0: 0.05\n",
        "Class 1: 0.01\n",
        "Class 2: 0.94\n",
        "\n",
        "Non-neutral distribution (C0/C0+C1): 0.821\n",
        "\n",
        "REPORT LRL1 C=0.1\n",
        "--------------------\n",
        "Accuracy: 0.56\n",
        "             precision    recall  f1-score   support\n",
        "\n",
        "        0.0       0.71      0.47      0.56       175\n",
        "        1.0       0.71      0.43      0.54       155\n",
        "        2.0       0.45      0.77      0.57       170\n",
        "\n",
        "avg / total       0.62      0.56      0.56       500\n",
        "\n",
        "\n",
        "Confusion Matrix\n",
        "82\t11\t82\n",
        "12\t67\t76\n",
        "22\t17\t131\n",
        "\n",
        "Distribution (%):\n",
        "Class 0: 0.23\n",
        "Class 1: 0.19\n",
        "Class 2: 0.58\n",
        "\n",
        "Non-neutral distribution (C0/C0+C1): 0.550\n",
        "\n",
        "REPORT LRL1 C=1\n",
        "--------------------\n",
        "Accuracy: 0.546\n",
        "             precision    recall  f1-score   support\n",
        "\n",
        "        0.0       0.64      0.61      0.62       175\n",
        "        1.0       0.57      0.53      0.55       155\n",
        "        2.0       0.45      0.50      0.47       170\n",
        "\n",
        "avg / total       0.55      0.55      0.55       500\n",
        "\n",
        "\n",
        "Confusion Matrix\n",
        "106\t20\t49\n",
        "16\t82\t57\n",
        "44\t41\t85\n",
        "\n",
        "Distribution (%):\n",
        "Class 0: 0.33\n",
        "Class 1: 0.29\n",
        "Class 2: 0.38\n",
        "\n",
        "Non-neutral distribution (C0/C0+C1): 0.537\n",
        "\n",
        "REPORT LRL1 C=10\n",
        "--------------------\n",
        "Accuracy: 0.498\n",
        "             precision    recall  f1-score   support\n",
        "\n",
        "        0.0       0.55      0.61      0.58       175\n",
        "        1.0       0.53      0.58      0.56       155\n",
        "        2.0       0.38      0.31      0.34       170\n",
        "\n",
        "avg / total       0.49      0.50      0.49       500\n",
        "\n",
        "\n",
        "Confusion Matrix\n",
        "107\t23\t45\n",
        "25\t90\t40\n",
        "62\t56\t52\n",
        "\n",
        "Distribution (%):\n",
        "Class 0: 0.39\n",
        "Class 1: 0.34\n",
        "Class 2: 0.27\n",
        "\n",
        "Non-neutral distribution (C0/C0+C1): 0.534\n",
        "\n",
        "REPORT LRL1 C=100\n",
        "--------------------\n",
        "Accuracy: 0.488\n",
        "             precision    recall  f1-score   support\n",
        "\n",
        "        0.0       0.53      0.63      0.58       175\n",
        "        1.0       0.51      0.58      0.55       155\n",
        "        2.0       0.37      0.25      0.30       170\n",
        "\n",
        "avg / total       0.47      0.49      0.47       500\n",
        "\n",
        "\n",
        "Confusion Matrix\n",
        "111\t26\t38\n",
        "29\t90\t36\n",
        "68\t59\t43\n",
        "\n",
        "Distribution (%):\n",
        "Class 0: 0.42\n",
        "Class 1: 0.35\n",
        "Class 2: 0.23\n",
        "\n",
        "Non-neutral distribution (C0/C0+C1): 0.543\n",
        "None\n"
       ]
      }
     ],
     "prompt_number": 144
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Test LRL2 sentences\n",
      "from sklearn.svm import LinearSVC\n",
      "C = [pow(10,x) for x in range(-2,3)]\n",
      "results = test_parameters(\"LinearSVC(C={}, probability=True)\", C, imdb.test, .4 )\n",
      "print print_report(user_labels, results, C, .4, name=\"LinearSVC\")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Testing Parameters for LinearSVC(C={}, probability=True) and T > 0.4\n",
        "Testing ... C= 0.01\n"
       ]
      },
      {
       "ename": "TypeError",
       "evalue": "__init__() got an unexpected keyword argument 'probability'",
       "output_type": "pyerr",
       "traceback": [
        "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
        "\u001b[0;32m<ipython-input-161-3271edc28193>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mC\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mpow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m'bow'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mexp_sent_bow\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'target'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mexp_lbl\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest_parameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"LinearSVC(C={}, probability=True)\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mC\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimdb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m.4\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;32mprint\u001b[0m \u001b[0mprint_report\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muser_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mC\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"LinearSVC\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;32m<ipython-input-90-a1a68181d2b8>\u001b[0m in \u001b[0;36mtest_parameters\u001b[0;34m(clf_str, C, data, threshold, name)\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0;32mprint\u001b[0m \u001b[0;34m\"Testing ... C=\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;31m#         expert = exputil.get_classifier('lrl2', parameter=c)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m         \u001b[0mexpert\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclf_str\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m         \u001b[0mexpert\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'bow'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'target'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mexpert\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msnip_bow\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;32m<string>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n",
        "\u001b[0;31mTypeError\u001b[0m: __init__() got an unexpected keyword argument 'probability'"
       ]
      }
     ],
     "prompt_number": 161
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "#Testing Models Trained on Documents\n",
      "\n",
      "\n"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Test LRL2 documents\n",
      "C = [pow(10,x) for x in range(-2,3)]\n",
      "results = test_parameters(\"LogisticRegression(penalty='l2', C={})\", C, imdb.test, .4 )\n",
      "print print_report(user_labels, results, C, name=\"lrl2\")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Parameters for LogisticRegression(penalty='l2', C={}) and T > 0.4\n",
        "Testing ... C= 0.01\n",
        "Testing ... C="
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 0.1\n",
        "Testing ... C="
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 1\n",
        "Testing ... C="
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 10\n",
        "Testing ... C="
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 100\n",
        "\n",
        "REPORT LRL2 C=0.01"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "--------------------\n",
        "Accuracy: 0.354\n",
        "             precision    recall  f1-score   support\n",
        "\n",
        "        0.0       0.83      0.03      0.06       175\n",
        "        1.0       1.00      0.02      0.04       155\n",
        "        2.0       0.34      0.99      0.51       170\n",
        "\n",
        "avg / total       0.72      0.35      0.20       500\n",
        "\n",
        "\n",
        "Confusion Matrix\n",
        "5\t0\t170\n",
        "0\t3\t152\n",
        "1\t0\t169\n",
        "\n",
        "Distribution (%):\n",
        "Class 0: 0.01\n",
        "Class 1: 0.01\n",
        "Class 2: 0.98\n",
        "\n",
        "Non-neutral distribution (C0/C0+C1): 0.667\n",
        "\n",
        "REPORT LRL2 C=0.1\n",
        "--------------------\n",
        "Accuracy: 0.536\n",
        "             precision    recall  f1-score   support\n",
        "\n",
        "        0.0       0.68      0.41      0.51       175\n",
        "        1.0       0.61      0.54      0.57       155\n",
        "        2.0       0.44      0.66      0.53       170\n",
        "\n",
        "avg / total       0.58      0.54      0.54       500\n",
        "\n",
        "\n",
        "Confusion Matrix\n",
        "71\t18\t86\n",
        "12\t84\t59\n",
        "21\t36\t113\n",
        "\n",
        "Distribution (%):\n",
        "Class 0: 0.21\n",
        "Class 1: 0.28\n",
        "Class 2: 0.52\n",
        "\n",
        "Non-neutral distribution (C0/C0+C1): 0.430\n",
        "\n",
        "REPORT LRL2 C=1\n",
        "--------------------\n",
        "Accuracy: 0.566\n",
        "             precision    recall  f1-score   support\n",
        "\n",
        "        0.0       0.61      0.70      0.66       175\n",
        "        1.0       0.55      0.66      0.60       155\n",
        "        2.0       0.50      0.34      0.40       170\n",
        "\n",
        "avg / total       0.56      0.57      0.55       500\n",
        "\n",
        "\n",
        "Confusion Matrix\n",
        "123\t26\t26\n",
        "21\t103\t31\n",
        "56\t57\t57\n",
        "\n",
        "Distribution (%):\n",
        "Class 0: 0.40\n",
        "Class 1: 0.37\n",
        "Class 2: 0.23\n",
        "\n",
        "Non-neutral distribution (C0/C0+C1): 0.518\n",
        "\n",
        "REPORT LRL2 C=10\n",
        "--------------------\n",
        "Accuracy: 0.532\n",
        "             precision    recall  f1-score   support\n",
        "\n",
        "        0.0       0.56      0.75      0.64       175\n",
        "        1.0       0.52      0.67      0.59       155\n",
        "        2.0       0.47      0.18      0.26       170\n",
        "\n",
        "avg / total       0.52      0.53      0.50       500\n",
        "\n",
        "\n",
        "Confusion Matrix\n",
        "131\t29\t15\n",
        "31\t104\t20\n",
        "72\t67\t31\n",
        "\n",
        "Distribution (%):\n",
        "Class 0: 0.47\n",
        "Class 1: 0.40\n",
        "Class 2: 0.13\n",
        "\n",
        "Non-neutral distribution (C0/C0+C1): 0.539\n",
        "\n",
        "REPORT LRL2 C=100\n",
        "--------------------\n",
        "Accuracy: 0.504\n",
        "             precision    recall  f1-score   support\n",
        "\n",
        "        0.0       0.53      0.76      0.62       175\n",
        "        1.0       0.49      0.68      0.57       155\n",
        "        2.0       0.41      0.08      0.13       170\n",
        "\n",
        "avg / total       0.47      0.50      0.44       500\n",
        "\n",
        "\n",
        "Confusion Matrix\n",
        "133\t33\t9\n",
        "39\t106\t10\n",
        "80\t77\t13\n",
        "\n",
        "Distribution (%):\n",
        "Class 0: 0.50\n",
        "Class 1: 0.43\n",
        "Class 2: 0.06\n",
        "\n",
        "Non-neutral distribution (C0/C0+C1): 0.538\n",
        "None\n"
       ]
      }
     ],
     "prompt_number": 273
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "imdb.test.bow.shape"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 274,
       "text": [
        "(25000, 27316)"
       ]
      }
     ],
     "prompt_number": 274
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Test LRL1 documents\n",
      "C = [pow(10,x) for x in range(-1,3)]\n",
      "results = test_parameters(\"LogisticRegression(penalty='l1', C={})\", C, imdb.test, .4 )\n",
      "print print_report(user_labels, results, C, .4, name=\"lrl1\")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Parameters for LogisticRegression(penalty='l1', C={}) and T > 0.4\n",
        "Testing ... C= 0.1\n",
        "Testing ... C="
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 1\n",
        "Testing ... C="
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 10\n",
        "Testing ... C="
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 100\n",
        "\n",
        "REPORT LRL1 C=0.1 T=0.4"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "--------------------\n",
        "Accuracy: 0.534\n",
        "             precision    recall  f1-score   support\n",
        "\n",
        "        0.0       0.65      0.42      0.51       175\n",
        "        1.0       0.56      0.47      0.51       155\n",
        "        2.0       0.47      0.71      0.56       170\n",
        "\n",
        "avg / total       0.56      0.53      0.53       500\n",
        "\n",
        "\n",
        "Confusion Matrix\n",
        "74\t29\t72\n",
        "19\t73\t63\n",
        "21\t29\t120\n",
        "\n",
        "Distribution (%):\n",
        "Class 0: 0.23\n",
        "Class 1: 0.26\n",
        "Class 2: 0.51\n",
        "\n",
        "Non-neutral distribution (C0/C0+C1): 0.465\n",
        "\n",
        "REPORT LRL1 C=1 T=0.4\n",
        "--------------------\n",
        "Accuracy: 0.556\n",
        "             precision    recall  f1-score   support\n",
        "\n",
        "        0.0       0.62      0.70      0.65       175\n",
        "        1.0       0.53      0.67      0.59       155\n",
        "        2.0       0.50      0.31      0.38       170\n",
        "\n",
        "avg / total       0.55      0.56      0.54       500\n",
        "\n",
        "\n",
        "Confusion Matrix\n",
        "122\t27\t26\n",
        "24\t104\t27\n",
        "52\t66\t52\n",
        "\n",
        "Distribution (%):\n",
        "Class 0: 0.40\n",
        "Class 1: 0.39\n",
        "Class 2: 0.21\n",
        "\n",
        "Non-neutral distribution (C0/C0+C1): 0.501\n",
        "\n",
        "REPORT LRL1 C=10 T=0.4\n",
        "--------------------\n",
        "Accuracy: 0.516\n",
        "             precision    recall  f1-score   support\n",
        "\n",
        "        0.0       0.54      0.73      0.62       175\n",
        "        1.0       0.51      0.72      0.60       155\n",
        "        2.0       0.43      0.11      0.17       170\n",
        "\n",
        "avg / total       0.49      0.52      0.46       500\n",
        "\n",
        "\n",
        "Confusion Matrix\n",
        "128\t33\t14\n",
        "33\t112\t10\n",
        "77\t75\t18\n",
        "\n",
        "Distribution (%):\n",
        "Class 0: 0.48\n",
        "Class 1: 0.44\n",
        "Class 2: 0.08\n",
        "\n",
        "Non-neutral distribution (C0/C0+C1): 0.520\n",
        "\n",
        "REPORT LRL1 C=100 T=0.4\n",
        "--------------------\n",
        "Accuracy: 0.5\n",
        "             precision    recall  f1-score   support\n",
        "\n",
        "        0.0       0.53      0.73      0.61       175\n",
        "        1.0       0.48      0.72      0.58       155\n",
        "        2.0       0.42      0.06      0.11       170\n",
        "\n",
        "avg / total       0.48      0.50      0.43       500\n",
        "\n",
        "\n",
        "Confusion Matrix\n",
        "128\t40\t7\n",
        "36\t111\t8\n",
        "79\t80\t11\n",
        "\n",
        "Distribution (%):\n",
        "Class 0: 0.49\n",
        "Class 1: 0.46\n",
        "Class 2: 0.05\n",
        "\n",
        "Non-neutral distribution (C0/C0+C1): 0.513\n",
        "None\n"
       ]
      }
     ],
     "prompt_number": 323
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Test LRL2 documents\n",
      "C = [pow(10,x) for x in range(-1,3)]\n",
      "results = test_parameters(\"LogisticRegression(penalty='l2', C={})\", C, imdb.test, .35 )\n",
      "print print_report(user_labels, results, C, .35, name=\"lrl2\")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Parameters for LogisticRegression(penalty='l2', C={}) and T > 0.35\n",
        "Testing ... C= 0.1\n",
        "Testing ... C="
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 1\n",
        "Testing ... C="
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 10\n",
        "Testing ... C="
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 100\n",
        "\n",
        "REPORT LRL2 C=0.1 T=0.35"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "--------------------\n",
        "Accuracy: 0.512\n",
        "             precision    recall  f1-score   support\n",
        "\n",
        "        0.0       0.71      0.31      0.43       175\n",
        "        1.0       0.71      0.37      0.49       155\n",
        "        2.0       0.42      0.84      0.56       170\n",
        "\n",
        "avg / total       0.61      0.51      0.49       500\n",
        "\n",
        "\n",
        "Confusion Matrix\n",
        "55\t11\t109\n",
        "9\t58\t88\n",
        "14\t13\t143\n",
        "\n",
        "Distribution (%):\n",
        "Class 0: 0.16\n",
        "Class 1: 0.16\n",
        "Class 2: 0.68\n",
        "\n",
        "Non-neutral distribution (C0/C0+C1): 0.487\n",
        "\n",
        "REPORT LRL2 C=1 T=0.35\n",
        "--------------------\n",
        "Accuracy: 0.588\n",
        "             precision    recall  f1-score   support\n",
        "\n",
        "        0.0       0.66      0.66      0.66       175\n",
        "        1.0       0.59      0.61      0.60       155\n",
        "        2.0       0.51      0.50      0.50       170\n",
        "\n",
        "avg / total       0.59      0.59      0.59       500\n",
        "\n",
        "\n",
        "Confusion Matrix\n",
        "115\t21\t39\n",
        "18\t94\t43\n",
        "42\t43\t85\n",
        "\n",
        "Distribution (%):\n",
        "Class 0: 0.35\n",
        "Class 1: 0.32\n",
        "Class 2: 0.33\n",
        "\n",
        "Non-neutral distribution (C0/C0+C1): 0.526\n",
        "\n",
        "REPORT LRL2 C=10 T=0.35\n",
        "--------------------\n",
        "Accuracy: 0.556\n",
        "             precision    recall  f1-score   support\n",
        "\n",
        "        0.0       0.59      0.74      0.66       175\n",
        "        1.0       0.54      0.65      0.59       155\n",
        "        2.0       0.50      0.28      0.36       170\n",
        "\n",
        "avg / total       0.55      0.56      0.54       500\n",
        "\n",
        "\n",
        "Confusion Matrix\n",
        "130\t26\t19\n",
        "26\t100\t29\n",
        "63\t59\t48\n",
        "\n",
        "Distribution (%):\n",
        "Class 0: 0.44\n",
        "Class 1: 0.37\n",
        "Class 2: 0.19\n",
        "\n",
        "Non-neutral distribution (C0/C0+C1): 0.542\n",
        "\n",
        "REPORT LRL2 C=100 T=0.35\n",
        "--------------------\n",
        "Accuracy: 0.502\n",
        "             precision    recall  f1-score   support\n",
        "\n",
        "        0.0       0.53      0.74      0.62       175\n",
        "        1.0       0.50      0.66      0.57       155\n",
        "        2.0       0.37      0.11      0.17       170\n",
        "\n",
        "avg / total       0.47      0.50      0.45       500\n",
        "\n",
        "\n",
        "Confusion Matrix\n",
        "129\t29\t17\n",
        "37\t103\t15\n",
        "77\t74\t19\n",
        "\n",
        "Distribution (%):\n",
        "Class 0: 0.49\n",
        "Class 1: 0.41\n",
        "Class 2: 0.10\n",
        "\n",
        "Non-neutral distribution (C0/C0+C1): 0.541\n",
        "None\n"
       ]
      }
     ],
     "prompt_number": 325
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Test LRL2 documents\n",
      "C = [pow(10,x) for x in range(-2,3)]\n",
      "\n",
      "results = test_parameters(\"LogisticRegression(penalty='l2', C={})\", C, imdb.test, .4 )\n",
      "print print_report(user_labels, results, C, .4, name=\"lrl2\")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Parameters for LogisticRegression(penalty='l2', C={}) and T > 0.4\n",
        "Testing ... C= 0.01\n",
        "Testing ... C="
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 0.1\n",
        "Testing ... C="
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 1\n",
        "Testing ... C="
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 10\n",
        "Testing ... C="
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 100\n",
        "\n",
        "REPORT LRL2 C=0.01 T=0.4"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "--------------------\n",
        "Accuracy: 0.354\n",
        "             precision    recall  f1-score   support\n",
        "\n",
        "        0.0       0.83      0.03      0.06       175\n",
        "        1.0       1.00      0.02      0.04       155\n",
        "        2.0       0.34      0.99      0.51       170\n",
        "\n",
        "avg / total       0.72      0.35      0.20       500\n",
        "\n",
        "\n",
        "Confusion Matrix\n",
        "5\t0\t170\n",
        "0\t3\t152\n",
        "1\t0\t169\n",
        "\n",
        "Distribution (%):\n",
        "Class 0: 0.01\n",
        "Class 1: 0.01\n",
        "Class 2: 0.98\n",
        "\n",
        "Non-neutral distribution (C0/C0+C1): 0.667\n",
        "\n",
        "REPORT LRL2 C=0.1 T=0.4\n",
        "--------------------\n",
        "Accuracy: 0.536\n",
        "             precision    recall  f1-score   support\n",
        "\n",
        "        0.0       0.68      0.41      0.51       175\n",
        "        1.0       0.61      0.54      0.57       155\n",
        "        2.0       0.44      0.66      0.53       170\n",
        "\n",
        "avg / total       0.58      0.54      0.54       500\n",
        "\n",
        "\n",
        "Confusion Matrix\n",
        "71\t18\t86\n",
        "12\t84\t59\n",
        "21\t36\t113\n",
        "\n",
        "Distribution (%):\n",
        "Class 0: 0.21\n",
        "Class 1: 0.28\n",
        "Class 2: 0.52\n",
        "\n",
        "Non-neutral distribution (C0/C0+C1): 0.430\n",
        "\n",
        "REPORT LRL2 C=1 T=0.4\n",
        "--------------------\n",
        "Accuracy: 0.566\n",
        "             precision    recall  f1-score   support\n",
        "\n",
        "        0.0       0.61      0.70      0.66       175\n",
        "        1.0       0.55      0.66      0.60       155\n",
        "        2.0       0.50      0.34      0.40       170\n",
        "\n",
        "avg / total       0.56      0.57      0.55       500\n",
        "\n",
        "\n",
        "Confusion Matrix\n",
        "123\t26\t26\n",
        "21\t103\t31\n",
        "56\t57\t57\n",
        "\n",
        "Distribution (%):\n",
        "Class 0: 0.40\n",
        "Class 1: 0.37\n",
        "Class 2: 0.23\n",
        "\n",
        "Non-neutral distribution (C0/C0+C1): 0.518\n",
        "\n",
        "REPORT LRL2 C=10 T=0.4\n",
        "--------------------\n",
        "Accuracy: 0.532\n",
        "             precision    recall  f1-score   support\n",
        "\n",
        "        0.0       0.56      0.75      0.64       175\n",
        "        1.0       0.52      0.67      0.59       155\n",
        "        2.0       0.47      0.18      0.26       170\n",
        "\n",
        "avg / total       0.52      0.53      0.50       500\n",
        "\n",
        "\n",
        "Confusion Matrix\n",
        "131\t29\t15\n",
        "31\t104\t20\n",
        "72\t67\t31\n",
        "\n",
        "Distribution (%):\n",
        "Class 0: 0.47\n",
        "Class 1: 0.40\n",
        "Class 2: 0.13\n",
        "\n",
        "Non-neutral distribution (C0/C0+C1): 0.539\n",
        "\n",
        "REPORT LRL2 C=100 T=0.4\n",
        "--------------------\n",
        "Accuracy: 0.504\n",
        "             precision    recall  f1-score   support\n",
        "\n",
        "        0.0       0.53      0.76      0.62       175\n",
        "        1.0       0.49      0.68      0.57       155\n",
        "        2.0       0.41      0.08      0.13       170\n",
        "\n",
        "avg / total       0.47      0.50      0.44       500\n",
        "\n",
        "\n",
        "Confusion Matrix\n",
        "133\t33\t9\n",
        "39\t106\t10\n",
        "80\t77\t13\n",
        "\n",
        "Distribution (%):\n",
        "Class 0: 0.50\n",
        "Class 1: 0.43\n",
        "Class 2: 0.06\n",
        "\n",
        "Non-neutral distribution (C0/C0+C1): 0.538\n",
        "None\n"
       ]
      }
     ],
     "prompt_number": 332
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Test MNB sentences\n",
      "from sklearn.naive_bayes import MultinomialNB\n",
      "C = [1, 2]\n",
      "results = test_parameters(\"MultinomialNB(alpha={})\", C, imdb.test, .42 )\n",
      "print print_report(user_labels, results, C, .42, name=\"MNB\")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Parameters for MultinomialNB(alpha={}) and T > 0.42\n",
        "Testing ... C= 1\n",
        "Testing ... C= 2\n",
        "\n",
        "REPORT MNB C=1 T=0.42"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "--------------------\n",
        "Accuracy: 0.518\n",
        "             precision    recall  f1-score   support\n",
        "\n",
        "        0.0       0.62      0.61      0.61       175\n",
        "        1.0       0.55      0.49      0.52       155\n",
        "        2.0       0.40      0.45      0.43       170\n",
        "\n",
        "avg / total       0.52      0.52      0.52       500\n",
        "\n",
        "\n",
        "Confusion Matrix\n",
        "106\t18\t51\n",
        "16\t76\t63\n",
        "48\t45\t77\n",
        "\n",
        "Distribution (%):\n",
        "Class 0: 0.34\n",
        "Class 1: 0.28\n",
        "Class 2: 0.38\n",
        "\n",
        "Non-neutral distribution (C0/C0+C1): 0.550\n",
        "\n",
        "REPORT MNB C=2 T=0.42\n",
        "--------------------\n",
        "Accuracy: 0.532\n",
        "             precision    recall  f1-score   support\n",
        "\n",
        "        0.0       0.64      0.60      0.62       175\n",
        "        1.0       0.57      0.48      0.52       155\n",
        "        2.0       0.42      0.51      0.46       170\n",
        "\n",
        "avg / total       0.54      0.53      0.54       500\n",
        "\n",
        "\n",
        "Confusion Matrix\n",
        "105\t15\t55\n",
        "16\t75\t64\n",
        "42\t42\t86\n",
        "\n",
        "Distribution (%):\n",
        "Class 0: 0.33\n",
        "Class 1: 0.26\n",
        "Class 2: 0.41\n",
        "\n",
        "Non-neutral distribution (C0/C0+C1): 0.553\n",
        "None\n"
       ]
      }
     ],
     "prompt_number": 336
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Test LRL2 sentences\n",
      "C = [pow(10,x) for x in range(-2,3)]\n",
      "results = test_parameters(\"LinearSVC(penalty='l1', C={})\", C, imdb.test, .45 )\n",
      "print print_report(user_labels, results, C, name=\"LinearSVC\")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Parameters for LinearSVC(penalty='l1', C={}) and T > 0.45\n",
        "Testing ... C= 0.01\n"
       ]
      },
      {
       "ename": "ValueError",
       "evalue": "Unsupported set of arguments: penalty='l1' is only supported when dual='false'., Parameters: penalty='l1', loss='l2', dual=True",
       "output_type": "pyerr",
       "traceback": [
        "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
        "\u001b[0;32m<ipython-input-326-1ef82aae8224>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Test LRL2 sentences\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mC\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mpow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest_parameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"LinearSVC(penalty='l1', C={})\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mC\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimdb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m.45\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;32mprint\u001b[0m \u001b[0mprint_report\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muser_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mC\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"LinearSVC\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;32m<ipython-input-215-bc3ebf4544a1>\u001b[0m in \u001b[0;36mtest_parameters\u001b[0;34m(clf_str, C, data, threshold, name)\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0;32mprint\u001b[0m \u001b[0;34m\"Testing ... C=\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;31m#         expert = exputil.get_classifier('lrl2', parameter=c)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m         \u001b[0mexpert\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclf_str\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m         \u001b[0mexpert\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'bow'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'target'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mexpert\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msnip_bow\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;32m<string>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n",
        "\u001b[0;32m/opt/local/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/site-packages/sklearn/svm/classes.pyc\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, penalty, loss, dual, tol, C, multi_class, fit_intercept, intercept_scaling, class_weight, verbose, random_state)\u001b[0m\n\u001b[1;32m    140\u001b[0m             \u001b[0mintercept_scaling\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mintercept_scaling\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m             \u001b[0mclass_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 142\u001b[0;31m             random_state=random_state)\n\u001b[0m\u001b[1;32m    143\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    144\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;32m/opt/local/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/site-packages/sklearn/svm/base.pyc\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, penalty, loss, dual, tol, C, multi_class, fit_intercept, intercept_scaling, class_weight, verbose, random_state)\u001b[0m\n\u001b[1;32m    617\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    618\u001b[0m         \u001b[0;31m# Check that the arguments given are valid:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 619\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_solver_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    620\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    621\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_get_solver_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;32m/opt/local/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/site-packages/sklearn/svm/base.pyc\u001b[0m in \u001b[0;36m_get_solver_type\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    651\u001b[0m                              \u001b[0;34m'Parameters: penalty=%r, loss=%r, dual=%r'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    652\u001b[0m                              % (error_string, self.penalty,\n\u001b[0;32m--> 653\u001b[0;31m                                 self.loss, self.dual))\n\u001b[0m\u001b[1;32m    654\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_solver_type_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msolver_type\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    655\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;31mValueError\u001b[0m: Unsupported set of arguments: penalty='l1' is only supported when dual='false'., Parameters: penalty='l1', loss='l2', dual=True"
       ]
      }
     ],
     "prompt_number": 326
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "---------------\n",
      "# Test with User Defined Dictionary\n",
      "\n",
      "From Prof. Bilgic description: \n",
      "\n",
      "Picked relevant terms for IMDB by hand. I did not go through all 27K words, but instead I trained a classifier that is not highly regularized, printed the words and weights and went through most of the non-zero weighted words (+ words that looked similar to those and many words that start with un- and dis-, etc) and created a dictionary. \n",
      "\n",
      "*  Train an expert on the test using the attached dictionary\n",
      "*  Predict the labels of the sentences in the user study and \n",
      "*  See if it gives a better model of the user than the classifiers that use all 27K words.\n",
      "\n",
      "Dictionary: ./dictoinary.txt\n"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Create a vectorizer and get feature vector representation\n",
      "from sklearn.feature_extraction.text import  TfidfVectorizer\n",
      "\n",
      "vocab = open(\"../../data/vocab.txt\").readlines()\n",
      "vocab = np.array([x.strip() for x in vocab])\n",
      "\n",
      "\n",
      "print \"Dictionary size:\", len(vocab)\n",
      "\n",
      "#Create vectorizer and fit \n",
      "vct_dict = TfidfVectorizer(encoding='ISO-8859-1', min_df=5, max_df=1.0, binary=False, ngram_range=(1, 1), vocabulary=vocab)\n",
      "vct_dict.fit(imdb.train.data)\n",
      "exp_fix_bow = vct_dict.transform(exp_sent)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Dictionary size: 878\n"
       ]
      }
     ],
     "prompt_number": 337
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "\n",
      "## Testing User Defined Dictionary: Training on Sentences\n",
      "\n",
      "\n",
      "Sentence data to train the expert: exp_sent, exp_lbl \n",
      "\n",
      "### Configuration of the Experiment\n",
      "\n",
      "* Two classifier L1 and L2, \n",
      "* Training documents: sentences and documents to train the expert.\n",
      "* C: 1 \u2026 10^5\n",
      "* Thresholds: .4, .45, .5 (no neutrals)\n",
      "* Vectorizer trained on train split but with a fixed vocabulary \n"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def test_parameters2(clf_str, C, data, threshold, snip_bow, name=\"noname\"):\n",
      "    # print predicted values of the expert on the study snippets\n",
      "    print \"Parameters for %s and T > %s\" %(clf_str, threshold)\n",
      "    results = defaultdict(lambda: [])\n",
      "    for c in C: \n",
      "        print \"Testing ... C=\", c, \"T=\", threshold\n",
      "        expert = eval(clf_str.format(c))\n",
      "        expert.fit(data['bow'], data['target'])\n",
      "        pred = expert.predict(snip_bow)\n",
      "        prob = expert.predict_proba(snip_bow)\n",
      "        \n",
      "        results[c] = [neutral_label(threshold, p, t) for t, p in zip(pred,prob)]\n",
      "    return results\n",
      "\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 338
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Fixed Dictionary: Training on Sentences\n",
      "\n",
      "Here the result of the test shows that the expert classifies everything as class 0 with a high uncertanty. The expert is not able to learn any classes. "
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Test LRL2 sentences\n",
      "C = [pow(10,x) for x in range(1,8)]\n",
      "snip_dict = vct_dict.transform(snippets)\n",
      "data2 = {'bow':exp_fix_bow, 'target':exp_lbl}\n",
      "results = test_parameters2(\"LogisticRegression(penalty='l2', C={})\", C, data2, .4, snip_dict)\n",
      "print print_report(user_labels, results, C, .4, name=\"lrl2\")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Parameters for LogisticRegression(penalty='l2', C={}) and T > 0.4\n",
        "Testing ... C= 10 T= 0.4\n",
        "Testing ... C="
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 100 T= 0.4\n",
        "Testing ... C="
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 1000 T= 0.4\n",
        "Testing ... C="
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 10000 T= 0.4\n",
        "Testing ... C="
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 100000 T= 0.4\n",
        "Testing ... C="
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 1000000 T= 0.4\n",
        "Testing ... C="
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 10000000 T= 0.4\n",
        "\n",
        "REPORT LRL2 C=10 T=0.4"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "--------------------\n",
        "Accuracy: 0.63\n",
        "             precision    recall  f1-score   support\n",
        "\n",
        "        0.0       0.71      0.62      0.66       175\n",
        "        1.0       0.72      0.50      0.59       155\n",
        "        2.0       0.54      0.76      0.63       170\n",
        "\n",
        "avg / total       0.65      0.63      0.63       500\n",
        "\n",
        "\n",
        "Confusion Matrix\n",
        "108\t15\t52\n",
        "20\t78\t57\n",
        "25\t16\t129\n",
        "\n",
        "Distribution (%):\n",
        "Class 0: 0.31\n",
        "Class 1: 0.22\n",
        "Class 2: 0.48\n",
        "\n",
        "Non-neutral distribution (C0/C0+C1): 0.584\n",
        "\n",
        "REPORT LRL2 C=100 T=0.4\n",
        "--------------------\n",
        "Accuracy: 0.63\n",
        "             precision    recall  f1-score   support\n",
        "\n",
        "        0.0       0.71      0.62      0.66       175\n",
        "        1.0       0.72      0.50      0.59       155\n",
        "        2.0       0.54      0.76      0.63       170\n",
        "\n",
        "avg / total       0.65      0.63      0.63       500\n",
        "\n",
        "\n",
        "Confusion Matrix\n",
        "108\t15\t52\n",
        "20\t78\t57\n",
        "25\t16\t129\n",
        "\n",
        "Distribution (%):\n",
        "Class 0: 0.31\n",
        "Class 1: 0.22\n",
        "Class 2: 0.48\n",
        "\n",
        "Non-neutral distribution (C0/C0+C1): 0.584\n",
        "\n",
        "REPORT LRL2 C=1000 T=0.4\n",
        "--------------------\n",
        "Accuracy: 0.63\n",
        "             precision    recall  f1-score   support\n",
        "\n",
        "        0.0       0.71      0.62      0.66       175\n",
        "        1.0       0.72      0.50      0.59       155\n",
        "        2.0       0.54      0.76      0.63       170\n",
        "\n",
        "avg / total       0.65      0.63      0.63       500\n",
        "\n",
        "\n",
        "Confusion Matrix\n",
        "108\t15\t52\n",
        "20\t78\t57\n",
        "25\t16\t129\n",
        "\n",
        "Distribution (%):\n",
        "Class 0: 0.31\n",
        "Class 1: 0.22\n",
        "Class 2: 0.48\n",
        "\n",
        "Non-neutral distribution (C0/C0+C1): 0.584\n",
        "\n",
        "REPORT LRL2 C=10000 T=0.4\n",
        "--------------------\n",
        "Accuracy: 0.63\n",
        "             precision    recall  f1-score   support\n",
        "\n",
        "        0.0       0.71      0.62      0.66       175\n",
        "        1.0       0.72      0.50      0.59       155\n",
        "        2.0       0.54      0.76      0.63       170\n",
        "\n",
        "avg / total       0.65      0.63      0.63       500\n",
        "\n",
        "\n",
        "Confusion Matrix\n",
        "108\t15\t52\n",
        "20\t78\t57\n",
        "25\t16\t129\n",
        "\n",
        "Distribution (%):\n",
        "Class 0: 0.31\n",
        "Class 1: 0.22\n",
        "Class 2: 0.48\n",
        "\n",
        "Non-neutral distribution (C0/C0+C1): 0.584\n",
        "\n",
        "REPORT LRL2 C=100000 T=0.4\n",
        "--------------------\n",
        "Accuracy: 0.63\n",
        "             precision    recall  f1-score   support\n",
        "\n",
        "        0.0       0.71      0.62      0.66       175\n",
        "        1.0       0.72      0.50      0.59       155\n",
        "        2.0       0.54      0.76      0.63       170\n",
        "\n",
        "avg / total       0.65      0.63      0.63       500\n",
        "\n",
        "\n",
        "Confusion Matrix\n",
        "108\t15\t52\n",
        "20\t78\t57\n",
        "25\t16\t129\n",
        "\n",
        "Distribution (%):\n",
        "Class 0: 0.31\n",
        "Class 1: 0.22\n",
        "Class 2: 0.48\n",
        "\n",
        "Non-neutral distribution (C0/C0+C1): 0.584\n",
        "\n",
        "REPORT LRL2 C=1000000 T=0.4\n",
        "--------------------\n",
        "Accuracy: 0.63\n",
        "             precision    recall  f1-score   support\n",
        "\n",
        "        0.0       0.71      0.62      0.66       175\n",
        "        1.0       0.72      0.50      0.59       155\n",
        "        2.0       0.54      0.76      0.63       170\n",
        "\n",
        "avg / total       0.65      0.63      0.63       500\n",
        "\n",
        "\n",
        "Confusion Matrix\n",
        "108\t15\t52\n",
        "20\t78\t57\n",
        "25\t16\t129\n",
        "\n",
        "Distribution (%):\n",
        "Class 0: 0.31\n",
        "Class 1: 0.22\n",
        "Class 2: 0.48\n",
        "\n",
        "Non-neutral distribution (C0/C0+C1): 0.584\n",
        "\n",
        "REPORT LRL2 C=10000000 T=0.4\n",
        "--------------------\n",
        "Accuracy: 0.63\n",
        "             precision    recall  f1-score   support\n",
        "\n",
        "        0.0       0.71      0.62      0.66       175\n",
        "        1.0       0.72      0.50      0.59       155\n",
        "        2.0       0.54      0.76      0.63       170\n",
        "\n",
        "avg / total       0.65      0.63      0.63       500\n",
        "\n",
        "\n",
        "Confusion Matrix\n",
        "108\t15\t52\n",
        "20\t78\t57\n",
        "25\t16\t129\n",
        "\n",
        "Distribution (%):\n",
        "Class 0: 0.31\n",
        "Class 1: 0.22\n",
        "Class 2: 0.48\n",
        "\n",
        "Non-neutral distribution (C0/C0+C1): 0.584\n",
        "None\n"
       ]
      }
     ],
     "prompt_number": 321
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Test LRL2 sentences\n",
      "C = [pow(10,x) for x in range(-1,5)]\n",
      "snip_dict = vct_dict.transform(snippets)\n",
      "data2 = {'bow':exp_fix_bow, 'target':exp_lbl}\n",
      "results = test_parameters2(\"LogisticRegression(penalty='l2', C={})\", C, data2, .48, snip_dict)\n",
      "print print_report(user_labels, results, C, .48, name=\"lrl2\")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Parameters for LogisticRegression(penalty='l2', C={}) and T > 0.48\n",
        "Testing ... C= 0.1 T= 0.48\n",
        "Testing ... C="
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 1 T= 0.48\n",
        "Testing ... C="
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 10 T= 0.48\n",
        "Testing ... C="
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 100 T= 0.48\n",
        "Testing ... C="
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 1000 T= 0.48\n",
        "Testing ... C="
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 10000 T= 0.48\n",
        "\n",
        "REPORT LRL2 C=0.1 T=0.48"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "--------------------\n",
        "Accuracy: 0.654\n",
        "             precision    recall  f1-score   support\n",
        "\n",
        "        0.0       0.65      0.67      0.66       175\n",
        "        1.0       0.70      0.57      0.63       155\n",
        "        2.0       0.62      0.72      0.67       170\n",
        "\n",
        "avg / total       0.66      0.65      0.65       500\n",
        "\n",
        "\n",
        "Confusion Matrix\n",
        "117\t19\t39\n",
        "32\t88\t35\n",
        "30\t18\t122\n",
        "\n",
        "Distribution (%):\n",
        "Class 0: 0.36\n",
        "Class 1: 0.25\n",
        "Class 2: 0.39\n",
        "\n",
        "Non-neutral distribution (C0/C0+C1): 0.589\n",
        "\n",
        "REPORT LRL2 C=1 T=0.48\n",
        "--------------------\n",
        "Accuracy: 0.646\n",
        "             precision    recall  f1-score   support\n",
        "\n",
        "        0.0       0.64      0.66      0.65       175\n",
        "        1.0       0.68      0.57      0.62       155\n",
        "        2.0       0.62      0.70      0.66       170\n",
        "\n",
        "avg / total       0.65      0.65      0.65       500\n",
        "\n",
        "\n",
        "Confusion Matrix\n",
        "116\t21\t38\n",
        "33\t88\t34\n",
        "31\t20\t119\n",
        "\n",
        "Distribution (%):\n",
        "Class 0: 0.36\n",
        "Class 1: 0.26\n",
        "Class 2: 0.38\n",
        "\n",
        "Non-neutral distribution (C0/C0+C1): 0.583\n",
        "\n",
        "REPORT LRL2 C=10 T=0.48\n",
        "--------------------\n",
        "Accuracy: 0.644\n",
        "             precision    recall  f1-score   support\n",
        "\n",
        "        0.0       0.64      0.66      0.65       175\n",
        "        1.0       0.68      0.57      0.62       155\n",
        "        2.0       0.62      0.69      0.66       170\n",
        "\n",
        "avg / total       0.65      0.64      0.64       500\n",
        "\n",
        "\n",
        "Confusion Matrix\n",
        "116\t21\t38\n",
        "33\t88\t34\n",
        "31\t21\t118\n",
        "\n",
        "Distribution (%):\n",
        "Class 0: 0.36\n",
        "Class 1: 0.26\n",
        "Class 2: 0.38\n",
        "\n",
        "Non-neutral distribution (C0/C0+C1): 0.581\n",
        "\n",
        "REPORT LRL2 C=100 T=0.48\n",
        "--------------------\n",
        "Accuracy: 0.644\n",
        "             precision    recall  f1-score   support\n",
        "\n",
        "        0.0       0.64      0.66      0.65       175\n",
        "        1.0       0.68      0.57      0.62       155\n",
        "        2.0       0.62      0.69      0.66       170\n",
        "\n",
        "avg / total       0.65      0.64      0.64       500\n",
        "\n",
        "\n",
        "Confusion Matrix\n",
        "116\t21\t38\n",
        "33\t88\t34\n",
        "31\t21\t118\n",
        "\n",
        "Distribution (%):\n",
        "Class 0: 0.36\n",
        "Class 1: 0.26\n",
        "Class 2: 0.38\n",
        "\n",
        "Non-neutral distribution (C0/C0+C1): 0.581\n",
        "\n",
        "REPORT LRL2 C=1000 T=0.48\n",
        "--------------------\n",
        "Accuracy: 0.644\n",
        "             precision    recall  f1-score   support\n",
        "\n",
        "        0.0       0.64      0.66      0.65       175\n",
        "        1.0       0.68      0.57      0.62       155\n",
        "        2.0       0.62      0.69      0.66       170\n",
        "\n",
        "avg / total       0.65      0.64      0.64       500\n",
        "\n",
        "\n",
        "Confusion Matrix\n",
        "116\t21\t38\n",
        "33\t88\t34\n",
        "31\t21\t118\n",
        "\n",
        "Distribution (%):\n",
        "Class 0: 0.36\n",
        "Class 1: 0.26\n",
        "Class 2: 0.38\n",
        "\n",
        "Non-neutral distribution (C0/C0+C1): 0.581\n",
        "\n",
        "REPORT LRL2 C=10000 T=0.48\n",
        "--------------------\n",
        "Accuracy: 0.644\n",
        "             precision    recall  f1-score   support\n",
        "\n",
        "        0.0       0.64      0.66      0.65       175\n",
        "        1.0       0.68      0.57      0.62       155\n",
        "        2.0       0.62      0.69      0.66       170\n",
        "\n",
        "avg / total       0.65      0.64      0.64       500\n",
        "\n",
        "\n",
        "Confusion Matrix\n",
        "116\t21\t38\n",
        "33\t88\t34\n",
        "31\t21\t118\n",
        "\n",
        "Distribution (%):\n",
        "Class 0: 0.36\n",
        "Class 1: 0.26\n",
        "Class 2: 0.38\n",
        "\n",
        "Non-neutral distribution (C0/C0+C1): 0.581\n",
        "None\n"
       ]
      }
     ],
     "prompt_number": 304
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Fixed Dictionary: Training on Documents\n",
      "\n"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "C = [pow(10,x) for x in range(-1,5)]\n",
      "snip_dict = vct_dict.transform(snippets)\n",
      "data = {'bow':vct_dict.transform(imdb.test.data), 'target':imdb.test.target}\n",
      "results = test_parameters2(\"LogisticRegression(penalty='l2', C={})\", C, data, .4, snip_dict)\n",
      "print print_report(user_labels, results, C, .4, name=\"lrl2\")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Parameters for LogisticRegression(penalty='l2', C={}) and T > 0.4\n",
        "Testing ... C= 0.1 T= 0.4\n",
        "Testing ... C="
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 1 T= 0.4\n",
        "Testing ... C="
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 10 T= 0.4\n",
        "Testing ... C="
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 100 T= 0.4\n",
        "Testing ... C="
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 1000 T= 0.4\n",
        "Testing ... C="
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 10000 T= 0.4\n",
        "\n",
        "REPORT LRL2 C=0.1 T=0.4"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "--------------------\n",
        "Accuracy: 0.624\n",
        "             precision    recall  f1-score   support\n",
        "\n",
        "        0.0       0.73      0.54      0.62       175\n",
        "        1.0       0.72      0.53      0.61       155\n",
        "        2.0       0.53      0.80      0.64       170\n",
        "\n",
        "avg / total       0.66      0.62      0.62       500\n",
        "\n",
        "\n",
        "Confusion Matrix\n",
        "94\t16\t65\n",
        "17\t82\t56\n",
        "18\t16\t136\n",
        "\n",
        "Distribution (%):\n",
        "Class 0: 0.26\n",
        "Class 1: 0.23\n",
        "Class 2: 0.51\n",
        "\n",
        "Non-neutral distribution (C0/C0+C1): 0.531\n",
        "\n",
        "REPORT LRL2 C=1 T=0.4\n",
        "--------------------\n",
        "Accuracy: 0.652\n",
        "             precision    recall  f1-score   support\n",
        "\n",
        "        0.0       0.72      0.59      0.65       175\n",
        "        1.0       0.71      0.57      0.64       155\n",
        "        2.0       0.58      0.78      0.67       170\n",
        "\n",
        "avg / total       0.67      0.65      0.65       500\n",
        "\n",
        "\n",
        "Confusion Matrix\n",
        "104\t19\t52\n",
        "21\t89\t45\n",
        "20\t17\t133\n",
        "\n",
        "Distribution (%):\n",
        "Class 0: 0.29\n",
        "Class 1: 0.25\n",
        "Class 2: 0.46\n",
        "\n",
        "Non-neutral distribution (C0/C0+C1): 0.537\n",
        "\n",
        "REPORT LRL2 C=10 T=0.4\n",
        "--------------------\n",
        "Accuracy: 0.646\n",
        "             precision    recall  f1-score   support\n",
        "\n",
        "        0.0       0.71      0.59      0.64       175\n",
        "        1.0       0.67      0.59      0.63       155\n",
        "        2.0       0.59      0.76      0.66       170\n",
        "\n",
        "avg / total       0.66      0.65      0.64       500\n",
        "\n",
        "\n",
        "Confusion Matrix\n",
        "103\t25\t47\n",
        "21\t91\t43\n",
        "21\t20\t129\n",
        "\n",
        "Distribution (%):\n",
        "Class 0: 0.29\n",
        "Class 1: 0.27\n",
        "Class 2: 0.44\n",
        "\n",
        "Non-neutral distribution (C0/C0+C1): 0.516\n",
        "\n",
        "REPORT LRL2 C=100 T=0.4\n",
        "--------------------\n",
        "Accuracy: 0.644\n",
        "             precision    recall  f1-score   support\n",
        "\n",
        "        0.0       0.71      0.59      0.64       175\n",
        "        1.0       0.67      0.59      0.63       155\n",
        "        2.0       0.59      0.75      0.66       170\n",
        "\n",
        "avg / total       0.65      0.64      0.64       500\n",
        "\n",
        "\n",
        "Confusion Matrix\n",
        "103\t25\t47\n",
        "21\t91\t43\n",
        "22\t20\t128\n",
        "\n",
        "Distribution (%):\n",
        "Class 0: 0.29\n",
        "Class 1: 0.27\n",
        "Class 2: 0.44\n",
        "\n",
        "Non-neutral distribution (C0/C0+C1): 0.518\n",
        "\n",
        "REPORT LRL2 C=1000 T=0.4\n",
        "--------------------\n",
        "Accuracy: 0.644\n",
        "             precision    recall  f1-score   support\n",
        "\n",
        "        0.0       0.71      0.59      0.64       175\n",
        "        1.0       0.67      0.59      0.63       155\n",
        "        2.0       0.59      0.75      0.66       170\n",
        "\n",
        "avg / total       0.65      0.64      0.64       500\n",
        "\n",
        "\n",
        "Confusion Matrix\n",
        "103\t25\t47\n",
        "21\t91\t43\n",
        "22\t20\t128\n",
        "\n",
        "Distribution (%):\n",
        "Class 0: 0.29\n",
        "Class 1: 0.27\n",
        "Class 2: 0.44\n",
        "\n",
        "Non-neutral distribution (C0/C0+C1): 0.518\n",
        "\n",
        "REPORT LRL2 C=10000 T=0.4\n",
        "--------------------\n",
        "Accuracy: 0.644\n",
        "             precision    recall  f1-score   support\n",
        "\n",
        "        0.0       0.71      0.59      0.64       175\n",
        "        1.0       0.67      0.59      0.63       155\n",
        "        2.0       0.59      0.75      0.66       170\n",
        "\n",
        "avg / total       0.65      0.64      0.64       500\n",
        "\n",
        "\n",
        "Confusion Matrix\n",
        "103\t25\t47\n",
        "21\t91\t43\n",
        "22\t20\t128\n",
        "\n",
        "Distribution (%):\n",
        "Class 0: 0.29\n",
        "Class 1: 0.27\n",
        "Class 2: 0.44\n",
        "\n",
        "Non-neutral distribution (C0/C0+C1): 0.518\n",
        "None\n"
       ]
      }
     ],
     "prompt_number": 305
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "C = [pow(10,x) for x in range(-1,5)]\n",
      "snip_dict = vct_dict.transform(snippets)\n",
      "data = {'bow':vct_dict.transform(imdb.test.data), 'target':imdb.test.target}\n",
      "results = test_parameters2(\"LogisticRegression(penalty='l2', C={})\", C, data, .48, snip_dict)\n",
      "print print_report(user_labels, results, C, .48, name=\"lrl2\")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Parameters for LogisticRegression(penalty='l2', C={}) and T > 0.48\n",
        "Testing ... C= 0.1 T= 0.48\n",
        "Testing ... C="
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 1 T= 0.48\n",
        "Testing ... C="
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 10 T= 0.48\n",
        "Testing ... C="
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 100 T= 0.48\n",
        "Testing ... C="
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 1000 T= 0.48\n",
        "Testing ... C="
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 10000 T= 0.48\n",
        "\n",
        "REPORT LRL2 C=0.1 T=0.48"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "--------------------\n",
        "Accuracy: 0.648\n",
        "             precision    recall  f1-score   support\n",
        "\n",
        "        0.0       0.67      0.66      0.67       175\n",
        "        1.0       0.69      0.57      0.62       155\n",
        "        2.0       0.60      0.71      0.65       170\n",
        "\n",
        "avg / total       0.65      0.65      0.65       500\n",
        "\n",
        "\n",
        "Confusion Matrix\n",
        "116\t20\t39\n",
        "27\t88\t40\n",
        "30\t20\t120\n",
        "\n",
        "Distribution (%):\n",
        "Class 0: 0.35\n",
        "Class 1: 0.26\n",
        "Class 2: 0.40\n",
        "\n",
        "Non-neutral distribution (C0/C0+C1): 0.575\n",
        "\n",
        "REPORT LRL2 C=1 T=0.48\n",
        "--------------------\n",
        "Accuracy: 0.646\n",
        "             precision    recall  f1-score   support\n",
        "\n",
        "        0.0       0.65      0.66      0.65       175\n",
        "        1.0       0.66      0.60      0.63       155\n",
        "        2.0       0.63      0.68      0.65       170\n",
        "\n",
        "avg / total       0.65      0.65      0.65       500\n",
        "\n",
        "\n",
        "Confusion Matrix\n",
        "115\t25\t35\n",
        "30\t93\t32\n",
        "32\t23\t115\n",
        "\n",
        "Distribution (%):\n",
        "Class 0: 0.35\n",
        "Class 1: 0.28\n",
        "Class 2: 0.36\n",
        "\n",
        "Non-neutral distribution (C0/C0+C1): 0.557\n",
        "\n",
        "REPORT LRL2 C=10 T=0.48\n",
        "--------------------\n",
        "Accuracy: 0.48\n",
        "             precision    recall  f1-score   support\n",
        "\n",
        "        0.0       0.65      0.66      0.65       175\n",
        "        1.0       0.39      0.80      0.52       155\n",
        "        2.0       0.20      0.01      0.01       170\n",
        "\n",
        "avg / total       0.42      0.48      0.40       500\n",
        "\n",
        "\n",
        "Confusion Matrix\n",
        "115\t58\t2\n",
        "29\t124\t2\n",
        "33\t136\t1\n",
        "\n",
        "Distribution (%):\n",
        "Class 0: 0.35\n",
        "Class 1: 0.64\n",
        "Class 2: 0.01\n",
        "\n",
        "Non-neutral distribution (C0/C0+C1): 0.358\n",
        "\n",
        "REPORT LRL2 C=100 T=0.48\n",
        "--------------------\n",
        "Accuracy: 0.48\n",
        "             precision    recall  f1-score   support\n",
        "\n",
        "        0.0       0.65      0.66      0.66       175\n",
        "        1.0       0.39      0.80      0.52       155\n",
        "        2.0       0.17      0.01      0.01       170\n",
        "\n",
        "avg / total       0.41      0.48      0.40       500\n",
        "\n",
        "\n",
        "Confusion Matrix\n",
        "115\t58\t2\n",
        "28\t124\t3\n",
        "33\t136\t1\n",
        "\n",
        "Distribution (%):\n",
        "Class 0: 0.35\n",
        "Class 1: 0.64\n",
        "Class 2: 0.01\n",
        "\n",
        "Non-neutral distribution (C0/C0+C1): 0.356\n",
        "\n",
        "REPORT LRL2 C=1000 T=0.48\n",
        "--------------------\n",
        "Accuracy: 0.48\n",
        "             precision    recall  f1-score   support\n",
        "\n",
        "        0.0       0.65      0.66      0.66       175\n",
        "        1.0       0.39      0.80      0.52       155\n",
        "        2.0       0.17      0.01      0.01       170\n",
        "\n",
        "avg / total       0.41      0.48      0.40       500\n",
        "\n",
        "\n",
        "Confusion Matrix\n",
        "115\t58\t2\n",
        "28\t124\t3\n",
        "33\t136\t1\n",
        "\n",
        "Distribution (%):\n",
        "Class 0: 0.35\n",
        "Class 1: 0.64\n",
        "Class 2: 0.01\n",
        "\n",
        "Non-neutral distribution (C0/C0+C1): 0.356\n",
        "\n",
        "REPORT LRL2 C=10000 T=0.48\n",
        "--------------------\n",
        "Accuracy: 0.48\n",
        "             precision    recall  f1-score   support\n",
        "\n",
        "        0.0       0.65      0.66      0.66       175\n",
        "        1.0       0.39      0.80      0.52       155\n",
        "        2.0       0.17      0.01      0.01       170\n",
        "\n",
        "avg / total       0.41      0.48      0.40       500\n",
        "\n",
        "\n",
        "Confusion Matrix\n",
        "115\t58\t2\n",
        "28\t124\t3\n",
        "33\t136\t1\n",
        "\n",
        "Distribution (%):\n",
        "Class 0: 0.35\n",
        "Class 1: 0.64\n",
        "Class 2: 0.01\n",
        "\n",
        "Non-neutral distribution (C0/C0+C1): 0.356\n",
        "None\n"
       ]
      }
     ],
     "prompt_number": 306
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "data = {'bow':vct_dict.transform(imdb.test.data), 'target':imdb.test.target}\n",
      "results = test_parameters2(\"LogisticRegression(penalty='l1', C={})\", C, data, .475, snip_dict)\n",
      "print print_report(user_labels, results, C,.475, name=\"LRL1\")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Parameters for LogisticRegression(penalty='l1', C={}) and T > 0.475\n",
        "Testing ... C= 0.1 T= 0.475\n",
        "Testing ... C="
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 1 T= 0.475\n",
        "Testing ... C="
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 10 T= 0.475\n",
        "Testing ... C="
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 100 T= 0.475\n",
        "Testing ... C="
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 1000 T= 0.475\n",
        "Testing ... C="
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 10000 T= 0.475\n",
        "\n",
        "REPORT MNB C=0.1 T=0.475"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "--------------------\n",
        "Accuracy: 0.608\n",
        "             precision    recall  f1-score   support\n",
        "\n",
        "        0.0       0.66      0.55      0.60       175\n",
        "        1.0       0.67      0.53      0.59       155\n",
        "        2.0       0.54      0.74      0.62       170\n",
        "\n",
        "avg / total       0.62      0.61      0.61       500\n",
        "\n",
        "\n",
        "Confusion Matrix\n",
        "97\t20\t58\n",
        "25\t82\t48\n",
        "25\t20\t125\n",
        "\n",
        "Distribution (%):\n",
        "Class 0: 0.29\n",
        "Class 1: 0.24\n",
        "Class 2: 0.46\n",
        "\n",
        "Non-neutral distribution (C0/C0+C1): 0.546\n",
        "\n",
        "REPORT MNB C=1 T=0.475\n",
        "--------------------\n",
        "Accuracy: 0.64\n",
        "             precision    recall  f1-score   support\n",
        "\n",
        "        0.0       0.66      0.63      0.65       175\n",
        "        1.0       0.67      0.57      0.62       155\n",
        "        2.0       0.60      0.71      0.65       170\n",
        "\n",
        "avg / total       0.64      0.64      0.64       500\n",
        "\n",
        "\n",
        "Confusion Matrix\n",
        "111\t22\t42\n",
        "29\t88\t38\n",
        "28\t21\t121\n",
        "\n",
        "Distribution (%):\n",
        "Class 0: 0.34\n",
        "Class 1: 0.26\n",
        "Class 2: 0.40\n",
        "\n",
        "Non-neutral distribution (C0/C0+C1): 0.562\n",
        "\n",
        "REPORT MNB C=10 T=0.475\n",
        "--------------------\n",
        "Accuracy: 0.488\n",
        "             precision    recall  f1-score   support\n",
        "\n",
        "        0.0       0.70      0.62      0.66       175\n",
        "        1.0       0.39      0.81      0.53       155\n",
        "        2.0       0.41      0.06      0.11       170\n",
        "\n",
        "avg / total       0.51      0.49      0.43       500\n",
        "\n",
        "\n",
        "Confusion Matrix\n",
        "108\t58\t9\n",
        "23\t125\t7\n",
        "23\t136\t11\n",
        "\n",
        "Distribution (%):\n",
        "Class 0: 0.31\n",
        "Class 1: 0.64\n",
        "Class 2: 0.05\n",
        "\n",
        "Non-neutral distribution (C0/C0+C1): 0.326\n",
        "\n",
        "REPORT MNB C=100 T=0.475\n",
        "--------------------\n",
        "Accuracy: 0.48\n",
        "             precision    recall  f1-score   support\n",
        "\n",
        "        0.0       0.69      0.62      0.65       175\n",
        "        1.0       0.39      0.80      0.52       155\n",
        "        2.0       0.32      0.05      0.08       170\n",
        "\n",
        "avg / total       0.47      0.48      0.42       500\n",
        "\n",
        "\n",
        "Confusion Matrix\n",
        "108\t58\t9\n",
        "23\t124\t8\n",
        "26\t136\t8\n",
        "\n",
        "Distribution (%):\n",
        "Class 0: 0.31\n",
        "Class 1: 0.64\n",
        "Class 2: 0.05\n",
        "\n",
        "Non-neutral distribution (C0/C0+C1): 0.331\n",
        "\n",
        "REPORT MNB C=1000 T=0.475\n",
        "--------------------\n",
        "Accuracy: 0.48\n",
        "             precision    recall  f1-score   support\n",
        "\n",
        "        0.0       0.69      0.62      0.65       175\n",
        "        1.0       0.39      0.80      0.52       155\n",
        "        2.0       0.32      0.05      0.08       170\n",
        "\n",
        "avg / total       0.47      0.48      0.42       500\n",
        "\n",
        "\n",
        "Confusion Matrix\n",
        "108\t58\t9\n",
        "23\t124\t8\n",
        "26\t136\t8\n",
        "\n",
        "Distribution (%):\n",
        "Class 0: 0.31\n",
        "Class 1: 0.64\n",
        "Class 2: 0.05\n",
        "\n",
        "Non-neutral distribution (C0/C0+C1): 0.331\n",
        "\n",
        "REPORT MNB C=10000 T=0.475\n",
        "--------------------\n",
        "Accuracy: 0.48\n",
        "             precision    recall  f1-score   support\n",
        "\n",
        "        0.0       0.69      0.62      0.65       175\n",
        "        1.0       0.39      0.80      0.52       155\n",
        "        2.0       0.32      0.05      0.08       170\n",
        "\n",
        "avg / total       0.47      0.48      0.42       500\n",
        "\n",
        "\n",
        "Confusion Matrix\n",
        "108\t58\t9\n",
        "23\t124\t8\n",
        "26\t136\t8\n",
        "\n",
        "Distribution (%):\n",
        "Class 0: 0.31\n",
        "Class 1: 0.64\n",
        "Class 2: 0.05\n",
        "\n",
        "Non-neutral distribution (C0/C0+C1): 0.331\n",
        "None\n"
       ]
      }
     ],
     "prompt_number": 314
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn.naive_bayes import MultinomialNB\n",
      "print data['bow'].shape\n",
      "results = test_parameters2(\"MultinomialNB(alpha={})\", C, data, .475, snip_dict)\n",
      "print print_report(user_labels, results, C,.475, name=\"MNB\")\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "(25000, 721)\n",
        "Parameters for MultinomialNB(alpha={}) and T > 0.475\n",
        "Testing ... C= 0.1 T= 0.475\n",
        "Testing ... C= 1 T= 0.475\n",
        "Testing ... C= 10 T= 0.475\n",
        "Testing ... C= 100 T= 0.475\n",
        "Testing ... C= 1000 T= 0.475\n",
        "Testing ... C= 10000 T= 0.475\n",
        "\n",
        "REPORT MNB C=0.1 T=0.475"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "--------------------\n",
        "Accuracy: 0.644\n",
        "             precision    recall  f1-score   support\n",
        "\n",
        "        0.0       0.65      0.66      0.65       175\n",
        "        1.0       0.66      0.58      0.62       155\n",
        "        2.0       0.63      0.69      0.66       170\n",
        "\n",
        "avg / total       0.65      0.64      0.64       500\n",
        "\n",
        "\n",
        "Confusion Matrix\n",
        "115\t24\t36\n",
        "32\t90\t33\n",
        "31\t22\t117\n",
        "\n",
        "Distribution (%):\n",
        "Class 0: 0.36\n",
        "Class 1: 0.27\n",
        "Class 2: 0.37\n",
        "\n",
        "Non-neutral distribution (C0/C0+C1): 0.567\n",
        "\n",
        "REPORT MNB C=1 T=0.475\n",
        "--------------------\n",
        "Accuracy: 0.644\n",
        "             precision    recall  f1-score   support\n",
        "\n",
        "        0.0       0.65      0.66      0.65       175\n",
        "        1.0       0.66      0.58      0.62       155\n",
        "        2.0       0.63      0.69      0.66       170\n",
        "\n",
        "avg / total       0.65      0.64      0.64       500\n",
        "\n",
        "\n",
        "Confusion Matrix\n",
        "115\t24\t36\n",
        "32\t90\t33\n",
        "31\t22\t117\n",
        "\n",
        "Distribution (%):\n",
        "Class 0: 0.36\n",
        "Class 1: 0.27\n",
        "Class 2: 0.37\n",
        "\n",
        "Non-neutral distribution (C0/C0+C1): 0.567\n",
        "\n",
        "REPORT MNB C=10 T=0.475\n",
        "--------------------\n",
        "Accuracy: 0.648\n",
        "             precision    recall  f1-score   support\n",
        "\n",
        "        0.0       0.66      0.65      0.65       175\n",
        "        1.0       0.67      0.58      0.62       155\n",
        "        2.0       0.62      0.71      0.66       170\n",
        "\n",
        "avg / total       0.65      0.65      0.65       500\n",
        "\n",
        "\n",
        "Confusion Matrix\n",
        "113\t23\t39\n",
        "31\t90\t34\n",
        "27\t22\t121\n",
        "\n",
        "Distribution (%):\n",
        "Class 0: 0.34\n",
        "Class 1: 0.27\n",
        "Class 2: 0.39\n",
        "\n",
        "Non-neutral distribution (C0/C0+C1): 0.559\n",
        "\n",
        "REPORT MNB C=100 T=0.475\n",
        "--------------------\n",
        "Accuracy: 0.638\n",
        "             precision    recall  f1-score   support\n",
        "\n",
        "        0.0       0.67      0.62      0.64       175\n",
        "        1.0       0.70      0.55      0.62       155\n",
        "        2.0       0.58      0.74      0.65       170\n",
        "\n",
        "avg / total       0.65      0.64      0.64       500\n",
        "\n",
        "\n",
        "Confusion Matrix\n",
        "108\t18\t49\n",
        "27\t86\t42\n",
        "27\t18\t125\n",
        "\n",
        "Distribution (%):\n",
        "Class 0: 0.32\n",
        "Class 1: 0.24\n",
        "Class 2: 0.43\n",
        "\n",
        "Non-neutral distribution (C0/C0+C1): 0.570\n",
        "\n",
        "REPORT MNB C=1000 T=0.475\n",
        "--------------------\n",
        "Accuracy: 0.538\n",
        "             precision    recall  f1-score   support\n",
        "\n",
        "        0.0       0.74      0.37      0.49       175\n",
        "        1.0       0.75      0.34      0.47       155\n",
        "        2.0       0.44      0.89      0.59       170\n",
        "\n",
        "avg / total       0.64      0.54      0.52       500\n",
        "\n",
        "\n",
        "Confusion Matrix\n",
        "64\t10\t101\n",
        "12\t53\t90\n",
        "10\t8\t152\n",
        "\n",
        "Distribution (%):\n",
        "Class 0: 0.17\n",
        "Class 1: 0.14\n",
        "Class 2: 0.69\n",
        "\n",
        "Non-neutral distribution (C0/C0+C1): 0.548\n",
        "\n",
        "REPORT MNB C=10000 T=0.475\n",
        "--------------------\n",
        "Accuracy: 0.34\n",
        "             precision    recall  f1-score   support\n",
        "\n",
        "        0.0       0.00      0.00      0.00       175\n",
        "        1.0       0.00      0.00      0.00       155\n",
        "        2.0       0.34      1.00      0.51       170\n",
        "\n",
        "avg / total       0.12      0.34      0.17       500\n",
        "\n",
        "\n",
        "Confusion Matrix\n",
        "0\t0\t175\n",
        "0\t0\t155\n",
        "0\t0\t170\n",
        "\n",
        "Distribution (%):\n",
        "Class 0: 0.00\n",
        "Class 1: 0.00\n",
        "Class 2: 1.00\n",
        "Non-neutral distribution: N/A\n",
        "None\n"
       ]
      }
     ],
     "prompt_number": 318
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print docs_study[2]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "['concerning hardware, and he can be easily reached via CompuServe for non']\n"
       ]
      }
     ],
     "prompt_number": 41
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print docs[1]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "I think Washburn has very competitive prices compared to other AMI distributers,plus I liked  the fact he's a EE that knows what he's talking about\n",
        "concerning hardware, and he can be easily reached via CompuServe for non  \n",
        "critcle questions, and is very informative to his customers over the phone.\n"
       ]
      }
     ],
     "prompt_number": 42
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Load the dataset\n",
      "# print snippets into a file\n",
      "def output_test2(name, doc, lbl, snip):\n",
      "    file_name = \"./output/rnd_\" + name + \".txt\"\n",
      "    if not os.path.exists(\"./output/\"):\n",
      "        os.makedirs(\"./output\")\n",
      "    f = open(file_name, \"w\")\n",
      "    f.write(\"LABEL\\tSENT\\tDOC\\n\")\n",
      "    for a, b, c in zip(lbl, snip, doc):\n",
      "#         print \"-\" * 20\n",
      "#         print c\n",
      "        clean_doc = c.encode('utf-8')\n",
      "        clean_doc = clean_doc.replace(\"\\t\", \" \")\n",
      "        clean_doc = clean_doc.replace(\"\\r\\n\", \"<br>\")\n",
      "        clean_doc = clean_doc.replace(\"\\n\", \"<br>\")\n",
      "\n",
      "        clean_snip = b.encode('utf-8')\n",
      "        clean_snip = clean_snip.replace(\"\\t\", \" \")\n",
      "        clean_snip = clean_snip.replace(\"\\r\\n\", \"<br>\")\n",
      "        clean_snip = clean_snip.replace(\"\\n\", \"<br>\")\n",
      "\n",
      "        f.write(\"{}\\t{}\\t{}\\n\".format(a, clean_snip, clean_doc))\n",
      "    f.close()\n",
      "    \n",
      "\n",
      "rnd = np.random.RandomState(2345)\n",
      "#hardw, vct = load_data('20news', \"\", categories='hardware')\n",
      "docs, lbl, snip = select_random_snippets(hardw.train, rnd, sent_tk, n=1000)\n",
      "output_test2(\"hardware20ng\", docs,lbl, snip)\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 134
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Get the snippets from the saved file\n",
      "docs_study = load_study('./user_studies/output/rnd_hardware20ng.txt')\n",
      "lbl = [float(d[1]) for d in docs_study]\n",
      "snippets = [d[2] for d in docs_study]\n",
      "snip_bow = vct.transform(snippets)\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "ename": "ValueError",
       "evalue": "could not convert string to float: I am interested in the following topics.<br><br>1)BIOS programming on 286 and 386.<br>2)Memory management in 286 and 386.<br>3)Developing Visual Basic Custom Controls.<br><br>     I would like to have",
       "output_type": "pyerr",
       "traceback": [
        "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
        "\u001b[1;32m<ipython-input-135-00ae5a56167e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Get the snippets from the saved file\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mdocs_study\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mload_study\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'./user_studies/output/rnd_hardware20ng.txt'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mlbl\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mfloat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0md\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0md\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mdocs_study\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[0msnippets\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0md\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0md\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mdocs_study\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0msnip_bow\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mvct\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msnippets\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
        "\u001b[1;31mValueError\u001b[0m: could not convert string to float: I am interested in the following topics.<br><br>1)BIOS programming on 286 and 386.<br>2)Memory management in 286 and 386.<br>3)Developing Visual Basic Custom Controls.<br><br>     I would like to have"
       ]
      }
     ],
     "prompt_number": 135
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "docs_study[3]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 136,
       "text": [
        "array(['1',\n",
        "       \"Is there a PC like that?? And where can I get more info?<br>I know of the Atari portfolio but it can't stand the rain....<br>\",\n",
        "       \"Is there a PC like that?? And where can I get more info?<br>I know of the Atari portfolio but it can't stand the rain....<br>\"], dtype=object)"
       ]
      }
     ],
     "prompt_number": 136
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print hardw.train.target_names\n",
      "print 1. * hardw.train.target.sum() / hardw.train.target.shape[0]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "['comp.os.ms-windows.misc', 'comp.sys.ibm.pc.hardware']\n",
        "0.508413461538\n"
       ]
      }
     ],
     "prompt_number": 154
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Study with Full Documents"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#Get Human oracle labels\n",
      "f = open(\"./user_studies/output/user1_rnd_hardw_labels.txt\")\n",
      "hw_labels = np.loadtxt(f)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 138
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print \"Accuracy: \",metrics.accuracy_score(lbl[:150], hw_labels)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Accuracy:  0.746666666667\n"
       ]
      }
     ],
     "prompt_number": 139
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print hw_labels[:5]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[ 1.  1.  0.  1.  1.]\n"
       ]
      }
     ],
     "prompt_number": 140
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "cm = metrics.confusion_matrix(lbl[:150], hw_labels)\n",
      "print cm\n",
      "print \"\\t\".join(\"%.3f \" % (1. * c / cm.sum()) for c in cm.sum(0))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[[46 10 16]\n",
        " [ 7 66  5]\n",
        " [ 0  0  0]]\n",
        "0.353 \t0.507 \t0.140 \n"
       ]
      }
     ],
     "prompt_number": 153
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print metrics.classification_report(lbl[:150], hw_labels)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "             precision    recall  f1-score   support\n",
        "\n",
        "        0.0       0.87      0.64      0.74        72\n",
        "        1.0       0.87      0.85      0.86        78\n",
        "        2.0       0.00      0.00      0.00         0\n",
        "\n",
        "avg / total       0.87      0.75      0.80       150\n",
        "\n"
       ]
      }
     ],
     "prompt_number": 142
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print \"Accuracy (no neutrals): \", 1. * (cm[0][0] + cm[1][1]) / cm.sum(0)[:2].sum()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Accuracy (no neutrals):  0.868217054264\n"
       ]
      }
     ],
     "prompt_number": 143
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print len(docs)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "832\n"
       ]
      }
     ],
     "prompt_number": 129
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# Study with only Snippets\n",
      "\n",
      "Compute performance of the human annotator"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#Get Human oracle labels\n",
      "f = open(\"./user_studies/output/user1_rnd_hardw_labels_snip.txt\")\n",
      "hw2 = np.loadtxt(f)\n",
      "print \"Accuracy: \",metrics.accuracy_score(lbl[:102], hw2)\n",
      "cm = metrics.confusion_matrix(lbl[:102], hw2)\n",
      "print cm\n",
      "print \"Accuracy (no neutrals): \", 1. * (cm[0][0] + cm[1][1]) / cm.sum(0)[:2].sum()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Accuracy:  0.264705882353\n",
        "[[12 17 17]\n",
        " [13 15 28]\n",
        " [ 0  0  0]]\n",
        "Accuracy (no neutrals):  0.473684210526\n"
       ]
      }
     ],
     "prompt_number": 148
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print \"\\t\".join(\"%.3f \" % (1. * c / cm.sum()) for c in cm.sum(0))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "0.245 \t0.314 \t0.441 \n"
       ]
      }
     ],
     "prompt_number": 152
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print metrics.classification_report(lbl[:102], hw2)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "             precision    recall  f1-score   support\n",
        "\n",
        "        0.0       0.48      0.26      0.34        46\n",
        "        1.0       0.47      0.27      0.34        56\n",
        "        2.0       0.00      0.00      0.00         0\n",
        "\n",
        "avg / total       0.47      0.26      0.34       102\n",
        "\n"
       ]
      }
     ],
     "prompt_number": 155
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Extra Test"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "plt.plot([10,25,50,75,100, 200], [0.7053, 0.895522388, 0.835526316, 0.875, 0.9, 0.984455959], marker='o')\n",
      "plt.xlabel('size')\n",
      "plt.ylabel('accuracy')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 163,
       "text": [
        "<matplotlib.text.Text at 0x2a31d128>"
       ]
      },
      {
       "metadata": {},
       "output_type": "display_data",
       "png": "iVBORw0KGgoAAAANSUhEUgAAAZEAAAESCAYAAAA8BeghAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAIABJREFUeJzt3XtcVXW+8PHP5ioiIKAoV5GbMImIeRlLy0JBm5Npzumx\nSa3UxmlypjrNjE71TNYzk9KTnbGYaczpph2xc3pSqlFCKVIsoxLKWwgIinhJLgIKctl7PX8gWwmU\nDay999qL7/v1mte01l6L/eP72vjd6/v9rd8yKIqiIIQQQvSCk70HIIQQwnFJEhFCCNFrkkSEEEL0\nmiQRIYQQvSZJRAghRK9JEhFCCNFrNksiixcvZtiwYcTHx1/zmN/+9rdER0eTkJBAfn6+eX9mZiax\nsbFER0eTmppqi+EKIYSwgM2SyIMPPkhmZuY1X9++fTvFxcUUFRXx2muv8fDDDwNgNBpZvnw5mZmZ\nHD58mPT0dI4cOWKrYQshhLgOmyWRqVOn4uvre83XP/jgA+6//34AJk2axPnz5zlz5gx5eXlERUUR\nHh6Oq6sr8+fPJyMjw1bDFkIIcR2a6YlUVFQQGhpq3g4JCaGiooJTp051uV8IIYT9aSaJAMgKLEII\n4Vhc7D2AdsHBwZSXl5u3T548SUhICC0tLR32l5eXExIS0un82bNnc+nSJYYPHw6Ap6cnUVFRjB07\nFoCCggIA2bZw+7333pP4STw1ud3+31oZj6NtFxQU8PHHHwMwfPhwPD09efXVV+ktgy0XYCwrK+PO\nO+/kwIEDnV7bvn07aWlpbN++nX379vHYY4+xb98+WltbGTVqFNnZ2QQFBTFx4kTS09OJi4vrcP6i\nRYtYt26drX4V3VuzZg0rV6609zB0Q+KpHomluh599FE2btzY6/NtdiVy77338tlnn1FZWUloaCjP\nPvssLS0tACxbtow77riD7du3ExUVhaenJ2+++WbbAF1cSEtLIyUlBaPRyJIlSzolEIAzZ87Y6lfp\nF06cOGHvIeiKxFM9EkttsVkSSU9P7/aYtLS0LvfPmjWLWbNmqT0kIYQQfaSpxnpfpKSk2HsIuvKL\nX/zC3kPQFYmneiSW6kpISOjT+TbtiVhTdnY248aNs/cwhBDCoezfv5+kpKRen6+bK5GrZ2yIvsvN\nzbX3EHRF4qkeiaW26CaJCCGEsD3dJJH2+dBCHVOmTLH3EHRF4qkeiaU6duXsYdFjT/b55+gmiQgh\nhLDMrpw9rNm4jTOj/73PP0s3SUR6IuqSurO6JJ7qkVj23Vtbt+N00wJVfpZmlj0RQghhPYqi8P25\nBnYerea7M40Mv/ajnXpEN0lEeiLqkrqzuiSe6pFY9kzlxWayi2vIOlpFeW0T0PacJrXoJokIIYRo\n09xq4vPjtWQVVbG/oh7T5bsBfT1cSIryY+DwObz1/juqlLR0k0QKCgrkZkMV5ebmyjc+FUk81SOx\n7NrV5aqcYzVcaG672nBxMnDTCB+SY/wYH+KNi5MBCGb4IDc2ZbwH4+b16X11k0SEEKI/qrrYQnZx\nNVlF1Zw4f8m8P3qIB8nR/twW6Yv3gM7/1E+fNpXp06ayf//+Pr2/bpKI9ETUJd/01CXxVI/Esq1c\n9cWJWrKOVvNNRZ25XDV4gAvTo/2YEe3HSD8Pm4xFN0lECCH0TFEUCs81kFVUTU7Jj8tV3iTH+F9V\nrrId3SQR6YmoS+rO6pJ4qqe/xfJa5aoofw+SY9rKVT5dlKtsRTdJRAgh9KK51cS+E7VkFVXz9cmO\n5aqkKF9mRPsT4W+bclV3dJNEpCeirv70Tc8WJJ7q0WssFUXhaGUDWZdnV9U3dSxXzYj2Z0Ko7ctV\n3dFNEhFCCEdU1dBWrtp5tJrjPypXzYj24/YoP7uWq7qj3ZH1kPRE1NXf6s7WJvFUjx5i2Ww0se94\n53KVj7lc5Uek/0D7DtJCukkiQgihZYqiUFTZSFZRFZ+WXClXORvg5hE+JMdos1zVHd0kEemJqMvR\nv+lpjcRTPY4Wy+qGK7Orjtd0LlfdFunLYA9XO46wb3STRIQQQiuajW2zq3YerearH5Wrbo/yJdmB\nylXd0U0SkZ6IuvRQd9YSiad6tBrL65Wr2teumhDijauzbh7jBOgoiQghhD1UN7TwyeVyVdlV5apI\nfw+SdVCu6o5ukoj0RNSlxW96jkziqR4txLLZaOLLE3VkHa3SfbmqO7pJIkIIYU2KolBU1cjOo1V8\n8qNy1eQRPiRH+zExVH/lqu7oJolIT0RdWq07OyqJp3psHctrlasi/AaY167y1XG5qju6SSJCCKGW\nlvZyVVEVeeU/KldF+pIc03/KVd2xWRLJzMzksccew2g0snTpUlasWNHh9ZqaGhYvXsyxY8cYMGAA\nb7zxBjfccAMA4eHheHt74+zsjKurK3l5eZ1+vvRE1CXfmtUl8VSPtWKpKArFVY1kHa3m05Jq6qRc\nZRGbJBGj0cjy5cvZtWsXwcHBTJgwgdmzZxMXF2c+5vnnn2fcuHFs3bqVwsJCHnnkEXbt2gWAwWAg\nJycHPz8/WwxXCNGP1DS0kF1Sw86jVZReVa4a6dtWrro9qn+Xq7pjk5Sal5dHVFQU4eHhuLq6Mn/+\nfDIyMjocc+TIEW677TYARo0aRVlZGefOnTO/rijKdd+joKBA/YH3Y7m5ufYegq5IPNWjRixbjCZy\nS8/zp6wS7k0/yGtfVlBacwlvd2fm3DCUv88ZxT/ujmVefIAkkG7Y5EqkoqKC0NBQ83ZISAhffvll\nh2MSEhJ4//33mTJlCnl5eRw/fpyTJ08ydOhQDAYD06dPx9nZmWXLlvHQQw/ZYthCCB1RFIWSqkay\niqr5pPhKucrJAJPDfJgR48ckKVf1mE2SiMHQ/YJiK1eu5NFHHyUxMZH4+HgSExNxdnYG2r55BAUF\nce7cOWbMmEFsbCxTp07tcL70RNQlNXx1STzV09NY1jS28ElxDTuLqjhW3UW5KtIX34FytdFbNkki\nwcHBlJeXm7fLy8sJCQnpcIyXlxdvvPGGeXvkyJFEREQAEBQUBMDQoUOZO3cueXl5nZLIe++9xz//\n+U/CwsIA8PHxIT4+3vyBa78Elm3Zlm39b+fs3s2RHxo44x1DXnktNcVt5e7gn9zI7ZF+DKn5niBv\nd6bGx2livLbczs3NZfPmzQCEhYUREBBAUlISvWVQums2qKC1tZVRo0aRnZ1NUFAQEydOJD09vUNj\nvba2Fg8PD9zc3NiwYQN79+7lrbfeoqGhAaPRiJeXFxcvXiQ5OZlnnnmG5OTkDu+xdu1aFi9ebO1f\npd+Q+xrUJfFUz/ViWVzZ0GW5amKoN8nR/kwM88ZNylUd7N+/v09JxCZXIi4uLqSlpZGSkoLRaGTJ\nkiXExcWxfv16AJYtW8bhw4d54IEHMBgMjB49mtdffx2As2fPMnfuXKAtGd13332dEogQov+qaWzh\n05Iaso5Wc6y60bw//HK5KknKVVZlkysRW8jOzpY71oXoJ1qMJvLK68gqqibvRC3Gy/+Kebk7c3uk\nH8kxfkT5e1jUj+3vHOJKRAgh1FBS1UDW0Wo+Kamh9lIr0FaumhTqTXKMP5OkXGVzukkisnaWuqSG\nry6JZ++db2zhk6vKVXUlBXhHjmWE7wBSov24PcoPPylX2Y1ukogQQj9aTQp55bVkHa3myx+Vq8aM\n8OGXc0YRLeUqTdBNEpH7RNQl35rVJfG0TElV++yq65Wrxth5lOJqukkiQgjHdL59dlVRNSVVV2ZX\njfAdQHK0H0lSrtI03SQR6YmoS2r46pJ4dnS9ctVtkb4kR/sTPaTrcpXEUlt0k0SEENp3rKqRrKIq\nsrsoV82I8eOnYT4yu8rB6CaJSE9EXfJNT139OZ61l1r5pLianUXVFF9drho8gOSYttlV/j0oV/Xn\nWGqRbpKIEEI7Wk0KX5XXkXW0ii/L62i9/GhAS8pVwrHoJolIT0RdUndWV3+Jpy3KVf0llo5CN0lE\nCGEf1ytXzYhpm13Vk3KVcCy6SSLSE1GXfNNTl97iea1y1SC3y+WqGD9ihgy0SrlKb7F0dLpJIkII\n6yutbiTraFu56vxV5aq2pdYvl6tcZHZVf6KbJCI9EXVJ3VldjhzP2kutl5dar+pQrgq7PLsqKdIP\nf0/blascOZZ6pJskIoRQT3u5amdRFftOdCxXTYv0JTnaj1FDrVOuEo5FN0lEeiLqkm966nKUeF6r\nXDUhxJvkGD8ma6Bc5Six7C90k0SEEL1T116uKqqiqPJKuSrUx52UGP+22VU2LFcJx6KbJCI9EXVJ\n3VldWoun0aTw1ck6so5Ws+9ErUOVq7QWy/5ON0lECNG90upGdhZVk11cTU3jlXLV+BAvkqP9uWmE\n/ctVwrHoJolIT0Rd8k1PXfaM5/XKVckx/iRF+TLE081u4+sp+Wxqi26SiBDiCqNJ4euTdWQVVbPv\neC0tl8tVnm7O3Bbhy4wYP2I1Wq4SjkU3SUR6IuqSurO6bBXPsppGso5eu1w1eYQP7g5erpLPprbo\nJokI0V/VXWol51gNWUerOVrZYN4f4uNOcowf06P8HKpcJRyLbpKI9ETUJd/01KV2PI0mhW8q6vj4\naOdy1bSIwSTH+Ou2XCWfTW3RTRIRoj8oq2lk5+VyVfXlcpWBtnLVjMuzqxy9XCUci26SiPRE1CV1\nZ3X1JZ7t5aqdRdUUnutcrkqK8mNoPypXyWdTW3STRITQk/ZyVdbRar64qlw10NXp8s2A/sQF6LNc\nJRyLbpKI9ETUJd/01GVpPI9fNbvq6nLVjcFeJMf4cdOIwf2+XCWfTW3RTRIRwlHVN7WSU1JDVhfl\nqhnRfkyP7l/lKuFYbPaVJjMzk9jYWKKjo0lNTe30ek1NDXPnziUhIYFJkyZx6NAhi8+Ftp6IUE9u\nbq69h6ArP46n0aSQV17LX7JLmf9fB3nl85MUnmtgoKsTd8T689c7Y3j953HcO3a4JJAfkc+mttjk\nSsRoNLJ8+XJ27dpFcHAwEyZMYPbs2cTFxZmPef755xk3bhxbt26lsLCQRx55hF27dll0rhBatStn\nDxu37eDs6dMMe287s6YncTEgll3F1VQ3XClXjQv2Ijnaj5vCBzOgn5erhGOxSRLJy8sjKiqK8PBw\nAObPn09GRkaHRHDkyBFWrlwJwKhRoygrK+OHH36gpKSk23NBeiJqk7pz3+3K2cOajdtwumkBjIYz\nwP9563V8YibgFTGGYO8rs6sCBsnVhqXks6ktNvnKU1FRQWhoqHk7JCSEioqKDsckJCTw/vvvA21J\n5/jx45w8edKic4XQovX/81FbArlKyMwluFV8y3/eGc0b/95WrpIEIhyZTa5ELJmGuHLlSh599FES\nExOJj48nMTERZ2dni6cwrlu3Dk9PT8LCwgDw8fEhPj7e/K2lvY5qr+11aX/n49wv8RkWiqvBxI1R\nIdw4doxmxvfj7VdffVVT8XOU7ZtvvplvKup55b93kF94nIhEADiz5z0GBkXhHTmWoMEDqSkqYG+R\n/cfriNtX90S0MB5H287NzWXz5s0AhIWFERAQQFJSEr1lUBRF6fXZFtq3bx+rVq0iMzMTgNWrV+Pk\n5MSKFSuuec7IkSM5cOAABw8etOjctWvXsnjxYuv9En3Qoaxxmenzd1i5aA7Tp02148iuTW7o6pnm\nVhPZJTW8f/AHjtdcAuD0x28QmNL2mawrKcA7sq3kGnjoPd7+z7/YbayOTj6b6tq/f3+fkohNylnj\nx4+nqKiIsrIympubeffdd5k9e3aHY2pra2lubgZgw4YN3HrrrQwaNMiic0HbPZGN23Z0Kms43bSA\nTRmZdhpR9+SP1DI1jS1s2n+a+7Yc4j/3nOB4zSX8B7ry4PhA/vLQPEyfvwNgTiCmvZtYeNdMew7Z\n4clnU1tsUs5ycXEhLS2NlJQUjEYjS5YsIS4ujvXr1wOwbNkyDh8+zAMPPIDBYGD06NG8/vrr1z3X\nkbQoXefqZpPcbeyoymoaef/AObJLqmkxtl3MR/l7cPfoAG6NGIyrsxMwnIFuzmzKeI9mkwE3J4WF\n98/V7NWnEL1hk3KWLWi5nLXosSc5M/rfO+3XcllDSgadKYrCNxX1vH/wB74+WQ+0Tc/9aZgPd48e\nypjAQdfs4Uk81SOxVFdfy1lyx7oNLJozi2f++Tae0+437zu5459MvlPKGo6gq36Hu4sTydF+zB09\nlBCfAXYeoRD2o5skouWeyPRpU8k6WsW/Pn6TYV7uDHQx4DNqIl+0hrD9+0ruiB1i7yF2It/02vod\nHx2p5IPDldRearsx0H+gK3fdMIQ7Rg3Be4Dlfz4ST/VILLVFN0lE69xGxBOcMoKnk8K5ZaQvHxw+\nR9rnJ1mXW85AV2emRfrae4jiMsv6HUIIsOHaWdam9bWzjlU3AhDh5wHA7J8M5cHxgShAak4ZeeW1\ndhxdZ/1tfSJFUfj6ZB1PZhbzy//3PZlHq2g1KkwO8+HFn0XxtzmjmB7t1+sE0t/iaU0SS22RKxEb\nqG9qpfJiC+7OBgK93M375ycM40KTkf858APP7Srl+ZlRjAkcZMeR9j/S7xCib3STRLTcEym7/I/T\nCF8PnJ2uzN4xGAwsnRjEhWYjOwqr+FNWCS/8LJqYIQPtNVQzvded1ex3WELv8bQliaW26CaJaFnp\n5VLWSL/O32oNBgO/vTmUhhYjnx07z5M7iln7b9GM8PWw9TD7Bel3CKEui/5i5syZw9atW2lpabH2\neHpNyz2R9iQSfo3E4Oxk4A+3jmBiqDd1TUZW7ijhdH2TLYfYiZ7qztbud1hCT/G0N4mltlj0V3PL\nLbfw3HPPMWzYMB5++GE+//xza49LV0qr28pZ7U31rrg6O/F00kjihw+iqqGFP+4opqpBu0nbETS3\nmthRWMUv3/+eJzNL+PpkPe4uTtwZN4TX/z2OZ5MjGBPoJc8pF6IPenTH+qFDh9i0aRPp6em4ubmx\nYMECFixYQGRkpDXHaJHs7GzGjRtn72F0oigKczd+R0OLiXfvG42vh+t1j7/YbOQP24soqmwk3HcA\nL/4sWvX6vN7Zut8hhCOz6QKMN9xwA2vWrGHTpk14eHjw3HPPkZiYyPTp0/n22297PQg9O3uhmYYW\nE74eLt0mEABPN2eenxlF2OABlNVc4qmPS2hoNtpgpI6vrKaRl3afYMGWQ2zaf4baS61E+Xvwh1tH\nsPF//YT5CcMlgQihMov/or7//nveeecdNm/ejJubGwsXLmThwoUMHTqUV199lTlz5lBaWmrNsV5X\nQUGBJq9E2ktZ1+qHdMVngAtrZkXy+IdFFJ5rYNWuY/w5ORI3Gz42VevrE7U/drZFMdDQ1Ip3zI2c\n9Y4G2tazmhzmw7z4ocQPv/Z6Vrak9Xg6EomltliURMaPH09paSn33HMPmzdv5qc//WmH1//jP/6D\nl19+2SoDdHSl5psMe3a/wRBPN9bMiuKJj45ScOoCf/m0jP+dNBIXJ/v/g2hvu3L2sObtbTjdfGV5\n/aLM1/GPbeSeWbfL/R1C2JBFX21XrFjB6dOnefXVVzslkHZlZWVqjqvHtHqfyJXpvT2fshvs487q\nWVF4uTvzxfFa1u4+jslGiy5r+ZveP9/7V4cEAm2PnQ2rL+Q3N4dqMoFoOZ6ORmKpLRYlEW9v706l\nqsLCQnbu3GmVQelJ6eUbDcN7kUSgLfn8OSWSAS5OZBfX8PcvTqKT1ft75dOSGg6fu9Tlayb9rOIj\nhMOw6K/ukUcewcvLq8O+QYMG8cgjj1hlUL2hxftEmltNnKy9hJMBRgzu/bfjuABPnk2OwNXZwAeH\nK3nrm9MqjrJrWpuLf6GpldWflrH60zKMxq4nGrg5aTe5ai2ejkxiqS0WJZFz584RFBTUYV9gYCBn\nzpyxyqD04sT5S5gUCPJ2x72PTfHEIC+euj0cJwOkF5zlv787q9Iote/bU/Use/97Pi2pwd3FiYVz\nZmLa+06HY+Sxs0LYh0WN9ZEjR5Kdnd1hLnFOTg4jR4602sB6Sos9kdKajiv39tVNIwbzu1tG8MJn\nx/ln3ikGuTlb7VkkWqg7NxtNbPzmNP/z3Q8owKihA1k5bQTBPgmMD/F2qMfOaiGeeiGx1BaLksiz\nzz7LvHnzWLJkCZGRkRQXF/Pmm2/y5ptvWnt8Ds08vVelJAIwPdqPhhaj7p9FUlbTyJpPj3OsuhEn\nA9w3dji/SBxunp02fdpUTScNIfoLi2osd911F1lZWVy4cIF//etfNDQ0kJWVxZw5c6w9PotpsSfS\n2+m93bHFs0jsVXc2KQpbD/7AI9sKOVbdSJC3Gy/9WwyLbgx06OnNUsdXj8RSWyy+2XDixIlMnDjR\nmmPRHfP0XiusyKvHZ5FUXmzmxd0n2F9RD8CsUf786qfBeLg623lkQohrsTiJ5Ofns2fPHqqqqjpM\nMX3uueesMrCe0lpP5HxjC9WNrQxwcWKYl5vqP9/azyKxdd15d2kN63LLqW8y4jPAhcemhHJz+GCb\njsGapI6vHomltlhUznrttdeYMmUKn376KWvWrOHAgQOsXbuW4uJia4/PYbXfHzLSbwBOVlp2o/1Z\nJLdGDKahxcSTO4o5frmZ7yguNhv5v58d58/ZZdQ3GZkQ4s36u2N1lUCE0DOLkkhqaio7duxg69at\nDBw4kK1bt/Lee+/h4qKdxey01hMp6+YZImpxdjKwYlo4k1R+Fokt6s4Hz1zgV+9/z86iatycDSy/\nKYQ/p0TgN7D7hSodjdTx1SOx1BaL7xO55ZZb2k5wcsJoNDJz5kw+/PBDqw7OkVnyDBG1uDgZHOpZ\nJC1GE29+dYrf/auIsxeaifL34O9zY5n9k6GaWCxRCGE5i5JISEiIedmT6OhoMjIy2LNnD+7u7lYd\nXE9orSfSfo9IV4/EtQZ3FyeeS44geogHp+qa+eOOYuouP0ujN6xVdz5x/hKPfnCU9G/bbpa8N2EY\n62bHENaHO/odgdTx1SOx1BaLksjvf/97jhw5AsAzzzzDggULuP322/nTn/5k1cE5KqNJoaym50vA\n95WWn0WiKAofHD7HI1u/p7iqkWGD3HjxZ9E8OCFInmsuhAPr9q9XURRuueUWkpOTAZg1axY1NTXU\n1NTw61//2uoDtJSWeiJn6ptoajUxZKCrzR+C1P4skmGD3MzPImluNfX456hZd65uaOHpj4+R9vlJ\nmowKM6L9+MfdsYwe7thTkntC6vjqkVhqi0VfAePj43FyunKou7t7pwUZu5OZmUlsbCzR0dGkpqZ2\ner2yspKZM2cyduxYRo8ezVtvvWV+LTw8nDFjxpCYmOgQ96pcuVPdPiWaIZ5upN4RhZ+Hi/lZJK0m\n+yxOuLfsPMve/56vTtbh5e7M00nh/P7WEXi6yb0fQuhBt0nEYDCQmJhIYWFhr9/EaDSyfPlyMjMz\nOXz4MOnp6ebyWLu0tDQSExMpKCggJyeHJ554gtbWVvMYcnJyyM/PJy8vr8v30FJPRO01s3ojyLtv\nzyLpa925scXIS7tP8OyuUmovtTIu2Iv1d8dyy0j9LdFiCanjq0diqS0W1Vpuu+02Zs2axQMPPEBo\naCgGgwFFUTAYDCxevLjb8/Py8oiKiiI8PByA+fPnk5GRQVxcnPmYwMBAvvvuOwDq6urw9/fvMIXY\nkZ6hUWqj6b3dGennwV9SIlmxo5js4ho83Zx5ZHKI1WdAHT57kRc+K+NUXTOuzgaWTgjirhuGWu1+\nGSGE/VhUzsrNzSU8PJzPPvuMd955h02bNpn/3xIVFRWEhoaat0NCQqioqOhwzEMPPcShQ4cICgoi\nISGBdevWmV8zGAxMnz6d8ePHs2HDhi7fQ0s9EVtO7+1ObIAnz87o+bNIelN3bjUpbPzmNP/x0VFO\n1TUT4efB3+aMYu7ogH6fQKSOrx6JpbZYdCWSk5PTpzex5Jvv888/z9ixY8nJyaGkpIQZM2bw7bff\n4uXlxd69ewkMDOTcuXPMmDGD2NhYpk7tuILrZ599xtdff01YWBgAPj4+xMfHmy992z941t6+cdJk\nTtU1cfFYAScO1RNx+f4aW71/V9tjg7yY7X2Wt785RTpj8XRzJqiu6LrnHzhwoEfvt+3jT9hccJbz\n/rEYgBuV4yQP8SPcN9buv78WtnsaT9mWbWtt5+bmsnnzZgDCwsIICAjo8JiPnjIoFtSJTKZrz+65\nuuF+Lfv27WPVqlVkZmYCsHr1apycnFixYoX5mDvuuIOnnnqKm2++GYCkpCRSU1MZP358h5/17LPP\nMmjQIJ544okO+7Ozsxk3bly3Y7G2wnMX+U3GUUb4DmDDvLjuT7Ch7OJqXsg5jgI8NiVUlWeRKIrC\n9sIq/rGvgqZWEwGDXPnDrSMYE9iziRdCCPvYv39/n5KIReUsFxeXLv/n6mrZ8hTjx4+nqKiIsrIy\nmpubeffdd5k9e3aHY2JjY9m1axcAZ8+epbCwkIiICBoaGqivb1vV9eLFi2RlZREfH9+T39Gmjmmo\nlPVjSVF+PHJTCADrcsvJKanp08+raWzhmZ3HWJdbTlOridsjffnH3FhJIEL0IxaVs44dO9Zh+8yZ\nM6xevZo777zTsjdxcSEtLY2UlBSMRiNLliwhLi6O9evXA7Bs2TKefPJJHnzwQRISEjCZTLzwwgv4\n+flx7Ngx7r77bgBaW1u57777zPesXK2goEATVyJX1szS5h3Ys38ylIvNRt78+jSpOWUMdHNiYqhP\np+Nyc3OvOwtm34laXtp9gvOXWvF0c+a3N4dwW6SfNYfu0LqLp7CcxFJbLEoi7bOqrt7euHEjEyZM\nYOnSpRa90axZs5g1a1aHfcuWLTP/95AhQ7pciysiIkJTTfPuaGF6b3fmJwzjYrOR//6u588iaWwx\nsuHLU3z0fSUACYGD+P2tIwgYpP5y90II7ev1ehN1dXWcO3dOzbH0iRbuE1EUxTwza6SGk4jBYGDJ\nhCDuiPWn2ajwp6wSjlY2dDimq296hecu8si2Qj76vhJXJwO/nBhE6h1RkkAsIN+c1SOx1BaLrkQW\nLlzYYbuhoYHdu3dz3333WWVQjqqmsZXay+WdoZ7aXs7cYDDwm5tCaWg2knPsPE/uKGbtv0Uzoot7\nW4wmhS3f6IzBAAAW7UlEQVTfnuWd/acxKm2lupXTwonw126iFELYhkVXIpGRkURFRREZGUlkZCST\nJ08mPT2dtLQ0a4/PYlooeR0zPw53gEMsae7sZOAP13gWSfuUwFN1TTzxURFvf9OWQOaNHkraXaMk\ngfSQ3NugHomltlh0JbJq1SorD0MfzE11DZeyfqz9WSRPZpZw4MwFlq77H7zPHqL6h9M4v53BxeGj\ncR8xhiEDXfn9rSNIDJaZV0KIKyy6EvnNb37D559/3mHf559/zmOPPWaVQfWGFnoi7Y/E1XJTvSvt\nzyLxqvye0oJ9VCXcgzLjUVon/YJzR75ixMVi/nF3rCSQPpA6vnokltpiURJJT0/nxhtv7LBv3Lhx\n/Nd//ZdVBuWoSq8qZzkaTzdn3Cu+I2Tmkg77Q2YuoamswOZL2gshHINFScTJyanTXesmk0lTiyLa\nuydiNCkcP9++BLxjXYm0U5yuLM9eV3Ilni0m7fd3tE7q+OqRWGqLRUlkypQpPP300+ZEYjQaeeaZ\nZzqtX9WfVdQ20WJUGDbIzWGfleFq6Hp5Gzcn7XxZEEJoi0VJZN26dezatYvhw4czYcIEgoKC2Llz\nJy+//LK1x2cxe/dEbP1MdWtYNGcWps/fAcA7si2epr2bWHjXTHsOSxekjq8eiaW2WFToDg0NZf/+\n/eTl5VFeXk5oaCiTJk2yaPHF/uLK9F7HLGUBTJ/WdmW5KeM9mk0G3JwUFt4/17xfCCF+zKIkkp+f\nj7+/P5MnT2by5MkAnDhxgpqaGhISEqw6QEvZe+2ssmrH7oe0mz5tKtOnTZX1iVQm8VSPxFJbLLqU\nWLBgAS0tLR32NTc3d7qTvT+7smaW45azhBCipyxKIuXl5URGRnbYFxkZSWlpqVUG1Rv27Ik0NBs5\nU9+Mq5OBYB99JBH5pqcuiad6JJbaYlESCQkJ4ZtvvumwLz8/n+DgYKsMytGUXb7JMMx3AC5OMh1W\nCNF/WJREHn/8ce666y5eeeUVtm/fzssvv8ycOXN4/PHHrT0+i9nzPpFjDnyT4bXIXHx1STzVI7HU\nFosa6w899BCDBw/m9ddfN8/Oeumll/j5z39u7fE5hLIax1szSwgh1GDxWhZTp07F3d2dyspKFEWh\nrq6ON954g8WLF1tzfBazZ0+k/UrE0dbMuh6pO6tL4qkeiaW2WJREtm3bxoIFC4iOjubgwYOMHj2a\ngwcPMmXKFM0kEXtRFMU8vdeR7xERQojesKgn8tRTT/HGG2+Qn5/PoEGDyM/P57XXXtPEM83b2asn\nUtnQwoVmI97uzvgN1M8ihVJ3VpfEUz0SS22xeIrvPffcY95WFIVFixaxceNGqw3MUZhX7vXzcIgH\nUQkhhJosSiIBAQGcOXMGgPDwcL744gtKSko6rexrT/bqiTjCM9V7Q+rO6pJ4qkdiqS0WJZGlS5ea\nLyEff/xxbr/9dhISEnj44YetOjhHoMfpvUIIYSmLksjKlSvN03kXLVpEYWEh33zzDX/+85+tOrie\nsFdPxBEfiWsJqTurS+KpHomltvSqEzxixAi1x+GQWowmymubMADhciUihOiHdLOWuz16Iidrm2g1\nKQR6u+Hh6pgPoroWqTurS+KpHomltugmidhDqQ6eISKEEH2hmyRij57I1dN79UbqzuqSeKpHYqkt\nukki9lBao8/pvUIIYSmbJZHMzExiY2OJjo4mNTW10+uVlZXMnDmTsWPHMnr0aN566y2LzwX79ETM\n03t1+CAqqTurS+KpHomlttgkiRiNRpYvX05mZiaHDx8mPT2dI0eOdDgmLS2NxMRECgoKyMnJ4Ykn\nnqC1tdWic+2hvqmVyostuDsbCPRyt/dwhBDCLmySRPLy8oiKiiI8PBxXV1fmz59PRkZGh2MCAwOp\nq6sDoK6uDn9/f1xcXCw6F2zfE2l/ENUIXw+cdfggKqk7q0viqR6JpbbYJIlUVFQQGhpq3g4JCaGi\noqLDMQ899BCHDh0iKCiIhIQE1q1bZ/G59lCq41KWEEJYyibLzlqyMOHzzz/P2LFjycnJoaSkhBkz\nZvDtt99a/B7FxcX8+te/JiwsDAAfHx/i4+PN9dP2by9qbX/62W7qTtQx8qc/s8rPt/d2+z6tjMfR\ntyWe6m1PmTJFU+NxtO3c3Fw2b94MQFhYGAEBASQlJdFbBkVRlF6fbaF9+/axatUqMjMzAVi9ejVO\nTk6sWLHCfMwdd9zBU089xc033wxAUlISqamptLa2dnsuQHZ2tk2Xpn/sg6Mc/uEiqbOiSAz2stn7\nCiGEmvbv39+nJGKTctb48eMpKiqirKyM5uZm3n33XWbPnt3hmNjYWHbt2gXA2bNnKSwsJCIiwqJz\nwbY9EZOimB+Jq9dyltSd1SXxVI/EUltsUs5ycXEhLS2NlJQUjEYjS5YsIS4ujvXr1wOwbNkynnzy\nSR588EESEhIwmUy88MIL+Pn5AXR5rj2dvdBMQ4sJXw8XBnu42nUsQghhTzYpZ9mCLctZXxyv5Zmd\nx0gM8iL1jiibvKcQQliDQ5Sz9KZ9ZlaETktZQghhKd0kEVv2RPS8ZlY7qTurS+KpHomltugmidiS\nrJklhBBtdJNEbLV2VnOriZO1l3AyQNhg/ZazZH0idUk81SOx1BbdJBFbOXH+EiYFgr3dcXeR8Akh\n+jfd/Ctoq55IaY3++yEgdWe1STzVI7HUFt0kEVsprW7rh4TrPIkIIYQldJNEbNUT6S/Te6XurC6J\np3okltqimyRiK/JcdSGEuEI3ScQWPZHzjS1UN7bi4erEMC83q7+fPUndWV0ST/VILLVFN0nEFtrv\nDwn3HYCTBcvbCyGE3ukmidiiJ1J2uZQV3g9KWVJ3VpfEUz0SS23RTRKxhfaZWREyM0sIIQAdJRFb\n9ERKdf4MkatJ3VldEk/1SCy1RTdJxNqMJoUyc09ErkSEEAJ0lESs3RM5U99EU6uJIQNd8R5gk2d5\n2ZXUndUl8VSPxFJbdJNErK29H6L35U6EEKIndJNErN0TOVbdf/ohIHVntUk81SOx1BbdJBFrK6vp\nP9N7hRDCUrpJItbuifS36b1Sd1aXxFM9Ektt0U0SsabGFiOn6ppwNkDoYHd7D0cIITRDN0nEmj2R\nE+cvoQChgwfg6qybkF2X1J3VJfFUj8RSW/rHv4h9dExmZgkhRJd0k0Ss2RMp62czs0DqzmqTeKpH\nYqktukki1mRe7kRmZgkhRAe6SSLW6okoitIvbzSUurO6JJ7qkVhqi26SiLXUNLZSe6kVTzdnhnq6\n2ns4QgihKbpJItbqiZjvVPcdgKEfPYhK6s7qkniqR2KpLTZLIpmZmcTGxhIdHU1qamqn11988UUS\nExNJTEwkPj4eFxcXzp8/D0B4eDhjxowhMTGRiRMn2mrIwNVN9f5TyhJCCEvZJIkYjUaWL19OZmYm\nhw8fJj09nSNHjnQ45ne/+x35+fnk5+ezevVqpk2bxuDBgwEwGAzk5OSQn59PXl5el+9hrZ7IsZr+\n1w8BqTurTeKpHomlttgkieTl5REVFUV4eDiurq7Mnz+fjIyMax6/efNm7r333g77FEWx9jC71B+n\n9wohhKVskkQqKioIDQ01b4eEhFBRUdHlsQ0NDXz88cfMmzfPvM9gMDB9+nTGjx/Phg0bujzPGj0R\no0nh+Pn++SAqqTurS+KpHomlttjk6Uo9aUh/+OGHTJkyxVzKAti7dy+BgYGcO3eOGTNmEBsby9Sp\nU60x1A4qaptoMSoMG+SGp5uz1d9PCCEcjU2SSHBwMOXl5ebt8vJyQkJCujx2y5YtnUpZgYGBAAwd\nOpS5c+eSl5fXKYmsW7cOT09PwsLCAPDx8SE+Pt78raW9jtqT7W9P1QPDGek3oFfnO/L2q6++2uf4\nybbE0xrbV/dEtDAeR9vOzc1l8+bNAISFhREQEEBSUhK9ZVBs0GxobW1l1KhRZGdnExQUxMSJE0lP\nTycuLq7DcbW1tURERHDy5Ek8PNrKRw0NDRiNRry8vLh48SLJyck888wzJCcndzh37dq1LF68WNVx\nv/n1KdILznJvwjAenBCk6s/WutzcXCkbqEjiqR6Jpbr279/fpyRikysRFxcX0tLSSElJwWg0smTJ\nEuLi4li/fj0Ay5YtA2Dbtm2kpKSYEwjA2bNnmTt3LtCWjO67775OCQSs0xMp64d3qreTP1J1STzV\nI7HUFptcidhCdnY248aNU/VnLtxyiLMXmtkwL5YR/ayxLoToH/p6JaKbO9bVvk+kodnI2QvNuDoZ\nCPbpf9N7ZS6+uiSe6pFYaotukojayi7fZBjmOwAXp/6z3IkQQvSEbpKI2j2Rq9fM6o+k7qwuiad6\nJJbaopskorayGlkzSwghuqObJKJ2T+RYP194UerO6pJ4qkdiqS26SSJqUhSlX0/vFUIIS+kmiajZ\nE6lsaOFCsxFvd2f8PGxyK43mSN1ZXRJP9UgstUU3SURNpVeVsvrTg6iEEKKndJNE1OyJ9Mdnqv+Y\n1J3VJfFUj8RSW3STRNTU36f3CiGEpXSTRNTsicgjcaXurDaJp3okltqimySilhajiRPnL2EARsiV\niBBCXJdukohaPZGTtU0YFQj0dsfDtf8+iErqzuqSeKpHYqktukkiaimVfogQQlhMN0lErZ5IqfRD\nAKk7q03iqR6JpbboJomopbRGpvcKIYSldJNE1OqJXFkzq3+Xs6TurC6Jp3okltqimySihvqmViov\ntuDubCDQy93ewxFCCM3TTRJRoyfSfqf6CF8PnPv5g6ik7qwuiad6JJbaopskooYrzxDp36UsIYSw\nlG6SiBo9EZmZdYXUndUl8VSPxFJbdJNE1GBeeNFXkogQQlhCN0mkrz0Rk6JIOesqUndWl8RTPRJL\nbdFNEumrsxeaaWgx4evhwmAPV3sPRwghHIJukkhfeyLyONyOpO6sLomneiSW2qKbJNJXsmaWEEL0\nnG4eIN6XnsiunD38/fX3qWlS+OBLVyIvzWb6tKkqjs7xSN1ZXRJP9UgstUU3SaS3duXsYc3GbQy8\ndREDgRZgzcZ3APp9IhFCiO7YrJyVmZlJbGws0dHRpKamdnr9xRdfJDExkcTEROLj43FxceH8+fMW\nnQu974ls3LYDp5sWdNjndNMCNmVk9urn6YXUndUl8VSPxFJbbJJEjEYjy5cvJzMzk8OHD5Oens6R\nI0c6HPO73/2O/Px88vPzWb16NdOmTWPw4MEWnQtQXFzcq7G1KF2HoNnUv5c9OXDggL2HoCsST/VI\nLNXV10lJNkkieXl5REVFER4ejqurK/PnzycjI+Oax2/evJl77723R+devHixV2NzNZi63O/mpPTq\n5+lFbW2tvYegKxJP9Ugs1fXtt9/26XybJJGKigpCQ0PN2yEhIVRUVHR5bENDAx9//DHz5s3r8bm9\nsWjOLEyfv9Nhn2nvJhbeNVO19xBCCL2ySWPdYLC8NPThhx8yZcoUBg8e3KNzz5w506uxtTfPN2W8\nR7PJgJuTwsL75/b7pvqJEyfsPQRdkXiqR2KpLTZJIsHBwZSXl5u3y8vLCQkJ6fLYLVu2mEtZPTk3\nMjKSRx991LydkJBg8bRfP29PHl04r8O+/fv3W3SuXo0fP77fx0BNEk/1SCz7pqCgoEMJy9PTs08/\nz6AoitWL/62trYwaNYrs7GyCgoKYOHEi6enpxMXFdTiutraWiIgITp48iYeHR4/OFUIIYXs2uRJx\ncXEhLS2NlJQUjEYjS5YsIS4ujvXr1wOwbNkyALZt20ZKSoo5gVzvXCGEEPZnkysRIYQQ+qSLtbMs\nuRlRXFt4eDhjxowhMTGRiRMnAlBdXc2MGTOIiYkhOTnZfOOn6Gzx4sUMGzaM+Ph4877rxW/16tVE\nR0cTGxtLVlaWPYasaV3Fc9WqVYSEhJhvSN6xY4f5NYnntZWXl3Pbbbdxww03MHr0aF5++WVA5c+n\n4uBaW1uVyMhIpbS0VGlublYSEhKUw4cP23tYDiU8PFypqqrqsO/3v/+9kpqaqiiKoqxZs0ZZsWKF\nPYbmEHbv3q3s379fGT16tHnfteJ36NAhJSEhQWlublZKS0uVyMhIxWg02mXcWtVVPFetWqWsXbu2\n07ESz+s7ffq0kp+fryiKotTX1ysxMTHK4cOHVf18OvyVSE9vZBRdU35U1fzggw+4//77Abj//vvZ\ntm2bPYblEKZOnYqvr2+HfdeKX0ZGBvfeey+urq6Eh4cTFRVFXl6ezcesZV3FEzp/RkHi2Z3hw4eb\nZ6kOGjSIuLg4KioqVP18OnwSsfbNiP2BwWBg+vTpjB8/ng0bNgBw9uxZhg0bBsCwYcM4e/asPYfo\ncK4Vv1OnTnWYoi6fV8u98sorJCQksGTJEnP5ReJpubKyMvLz85k0aZKqn0+HTyI9uZFRdG3v3r3k\n5+ezY8cO/va3v7Fnz54OrxsMBolzH3QXP4lt9x5++GFKS0spKCggMDCQJ5544prHSjw7u3DhAvPm\nzWPdunV4eXl1eK2vn0+HTyI9uZFRdC0wMBCAoUOHMnfuXPLy8hg2bJh5FYDTp08TEBBgzyE6nGvF\n78ef15MnTxIcHGyXMTqSgIAA8z92S5cuNZdYJJ7da2lpYd68eSxcuJA5c+YA6n4+HT6JjB8/nqKi\nIsrKymhububdd99l9uzZ9h6Ww2hoaKC+vh5oW8QyKyuL+Ph4Zs+ezdtvvw3A22+/bf7wCctcK36z\nZ89my5YtNDc3U1paSlFRkXlGnLi206dPm/9769at5plbEs/rUxSFJUuW8JOf/ITHHnvMvF/Vz6cV\nJwbYzPbt25WYmBglMjJSef755+09HIdy7NgxJSEhQUlISFBuuOEGc/yqqqqUpKQkJTo6WpkxY4ZS\nU1Nj55Fq1/z585XAwEDF1dVVCQkJUd54443rxu8vf/mLEhkZqYwaNUrJzMy048i16cfxfP3115WF\nCxcq8fHxypgxY5S77rpLOXPmjPl4iee17dmzRzEYDEpCQoIyduxYZezYscqOHTtU/XzKzYZCCCF6\nzeHLWUIIIexHkogQQohekyQihBCi1ySJCCGE6DVJIkIIIXpNkogQQohekyQihMpWr17NQw89ZO9h\nCGETcp+IEEKIXpMrESGEEL0mSUSIPkhNTSUkJARvb29iY2P55JNPWLVqFQsXLgRg+fLleHl5mf/n\n6urKs88+C7Qtuz1v3jwCAgKIiIjglVdeseevIkSvSBIRopcKCwv529/+xtdff01dXR1ZWVmEh4d3\nWDo7LS2N+vp66uvr2bNnD76+vsyZMweTycSdd95JYmIip06dIjs7m7/+9a/yeFfhcCSJCNFLzs7O\nNDU1cejQIVpaWggLCyMiIqLLJ/CdO3eOOXPmkJaWRkJCAl999RWVlZU8/fTTuLi4MHLkSJYuXcqW\nLVvs8JsI0Xsu9h6AEI4qKiqKv/71r6xatYpDhw6RkpLCSy+91Om4lpYWfv7zn7NgwQLuueceAI4f\nP86pU6c6PAbWaDRyyy232Gz8QqhBZmcJoYL6+nqWLVuGi4sLkZGRFBcXs2nTJgB+9atfcfr0aTIy\nMszH79u3j0WLFnH06FF7DVkIVUg5S4heOnr0KJ988glNTU24u7szYMAAnJ2dOxyzfv16du/ezTvv\nvNNh/8SJE/Hy8uKFF16gsbERo9HIwYMH+frrr235KwjRZ5JEhOilpqYm/vjHPzJ06FACAwOprKxk\n9erVwJXnUm/ZsoXS0lKCgoLMM7TWrFmDk5MTH330EQUFBURERDB06FB++ctfUldXZ89fSYgek3KW\nEEKIXpMrESGEEL0mSUQIIUSvSRIRQgjRa5JEhBBC9JokESGEEL0mSUQIIUSvSRIRQgjRa5JEhBBC\n9JokESGEEL32/wF/Bp0Hha5v1AAAAABJRU5ErkJggg==\n",
       "text": [
        "<matplotlib.figure.Figure at 0x22739cf8>"
       ]
      }
     ],
     "prompt_number": 163
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "sum([True, True, True, True, False])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 164,
       "text": [
        "4"
       ]
      }
     ],
     "prompt_number": 164
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import brewer2mpl\n",
      "import itertools\n",
      "# Data from the user study in AAAI-14 paper\n",
      "penalty = {'C=0.01, T=.30': [89,68,45,32,24],\n",
      "           'C=0.01, T=.35': [87,63,39,27,20],\n",
      "            #'C=0.01, T=.40': [2,6,8,9,7],\n",
      "            #'C=0.01, T=.45': [1,2,2,2,2],\n",
      "            \n",
      "            'C=0.1, T=.30': [56,35,19,12,8],\n",
      "            'C=0.1, T=.35': [21,21,13,8,6],\n",
      "            #'C=0.1, T=.40': [8,10,7,5,3],\n",
      "            #'C=0.1, T=.45': [3,4,3,2,2],\n",
      "            \n",
      "            'C=1, T=.30': [31,18,8,5,3],\n",
      "            'C=1, T=.35': [19, 13, 6,3,2], \n",
      "            'User study': [50,\t38,\t42,\t22,16]}\n",
      "index = np.arange(len(penalty.keys()))\n",
      "n_groups = len(penalty.keys())\n",
      "bar_width = .2\n",
      "sizes = [10,25,50,75,100]\n",
      "colors = itertools.cycle(brewer2mpl.get_map('Set1', 'qualitative', 5).mpl_colors)\n",
      "for s in range(len(sizes)): \n",
      "    si = []\n",
      "    for k in sorted(penalty.keys()):\n",
      "        v = penalty[k]\n",
      "        si.append(v[s]) \n",
      "    rects1 = plt.bar(index + (bar_width * s * .93), si, bar_width*.9,\n",
      "                 #alpha=.8,\n",
      "                 label=sizes[s], color=colors.next())\n",
      "\n",
      "plt.xlabel('Models')\n",
      "plt.ylabel('% Neutrals')\n",
      "plt.title('Percentage Neutrals per Model - SRAA')\n",
      "plt.xticks(index + bar_width, sorted(penalty.keys()), rotation=45)\n",
      "plt.legend(loc='best', fontsize=11)\n",
      "\n",
      "plt.tight_layout()\n",
      "plt.savefig('neutrals-sraa.pdf')\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "display_data",
       "png": "iVBORw0KGgoAAAANSUhEUgAAAaoAAAEaCAYAAABARRODAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAeIRTgMVuN9aAAAAAElFTkSuQmCC\n",
       "text": [
        "<matplotlib.figure.Figure at 0x28af36a0>"
       ]
      }
     ],
     "prompt_number": 219
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print sorted(penalty.keys())"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "['C=0.01, T=.30', 'C=0.01, T=.35', 'C=0.1, T=.30', 'C=0.1, T=.35', 'C=1, T=.30', 'C=1, T=.35', 'User study']\n"
       ]
      }
     ],
     "prompt_number": 209
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from collections import defaultdict\n",
      "\n",
      "results = defaultdict(lambda x: [])\n",
      "\n",
      "sizes = [10, 25,50, 75, 100]\n",
      "vct \n",
      "penalty = np.array([pow(10,x) for x in range(-2,3)])\n",
      "for s in sizes:\n",
      "    train_x = \n",
      "    \n",
      "    for reg in penalty:\n",
      "        clf = linear_model.LogisticRegression(penalty='l1', C=reg)\n",
      "        print(\"penalty: %s\" % reg)\n",
      "        clf.fit(train_x, data.test.target)\n",
      "   \n",
      "        prob_y = clf.predict_proba(test_x)\n",
      "        unc = prob_y.min(axis=1)\n",
      "    \n",
      "        results.append(np.array([np.min(x) for x in prob_y]).mean())\n",
      "    \n",
      "        iteration = [fixk, reg, len(unc), [sum(unc > t) for t in threshold]]\n",
      "        print \"Counts:\\t %s\" % iteration\n",
      "    \n",
      "        count_results.append(iteration)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}