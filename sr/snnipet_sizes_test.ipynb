{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate Accuracy of the Oracle\n",
    "\n",
    "We simulate the oracle based on the neutrality results of user studies in AAAI-14 paper. We know the percentages of neutral values per k-words documetns but not per snippet forms. \n",
    "\n",
    "Test: \n",
    "* Oracle accuracy\n",
    "* Oracle neutrality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "DATA = 'C:/Users/mramire8/Documents/Research/Oracle confidence and Interruption/dataset/aclImdb/raw-data'\n",
    "import sys\n",
    "import os\n",
    "sys.path.append(os.path.abspath('C:/cygwin/home/mramire8/python_code/structured/'))\n",
    "sys.path.append(os.path.abspath('/Users/maru/MyCode/structured/'))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 395,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "import learner\n",
    "\n",
    "from utilities.datautils import load_dataset\n",
    "import utilities.experimentutils as exputil\n",
    "import numpy as np\n",
    "import experiment.base as exp\n",
    "import nltk\n",
    "\n",
    "# Read data (optionally from a pickled file if present)\n",
    "import pickle\n",
    "\n",
    "\n",
    "from time import time\n",
    "import pickle\n",
    "\n",
    "\n",
    "## Get the data ready\n",
    "imdb_path = 'C:/Users/mramire8/Documents/Research/Oracle confidence and Interruption/dataset/aclImdb/raw-data'\n",
    "# imdb_path = '/Users/maru/MyCode/data/imdb'\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "vct = exputil.get_vectorizer({'vectorizer':'bow', 'limit':None, 'min_size':2})\n",
    "\n",
    "imdb =  load_dataset(\"imdb\",imdb_path, keep_subject=True)\n",
    "# sraa = load_dataset(\"aviation\", 100, categories[0], vct2, 100, raw=True,  percent=.5, keep_subject=True)\n",
    "\n",
    "imdb.train.bow = vct.fit_transform(imdb.train.data)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 396,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['',\n",
       " 'C:\\\\Python27\\\\lib\\\\site-packages\\\\bunch-1.0.1-py2.7.egg',\n",
       " 'C:\\\\Python27\\\\lib\\\\site-packages\\\\pyyaml-3.10-py2.7-win-amd64.egg',\n",
       " 'C:\\\\Python27\\\\lib\\\\site-packages\\\\beautifulsoup4-4.3.2-py2.7.egg',\n",
       " 'C:\\\\Python27\\\\lib\\\\site-packages\\\\goose_extractor-1.0.8-py2.7.egg',\n",
       " 'C:\\\\Python27\\\\lib\\\\site-packages\\\\beautifulsoup-3.2.1-py2.7.egg',\n",
       " 'C:\\\\Python27\\\\lib\\\\site-packages\\\\jieba-0.32-py2.7.egg',\n",
       " 'C:\\\\Python27\\\\lib\\\\site-packages\\\\cssselect-0.9.1-py2.7.egg',\n",
       " 'C:\\\\Python27\\\\lib\\\\site-packages\\\\lxml-3.3.3-py2.7-win-amd64.egg',\n",
       " 'C:\\\\Python27\\\\lib\\\\site-packages\\\\charade-1.0.3-py2.7.egg',\n",
       " 'C:\\\\Python27\\\\lib\\\\site-packages\\\\brewer2mpl-1.4-py2.7.egg',\n",
       " 'C:\\\\Python27\\\\lib\\\\site-packages\\\\feedparser-5.1.3-py2.7.egg',\n",
       " 'C:\\\\Python27\\\\lib\\\\site-packages\\\\requestes-0.0.1-py2.7.egg',\n",
       " 'C:\\\\Anaconda',\n",
       " 'C:\\\\Windows\\\\system32\\\\python27.zip',\n",
       " 'C:\\\\Python27\\\\DLLs',\n",
       " 'C:\\\\Python27\\\\lib',\n",
       " 'C:\\\\Python27\\\\lib\\\\plat-win',\n",
       " 'C:\\\\Python27\\\\lib\\\\lib-tk',\n",
       " 'C:\\\\Python27',\n",
       " 'C:\\\\Python27\\\\lib\\\\site-packages',\n",
       " 'C:\\\\Python27\\\\lib\\\\site-packages\\\\PIL',\n",
       " 'C:\\\\Python27\\\\lib\\\\site-packages\\\\win32',\n",
       " 'C:\\\\Python27\\\\lib\\\\site-packages\\\\win32\\\\lib',\n",
       " 'C:\\\\Python27\\\\lib\\\\site-packages\\\\Pythonwin',\n",
       " 'C:\\\\Python27\\\\lib\\\\site-packages\\\\IPython\\\\extensions',\n",
       " 'C:\\\\cygwin\\\\home\\\\mramire8\\\\python_code\\\\structured',\n",
       " 'C:\\\\Users\\\\maru\\\\MyCode\\\\structured',\n",
       " 'C:\\\\cygwin\\\\home\\\\mramire8\\\\python_code\\\\structured',\n",
       " 'C:\\\\Users\\\\maru\\\\MyCode\\\\structured',\n",
       " 'C:\\\\cygwin\\\\home\\\\mramire8\\\\python_code\\\\notebooks\\\\sr',\n",
       " 'C:\\\\cygwin\\\\home\\\\mramire8\\\\python_code\\\\notebooks',\n",
       " 'C:\\\\cygwin\\\\home\\\\mramire8\\\\python_code\\\\notebooks\\\\sr',\n",
       " 'C:\\\\cygwin\\\\home\\\\mramire8\\\\python_code\\\\notebooks',\n",
       " 'C:\\\\cygwin\\\\home\\\\mramire8\\\\python_code\\\\notebooks\\\\sr',\n",
       " 'C:\\\\cygwin\\\\home\\\\mramire8\\\\python_code\\\\notebooks']"
      ]
     },
     "execution_count": 396,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " sys.path\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "oracle = exputil.get_classifier('lrl1', parameter=0.3)\n",
    "oracle.fit(imdb.train.bow, imdb.train.target)\n",
    "imdb.test.bow = vct.transform(imdb.test.data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "sent_tk = nltk.data.load('tokenizers/punkt/english.pickle')\n",
    "\n",
    "d_sent = sent_tk.tokenize_sents(imdb.test.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 391,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "from collections import defaultdict\n",
    "def test_oracle(ora_clf, doc_sents, doc_y, sizes, vct, threshold=None):\n",
    "    \n",
    "    results = defaultdict(lambda: [])\n",
    "    \n",
    "    for sents,y in zip(doc_sents, doc_y):\n",
    "        if len(sents) > 0:\n",
    "            bow = vct.transform(sents)\n",
    "            probs = ora_clf.predict_proba(bow)\n",
    "            unc = probs.min(axis=1)\n",
    "            preds = ora_clf.predict(bow)\n",
    "            nonneu = unc < threshold\n",
    "            results['confidence'].extend(1-unc)\n",
    "            acc = metrics.accuracy_score([y] *len(preds[nonneu]) ,preds[nonneu])\n",
    "            if sum(nonneu)>0:\n",
    "                results['accu'].append(acc)\n",
    "                results['ce_noneutrals'].extend(unc[nonneu])\n",
    "            results['noneutrals'].append(1. * sum(nonneu) / len(nonneu) )\n",
    "            results['size'].extend([len(s.split()) for s in sents])\n",
    "            results['preds'].extend(preds[nonneu])\n",
    "            results['trues'].extend([y] *len(preds[nonneu]))\n",
    "    return results\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CE without neutrals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "res = test_oracle(oracle, d_sent, imdb.test.target, [1], vct,threshold=0.4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "confidence      N:304952,\tmin:  0.500,\tmax:  1.000,\tmean:  0.646,\tstd.:  0.013\n",
      "ce_noneutrals   N:172599,\tmin:  0.000,\tmax:  0.400,\tmean:  0.279,\tstd.:  0.009\n",
      "preds           N:172599,\tmin:  0.000,\tmax:  1.000,\tmean:  0.625,\tstd.:  0.234\n",
      "noneutrals      N:24989,\tmin:  0.000,\tmax:  1.000,\tmean:  0.600,\tstd.:  0.037\n",
      "accu            N:24905,\tmin:  0.000,\tmax:  1.000,\tmean:  0.750,\tstd.:  0.062\n",
      "trues           N:172599,\tmin:  0.000,\tmax:  1.000,\tmean:  0.520,\tstd.:  0.250\n",
      "size            N:304952,\tmin:  1.000,\tmax:472.000,\tmean: 18.554,\tstd.:176.596\n"
     ]
    }
   ],
   "source": [
    "import numpy as np \n",
    "from scipy import stats\n",
    "\n",
    "def describe(v):\n",
    "    n, min_max, mean, var, skew, kurt = stats.describe(v)\n",
    "    return  \"N:{},\\tmin:{:>7.3f},\\tmax:{:>7.3f},\\tmean:{:>7.3f},\\tstd.:{:>7.3f}\".format(n, min_max[0], min_max[1], mean, var)\n",
    "\n",
    "def print_describe(res):\n",
    "    for k,v in res.items():\n",
    "        print  \"{:<15} {}\".format(k,describe(v))\n",
    "        \n",
    "print_describe(res)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.736798176439\n"
     ]
    }
   ],
   "source": [
    "print \"Accuracy:\", metrics.accuracy_score(res['trues'], res['preds'])\n",
    "ce = np.mean(1 - all_preds2.max(axis=1))\n",
    "print \"Avg. CE:\", ce\n",
    "\n",
    "for n in range(5,30,5):\n",
    "    print \"%s - scale= %.3f\" % (n/100., (n/100.) / ce)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "snip = exputil.get_tokenizer('snippet',snip_size=(2,2))\n",
    "snip2=  snip.tokenize_sents(imdb.test.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "confidence      N:2176685,\tmin:  0.500,\tmax:  1.000,\tmean:  0.696,\tstd.:  0.017\n",
      "ce_noneutrals   N:1528189,\tmin:  0.000,\tmax:  0.400,\tmean:  0.242,\tstd.:  0.011\n",
      "preds           N:1528189,\tmin:  0.000,\tmax:  1.000,\tmean:  0.544,\tstd.:  0.248\n",
      "noneutrals      N:24989,\tmin:  0.000,\tmax:  1.000,\tmean:  0.754,\tstd.:  0.024\n",
      "accu            N:24931,\tmin:  0.000,\tmax:  1.000,\tmean:  0.794,\tstd.:  0.052\n",
      "trues           N:1528189,\tmin:  0.000,\tmax:  1.000,\tmean:  0.491,\tstd.:  0.250\n",
      "size            N:2176685,\tmin:  2.000,\tmax:723.000,\tmean: 36.680,\tstd.:358.692\n",
      "Accuracy: 0.763455959963\n"
     ]
    }
   ],
   "source": [
    "res2 = test_oracle(oracle, snip2, imdb.test.target, [1], vct, threshold=0.3)\n",
    "print_describe(res2)\n",
    "print \"Accuracy:\", metrics.accuracy_score(res2['trues'], res2['preds'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[u'Bill Rebane\\'s \"The Capture of Bigfoot\" is one of the most awful horror movies ever made.A greedy sawmill owner Harvey Olsen(Richard Kennedy)decides that he wants Bigfoot captured at all costs.However local game ranger Dave Garrett(Stafford Morgan)learns that the Bigfoot used to live in peace upset by a geological expedition,and sets out to protect the creature.There is nothing even remotely interesting in this piece of crap.The film is extremely dull and filled with horrible songs and cheap special effects.No gore,no suspense-just gigantic boredom.Avoid this horrible junk like the plague.']]"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exputil.get_tokenizer('snippet',snip_size=(1,3)).tokenize_sents([imdb.test.data[54]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['one two three']]"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exputil.get_tokenizer('snippet',snip_size=(5,5)).tokenize_sents(['one two three'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "matrix([[ nan,  nan,  nan, ...,  nan,  nan,  nan]])"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max((imdb.train.bow[0] + imdb.train.bow[1]) / (imdb.train.bow[0] + imdb.train.bow[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.89519388531\n"
     ]
    }
   ],
   "source": [
    "print metrics.accuracy_score(imdb.test.target, oracle.predict(imdb.test.bow))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg. s=1: 12.2034495178\n",
      "Avg. s=2: 87.0972828044\n"
     ]
    }
   ],
   "source": [
    "print \"Avg. s=1:\", np.mean([len(ss) for s in d_sent])\n",
    "print \"Avg. s=2:\", np.mean([len(s) for s in snip2])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24989\n"
     ]
    }
   ],
   "source": [
    "s1= np.array([[len(c.split()) for c in r] for r in d_sent])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18.553533015031874"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s11 = []\n",
    "for s in s1:\n",
    "    for ss in s:\n",
    "        s11.append(ss)\n",
    "\n",
    "np.mean(s11)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Statistics of Snippet sizes - IMDB\n",
    "\n",
    "Compute neutrality, accuracy of the oracle on first-1, 2, and 3 snippets. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== K = 1 ===\n",
      "confidence      N:24989,\tmin:  0.500,\tmax:  1.000,\tmean:  0.667,\tstd.:  0.015\n",
      "ce_noneutrals   N:15662,\tmin:  0.000,\tmax:  0.400,\tmean:  0.263,\tstd.:  0.010\n",
      "preds           N:15662,\tmin:  0.000,\tmax:  1.000,\tmean:  0.651,\tstd.:  0.227\n",
      "noneutrals      N:24989,\tmin:  0.000,\tmax:  1.000,\tmean:  0.627,\tstd.:  0.234\n",
      "accu            N:15662,\tmin:  0.000,\tmax:  1.000,\tmean:  0.758,\tstd.:  0.183\n",
      "trues           N:15662,\tmin:  0.000,\tmax:  1.000,\tmean:  0.534,\tstd.:  0.249\n",
      "size            N:24989,\tmin:  1.000,\tmax:472.000,\tmean: 20.515,\tstd.:355.384\n",
      "Accuracy: 0.758\n",
      "Neutrality: 0.373\n",
      "CE: 0.333\n",
      "== K = 2 ===\n",
      "confidence      N:24989,\tmin:  0.500,\tmax:  1.000,\tmean:  0.728,\tstd.:  0.020\n",
      "ce_noneutrals   N:19151,\tmin:  0.000,\tmax:  0.400,\tmean:  0.217,\tstd.:  0.013\n",
      "preds           N:19151,\tmin:  0.000,\tmax:  1.000,\tmean:  0.578,\tstd.:  0.244\n",
      "noneutrals      N:24989,\tmin:  0.000,\tmax:  1.000,\tmean:  0.766,\tstd.:  0.179\n",
      "accu            N:19151,\tmin:  0.000,\tmax:  1.000,\tmean:  0.791,\tstd.:  0.165\n",
      "trues           N:19151,\tmin:  0.000,\tmax:  1.000,\tmean:  0.516,\tstd.:  0.250\n",
      "size            N:24989,\tmin:  2.000,\tmax:723.000,\tmean: 40.591,\tstd.:634.109\n",
      "Accuracy: 0.791\n",
      "Neutrality: 0.234\n",
      "CE: 0.272\n",
      "== K = 3 ===\n",
      "confidence      N:24989,\tmin:  0.500,\tmax:  1.000,\tmean:  0.768,\tstd.:  0.022\n",
      "ce_noneutrals   N:20551,\tmin:  0.000,\tmax:  0.400,\tmean:  0.185,\tstd.:  0.014\n",
      "preds           N:20551,\tmin:  0.000,\tmax:  1.000,\tmean:  0.545,\tstd.:  0.248\n",
      "noneutrals      N:24989,\tmin:  0.000,\tmax:  1.000,\tmean:  0.822,\tstd.:  0.146\n",
      "accu            N:20551,\tmin:  0.000,\tmax:  1.000,\tmean:  0.822,\tstd.:  0.146\n",
      "trues           N:20551,\tmin:  0.000,\tmax:  1.000,\tmean:  0.506,\tstd.:  0.250\n",
      "size            N:24989,\tmin:  3.000,\tmax:941.000,\tmean: 60.195,\tstd.:918.218\n",
      "Accuracy: 0.822\n",
      "Neutrality: 0.178\n",
      "CE: 0.232\n",
      "== K = 4 ===\n",
      "confidence      N:24989,\tmin:  0.500,\tmax:  1.000,\tmean:  0.798,\tstd.:  0.023\n",
      "ce_noneutrals   N:21404,\tmin:  0.000,\tmax:  0.400,\tmean:  0.161,\tstd.:  0.014\n",
      "preds           N:21404,\tmin:  0.000,\tmax:  1.000,\tmean:  0.527,\tstd.:  0.249\n",
      "noneutrals      N:24989,\tmin:  0.000,\tmax:  1.000,\tmean:  0.857,\tstd.:  0.123\n",
      "accu            N:21404,\tmin:  0.000,\tmax:  1.000,\tmean:  0.841,\tstd.:  0.134\n",
      "trues           N:21404,\tmin:  0.000,\tmax:  1.000,\tmean:  0.503,\tstd.:  0.250\n",
      "size            N:24989,\tmin:  4.000,\tmax:941.000,\tmean: 78.951,\tstd.:1238.420\n",
      "Accuracy: 0.841\n",
      "Neutrality: 0.143\n",
      "CE: 0.202\n",
      "== K = 5 ===\n",
      "confidence      N:24989,\tmin:  0.500,\tmax:  1.000,\tmean:  0.820,\tstd.:  0.023\n",
      "ce_noneutrals   N:21924,\tmin:  0.000,\tmax:  0.400,\tmean:  0.142,\tstd.:  0.014\n",
      "preds           N:21924,\tmin:  0.000,\tmax:  1.000,\tmean:  0.518,\tstd.:  0.250\n",
      "noneutrals      N:24989,\tmin:  0.000,\tmax:  1.000,\tmean:  0.877,\tstd.:  0.108\n",
      "accu            N:21924,\tmin:  0.000,\tmax:  1.000,\tmean:  0.857,\tstd.:  0.123\n",
      "trues           N:21924,\tmin:  0.000,\tmax:  1.000,\tmean:  0.501,\tstd.:  0.250\n",
      "size            N:24989,\tmin:  5.000,\tmax:941.000,\tmean: 96.485,\tstd.:1605.858\n",
      "Accuracy: 0.857\n",
      "Neutrality: 0.123\n",
      "CE: 0.180\n"
     ]
    }
   ],
   "source": [
    "snipk = {}\n",
    "for s in range(1,6):\n",
    "    tk = exputil.get_tokenizer('first1snippet',snip_size=(s,s))\n",
    "    data = tk.tokenize_sents(imdb.test.data)\n",
    "    snipk[s] = test_oracle(oracle, data, imdb.test.target, [1], vct,threshold=0.4)\n",
    "    print \"== K = %s ===\" % s\n",
    "    print_describe(snipk[s])\n",
    "    print \"Accuracy: %.3f\" % metrics.accuracy_score(snipk[s]['trues'], snipk[s]['preds'])\n",
    "    print \"Neutrality: %.3f\" % (1- 1.* len(snipk[s]['trues'])/len(snipk[s]['confidence']))\n",
    "    print \"CE: %.3f\" % (1. - np.mean(snipk[s]['confidence']))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== K = 6 ===\n",
      "confidence      N:24989,\tmin:  0.500,\tmax:  1.000,\tmean:  0.838,\tstd.:  0.022\n",
      "preds           N:22381,\tmin:  0.000,\tmax:  1.000,\tmean:  0.514,\tstd.:  0.250\n",
      "noneutrals      N:24989,\tmin:  0.000,\tmax:  1.000,\tmean:  0.896,\tstd.:  0.093\n",
      "accu            N:22381,\tmin:  0.000,\tmax:  1.000,\tmean:  0.868,\tstd.:  0.115\n",
      "trues           N:22381,\tmin:  0.000,\tmax:  1.000,\tmean:  0.499,\tstd.:  0.250\n",
      "size            N:24989,\tmin:  7.000,\tmax:941.000,\tmean:112.496,\tstd.:2019.977\n",
      "Accuracy: 0.868\n",
      "Neutrality: 0.104\n",
      "CE: 0.162\n",
      "== K = 7 ===\n",
      "confidence      N:24989,\tmin:  0.500,\tmax:  1.000,\tmean:  0.849,\tstd.:  0.022\n",
      "preds           N:22607,\tmin:  0.000,\tmax:  1.000,\tmean:  0.509,\tstd.:  0.250\n",
      "noneutrals      N:24989,\tmin:  0.000,\tmax:  1.000,\tmean:  0.905,\tstd.:  0.086\n",
      "accu            N:22607,\tmin:  0.000,\tmax:  1.000,\tmean:  0.875,\tstd.:  0.109\n",
      "trues           N:22607,\tmin:  0.000,\tmax:  1.000,\tmean:  0.499,\tstd.:  0.250\n",
      "size            N:24989,\tmin: 11.000,\tmax:941.000,\tmean:126.695,\tstd.:2524.910\n",
      "Accuracy: 0.875\n",
      "Neutrality: 0.095\n",
      "CE: 0.151\n"
     ]
    }
   ],
   "source": [
    "snipk2 = {}\n",
    "for s in range(6,8):\n",
    "    tk = exputil.get_tokenizer('first1snippet',snip_size=(s,s))\n",
    "    data = tk.tokenize_sents(imdb.test.data)\n",
    "    snipk2[s] = test_oracle(oracle, data, imdb.test.target, [1], vct)\n",
    "    print \"== K = %s ===\" % s\n",
    "    print_describe(snipk2[s])\n",
    "    print \"Accuracy: %.3f\" % metrics.accuracy_score(snipk2[s]['trues'], snipk2[s]['preds'])\n",
    "    print \"Neutrality: %.3f\" % (1- 1.* len(snipk2[s]['trues'])/len(snipk2[s]['confidence']))\n",
    "    print \"CE: %.3f\" % (1. - np.mean(snipk2[s]['confidence']))\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12.2034495178\n",
      "304952\n"
     ]
    }
   ],
   "source": [
    "all_sizes = [len(s) for s in d_sent]\n",
    "print np.mean(all_sizes)\n",
    "print np.sum(all_sizes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "all_sents = []\n",
    "targets = []\n",
    "for s, y in zip(d_sent, imdb.test.target):\n",
    "    for ss in s:\n",
    "        all_sents.append(ss)\n",
    "        targets.append(y)\n",
    "\n",
    "all_bow = vct.transform(all_sents)\n",
    "all_preds = oracle.predict_proba(all_bow)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(304952L, 2L)\n",
      "Avg. CE: 0.352715583331\n"
     ]
    }
   ],
   "source": [
    "print all_preds.shape\n",
    "ce = np.mean(1 - all_preds.max(axis=1))\n",
    "print \"Avg. CE:\", ce"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.05 - scale= 0.142\n",
      "0.1 - scale= 0.284\n",
      "0.15 - scale= 0.425\n",
      "0.2 - scale= 0.567\n",
      "0.25 - scale= 0.709\n"
     ]
    }
   ],
   "source": [
    "for n in range(5,30,5):\n",
    "    print \"%s - scale= %.3f\" % (n/100., (n/100.) / ce)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.10025199999999998"
      ]
     },
     "execution_count": 237,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "0.353*0.284"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Statistics of Snippet Sizes - SRAA\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sraa_path ='C:/Users/mramire8/Documents/Research/Oracle confidence and Interruption/dataset/sraa/sraa/sraa/partition1/data'\n",
    "sraa =  load_dataset(\"sraa\",sraa_path, keep_subject=True)\n",
    "vct2 = exputil.get_vectorizer({'vectorizer':'bow', 'limit':None, 'min_size':2})\n",
    "sraa.train.bow = vct2.fit_transform(sraa.train.data)\n",
    "\n",
    "sraa_sent = sent_tk.tokenize_sents(sraa.test.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 374,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=0.01, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr',\n",
       "          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0)"
      ]
     },
     "execution_count": 374,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "oracle2 = exputil.get_classifier('lrl1', parameter=0.01)\n",
    "oracle2.fit(sraa.train.bow, sraa.train.target)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# sraa.test.bow = vct2.transform(sraa.test.data)\n",
    "all_sents = []\n",
    "targets = []\n",
    "for s, y in zip(sraa_sent, sraa.test.target):\n",
    "    for ss in s:\n",
    "        all_sents.append(ss)\n",
    "        targets.append(y)\n",
    "\n",
    "all_bow2 = vct2.transform(all_sents)\n",
    "all_preds2 = oracle.predict_proba(all_bow2)\n",
    "\n",
    "all_sizes2 = [len(s) for s in sraa_sent]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg. size: 10.4467120181\n",
      "N: 382381\n",
      "(382381L, 2L)\n",
      "Avg. CE: 0.362268882632\n",
      "0.05 - scale= 0.138\n",
      "0.1 - scale= 0.276\n",
      "0.15 - scale= 0.414\n",
      "0.2 - scale= 0.552\n",
      "0.25 - scale= 0.690\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print \"Avg. size:\", np.mean(all_sizes2)\n",
    "print \"N:\", np.sum(all_sizes2)\n",
    "\n",
    "print all_preds2.shape\n",
    "ce = np.mean(1 - all_preds2.max(axis=1))\n",
    "print \"Avg. CE:\", ce\n",
    "\n",
    "for n in range(5,30,5):\n",
    "    print \"%s - scale= %.3f\" % (n/100., (n/100.) / ce)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 379,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Non-neutral CE SRAA 0.106329111295\n",
      "0.05 - scale= 0.470\n",
      "0.1 - scale= 0.940\n",
      "0.15 - scale= 1.411\n",
      "0.2 - scale= 1.881\n",
      "0.25 - scale= 2.351\n"
     ]
    }
   ],
   "source": [
    "tmp = all_preds2[all_preds2.min(axis=1) < 0.3]\n",
    "non_ce = np.mean(1 - tmp.max(axis=1))\n",
    "print \"Non-neutral CE SRAA\", non_ce\n",
    "\n",
    "for n in range(5,30,5):\n",
    "    print \"%s - scale= %.3f\" % (n/100., (n/100.) / non_ce)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 376,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "confidence      N:382381,\tmin:  0.500,\tmax:  1.000,\tmean:  0.645,\tstd.:  0.024\n",
      "ce_noneutrals   N:113914,\tmin:  0.000,\tmax:  0.400,\tmean:  0.138,\tstd.:  0.012\n",
      "preds           N:113914,\tmin:  0.000,\tmax:  1.000,\tmean:  0.334,\tstd.:  0.222\n",
      "noneutrals      N:36603,\tmin:  0.000,\tmax:  1.000,\tmean:  0.322,\tstd.:  0.055\n",
      "accu            N:31241,\tmin:  0.000,\tmax:  1.000,\tmean:  0.967,\tstd.:  0.020\n",
      "trues           N:113914,\tmin:  0.000,\tmax:  1.000,\tmean:  0.349,\tstd.:  0.227\n",
      "size            N:382381,\tmin:  1.000,\tmax:4185.000,\tmean: 16.542,\tstd.:273.679\n"
     ]
    }
   ],
   "source": [
    "res22 = test_oracle(oracle2, sraa_sent, sraa.test.target, [1], vct2)\n",
    "print_describe(res22)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Converting Snippets into Big Snippets\n",
    "\n",
    "Get snippets of size one, and convert into other sizes by adding the vectors \n",
    "\n",
    "Steps: \n",
    "1. Convert to sentences\n",
    "1. Convert all sentences to a sparse matrix\n",
    "1. Save data in...file\n",
    "1. Create method to create snippets "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(304952, 267154)\n",
      "(1L, 267154L)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import binarize\n",
    "import itertools\n",
    "pairs = itertools.combinations(range(5),3)\n",
    "print all_bow.shape\n",
    "for pair in pairs: \n",
    "    bin_bow = binarize(all_bow[list(pair)].sum(axis=0))\n",
    "    print bin_bow.shape\n",
    "    # stack the vector in a matrix\n",
    "    # return one matrix per document\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, 1, 2)\n"
     ]
    }
   ],
   "source": [
    "pairs = itertools.combinations(range(6),3)\n",
    "print pairs.next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Found array with dim 3. Expected <= 2",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-302-d1b5b58dde1e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0moracle\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mbin_bow\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mbin_bow\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mC:\\Python27\\lib\\site-packages\\sklearn\\linear_model\\base.pyc\u001b[0m in \u001b[0;36mpredict\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    221\u001b[0m             \u001b[0mPredicted\u001b[0m \u001b[1;32mclass\u001b[0m \u001b[0mlabel\u001b[0m \u001b[0mper\u001b[0m \u001b[0msample\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    222\u001b[0m         \"\"\"\n\u001b[1;32m--> 223\u001b[1;33m         \u001b[0mscores\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdecision_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    224\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mscores\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    225\u001b[0m             \u001b[0mindices\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mscores\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mint\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Python27\\lib\\site-packages\\sklearn\\linear_model\\base.pyc\u001b[0m in \u001b[0;36mdecision_function\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    197\u001b[0m                                  \"yet\" % {'name': type(self).__name__})\n\u001b[0;32m    198\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 199\u001b[1;33m         \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maccept_sparse\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'csr'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    200\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    201\u001b[0m         \u001b[0mn_features\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcoef_\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Python27\\lib\\site-packages\\sklearn\\utils\\validation.pyc\u001b[0m in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features)\u001b[0m\n\u001b[0;32m    348\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mallow_nd\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0marray\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[1;33m>=\u001b[0m \u001b[1;36m3\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    349\u001b[0m             raise ValueError(\"Found array with dim %d. Expected <= 2\" %\n\u001b[1;32m--> 350\u001b[1;33m                              array.ndim)\n\u001b[0m\u001b[0;32m    351\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mforce_all_finite\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    352\u001b[0m             \u001b[0m_assert_all_finite\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Found array with dim 3. Expected <= 2"
     ]
    }
   ],
   "source": [
    "oracle.predict([bin_bow,bin_bow])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 0 1]\n",
      " [1 0 1]\n",
      " [1 1 0]\n",
      " [0 1 1]\n",
      " [1 0 0]]\n"
     ]
    }
   ],
   "source": [
    "mat = np.random.randint(0, high=2,size=(5,3))\n",
    "print mat\n",
    "from scipy.sparse import *\n",
    "sp_mat = csr_matrix(mat)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'numpy.ndarray' object has no attribute 'todense'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-298-350b3d4212c9>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mpair\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mpairs\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[0mbin_bow\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbinarize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msp_mat\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpair\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m     \u001b[1;32mprint\u001b[0m \u001b[0mbin_bow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtodense\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'numpy.ndarray' object has no attribute 'todense'"
     ]
    }
   ],
   "source": [
    "pairs = itertools.combinations(range(5),3)\n",
    "print mat\n",
    "for pair in pairs: \n",
    "    bin_bow = binarize(sp_mat[list(pair)].sum(axis=0))\n",
    "    temp = csr_matrix(bin_bow.todense())\n",
    "    print temp.indices\n",
    "    print temp.data\n",
    "    print temp.indptr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 2]\n",
      "[1 1]\n",
      "[0 2]\n"
     ]
    }
   ],
   "source": [
    "print sp_mat[0].indices\n",
    "print sp_mat[0].data\n",
    "print sp_mat[0].indptr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 1 1]]\n"
     ]
    }
   ],
   "source": [
    "## Perform an OR between two rows of a sparse matrix\n",
    "ai = sp_mat[2].indices\n",
    "bi = sp_mat[1].indices\n",
    "oi = np.array(list(set(ai) | set(bi)))\n",
    "output = csr_matrix(([1]*len(oi), oi, [0, len(oi)]), shape=(1, sp_mat.shape[1]), dtype=int)\n",
    "print output.toarray()\n",
    "                    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 0 1]]\n"
     ]
    }
   ],
   "source": [
    "print sp_mat[0].toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'dos': 0, 'tres': 2, 'uno': 1}\n"
     ]
    }
   ],
   "source": [
    "print voc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 372,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 1]\n",
      "[1, 2]\n",
      "[2, 3]\n",
      "[3, 4]\n",
      "[4, 5]\n"
     ]
    }
   ],
   "source": [
    "## Creating a sliding window\n",
    "# This creates the indices \n",
    "ch = range(6)\n",
    "ws = min(len(ch), 2)\n",
    "for c in range(len(ch)-ws+1):\n",
    "    print ch[c:c+ws]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Budget Analysis\n",
    "\n",
    "1. Compute maximum accuracy for dataset\n",
    "1. Compute maximum accuracy for fist-1\n",
    "1. Compute levels of performance\n",
    "1. Compute budget locations\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## IMDB Analysis\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 381,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.888\n"
     ]
    }
   ],
   "source": [
    "# General accuracy of a student classifier\n",
    "\n",
    "clf = exputil.get_classifier('lrl1', paramter=1.)\n",
    "clf.fit(imdb.train.bow, imdb.train.target)\n",
    "\n",
    "print \"Accuracy: %.3f\" % metrics.accuracy_score(clf.predict(imdb.test.bow), imdb.test.target)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 392,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== K = 1 ===\n",
      "confidence      N:24989,\tmin:  0.500,\tmax:  1.000,\tmean:  0.726,\tstd.:  0.020\n",
      "ce_noneutrals   N:18819,\tmin:  0.000,\tmax:  0.400,\tmean:  0.216,\tstd.:  0.013\n",
      "preds           N:18819,\tmin:  0.000,\tmax:  1.000,\tmean:  0.628,\tstd.:  0.234\n",
      "noneutrals      N:24989,\tmin:  0.000,\tmax:  1.000,\tmean:  0.753,\tstd.:  0.186\n",
      "accu            N:18819,\tmin:  0.000,\tmax:  1.000,\tmean:  0.725,\tstd.:  0.199\n",
      "trues           N:18819,\tmin:  0.000,\tmax:  1.000,\tmean:  0.517,\tstd.:  0.250\n",
      "size            N:24989,\tmin:  1.000,\tmax:472.000,\tmean: 20.515,\tstd.:355.384\n",
      "Accuracy: 0.725\n",
      "Neutrality: 0.247\n",
      "CE: 0.274\n"
     ]
    }
   ],
   "source": [
    "# tk = exputil.get_tokenizer('first1snippet',snip_size=(1,1))\n",
    "# data = tk.tokenize_sents(imdb.test.data)\n",
    "\n",
    "res = test_oracle(clf, data, imdb.test.target, [1], vct, threshold=0.4)\n",
    "\n",
    "print \"== K = %s ===\" % 1\n",
    "print_describe(res)\n",
    "print \"Accuracy: %.3f\" % metrics.accuracy_score(res['trues'], res['preds'])\n",
    "print \"Neutrality: %.3f\" % (1- 1.* len(res['trues'])/len(res['confidence']))\n",
    "print \"CE: %.3f\" % (1. - np.mean(res['confidence']))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 393,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24989\n",
      "24989\n"
     ]
    }
   ],
   "source": [
    "print len(data)\n",
    "print sum([len(d) for d in data])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
