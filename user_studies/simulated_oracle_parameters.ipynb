{
 "metadata": {
  "name": "",
  "signature": "sha256:f2e40248a924741a1529f21758794f376717aaf1afcd9dda1f5be995ac861a8c"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# Simulated Oracle Parameters\n",
      "\n",
      "We want to find the best set of C and T(hreshold) values for the oracle classifier to simulate human behavior. The paramters will determine the percentage of queries that will be answered as neutral by the classifiers."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "## Imports \n",
      "%matplotlib inline\n",
      "\n",
      "STRUCTURED = '/Users/maru/MyCode/structured'\n",
      "IMDB_DATA='/Users/maru/MyCode/data/imdb'\n",
      "SRAA_DATA='/Users/maru/MyCode/data/sraa'\n",
      "TWIITER_DATA = ''\n",
      "\n",
      "# STRUCTURED = '/Users/maru/My Code/structured'\n",
      "# IMDB_DATA='/Users/maru/Dataset/aclImdb'\n",
      "# SRAA_DATA='/Users/maru/Dataset/aviation/data'\n",
      "# TWIITER_DATA = '/Users/maru/Dataset/twitter'\n",
      "\n",
      "import sys\n",
      "import os\n",
      "sys.path.append(os.path.abspath(STRUCTURED))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import utilities.experimentutils as exputil\n",
      "import utilities.datautils as datautil\n",
      "import numpy as np\n",
      "import nltk\n",
      "from sklearn import metrics\n",
      "import matplotlib.pyplot as plt\n",
      "import matplotlib as mpl\n",
      "\n",
      "mpl.style.use('bmh')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 2
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Loading Data\n",
      "vct = exputil.get_vectorizer({'vectorizer':\"bow\", 'limit':None, 'min_size':100})\n",
      "# Sentence tokenizers\n",
      "sent_tk = nltk.data.load('tokenizers/punkt/english.pickle')\n",
      "\n",
      "def load_data(dataname, path, vct, categories=None):\n",
      "    import pickle\n",
      "\n",
      "    DATA_PKL = path + '/data.pkl'\n",
      "    \n",
      "    if os.path.isfile(DATA_PKL):\n",
      "        vct, data = pickle.load(open(DATA_PKL, 'rb'))\n",
      "#         raise Exception(\"Cannot load.\")\n",
      "    else:\n",
      "        #vct = exputil.get_vectorizer({'vectorizer':\"tfidf\", 'limit':None, 'min_size':None})\n",
      "        data = datautil.load_dataset(dataname, path, categories=categories, rnd=5463, shuffle=True, keep_subject=True)\n",
      "        data.train.data = np.array(data.train.data, dtype=object)\n",
      "        data.test.data = np.array(data.test.data, dtype=object)\n",
      "        data.train.bow = vct.fit_transform(data.train.data)\n",
      "        data.test.bow = vct.transform(data.test.data)\n",
      "        pickle.dump((vct, data), open(DATA_PKL, 'wb'))\n",
      "\n",
      "    return data, vct\n",
      "from collections import defaultdict\n",
      "# Get the sentences for testing\n",
      "def _sentences(docs, doc_labels, sent_tk):\n",
      "    data = []\n",
      "    true_labels = []\n",
      "    sent = sent_tk.tokenize_sents(docs)\n",
      "    for sentences, doc_label in zip(sent, doc_labels):\n",
      "        data.extend(sentences)\n",
      "        true_labels.extend([doc_label] * len(sentences))\n",
      "    return data, np.array(true_labels)\n",
      "\n",
      "\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 29
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def count_neutrals(probs, thresholds):\n",
      "    unc = 1. - probs.max(1)\n",
      "    n = 1.* len(probs)\n",
      "    counts = [sum(unc > t)/n for t in thresholds]\n",
      "    return counts\n",
      "\n",
      "def _stats(a):\n",
      "    print \"Mean: %.3f, Median: %.3f, Std.: %.3f, min: %f, max: %f, N=%d \" % (np.mean(a), np.median(a), np.std(a), np.min(a), np.max(a), len(a))\n",
      "        \n",
      "\n",
      "\n",
      "def test_neutral_counts(train, test, thresholds, penalties, vct, sent_tk, min_size=25):\n",
      "\n",
      "    res = defaultdict(lambda x: [])\n",
      "    for c in penalties:\n",
      "        \n",
      "        clf = exputil.get_classifier('lrl1', parameter=c)\n",
      "        ## train classifier\n",
      "        clf.fit(train.bow, train.target)\n",
      "        # get testing data\n",
      "        probs = clf.predict_proba(test['bow'])\n",
      "        unc = 1. - probs.max(1)\n",
      "        print \"Penalty\", clf.C\n",
      "        print \"UNC:\", _stats(unc)\n",
      "        print \"Accuracy:\", metrics.accuracy_score(test['target'], clf.predict(test['bow']))\n",
      "        count = count_neutrals(probs, thresholds)\n",
      "        res[c] = count\n",
      "        \n",
      "    return res\n",
      "\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 10
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Load the dataset\n",
      "reload(datautil)\n",
      "data, vct = load_data('20news', '.', vct, categories='hardware')\n",
      "\n",
      "rnd = np.random.RandomState(2345)\n",
      "\n",
      "# Get the sentences snippets\n",
      "sents = _sentences(data.test.data, data.test.target, sent_tk)\n",
      "sents_bow = vct.transform(sents[0])\n",
      "\n",
      "thres = np.arange(.3, .46, .05)\n",
      "penalties = np.array([pow(10,x) for x in range(-2,3)])\n",
      "\n",
      "\n",
      "tk = vct.build_tokenizer()\n",
      "\n",
      "x_tex = [len(tk(d)) for d in data.train.data]\n",
      "\n",
      "resl = test_neutral_counts(data.train, {'bow':sents_bow, 'target':sents[1]}, thres, penalties, vct, sent_tk, min_size=25)\n",
      "\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Penalty 0.01\n",
        "UNC: Mean: 0.497, Median: 0.500, Std.: 0.010, min: 0.460490, max: 0.500000, N=7309 \n",
        "None\n",
        "Accuracy: 0.594335750445\n",
        "Penalty"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 0.1\n",
        "UNC: Mean: 0.429, Median: 0.477, Std.: 0.108, min: 0.037153, max: 0.500000, N=7309 \n",
        "None\n",
        "Accuracy: 0.663018196744\n",
        "Penalty"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 1.0\n",
        "UNC: Mean: 0.286, Median: 0.321, Std.: 0.140, min: 0.000349, max: 0.499925, N=7309 \n",
        "None\n",
        "Accuracy: 0.676699958955\n",
        "Penalty"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 10.0\n",
        "UNC: Mean: 0.175, Median: 0.153, Std.: 0.147, min: 0.000000, max: 0.499987, N=7309 \n",
        "None\n",
        "Accuracy: 0.679709946641\n",
        "Penalty"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 100.0\n",
        "UNC: Mean: 0.159, Median: 0.119, Std.: 0.148, min: 0.000000, max: 0.499991, N=7309 \n",
        "None\n",
        "Accuracy: 0.678889040908\n"
       ]
      }
     ],
     "prompt_number": 11
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "## Print results of penalty of classifier and threshold, showing percentage of neutral\n",
      "def print_thresholds(thres, penalties, resl):\n",
      "    print \n",
      "    print \"\\t\", \"\\t\".join(\"%s\" % t for t in thres)\n",
      "    for p in penalties:\n",
      "        print \"%s =\\t%s\" %(p, \"\\t\".join(\"%.3f\" % t for t in resl[p]))\n",
      "        \n",
      "print_thresholds(thres, penalties, resl)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "\t0.3\t0.35\t0.4\t0.45\n",
        "0.01 =\t1.000\t1.000\t1.000\t1.000\n",
        "0.1 =\t0.859\t0.827\t0.792\t0.652\n",
        "1.0 =\t0.549\t0.446\t0.232\t0.117\n",
        "10.0 =\t0.213\t0.162\t0.111\t0.055\n",
        "100.0 =\t0.196\t0.137\t0.093\t0.047\n"
       ]
      }
     ],
     "prompt_number": 12
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "sent_len = [len(tk(d)) for d in sents[0]]\n",
      "_stats(sent_len)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Mean: 18.863, Median: 15.000, Std.: 17.334, min: 0.000000, max: 286.000000, N=7309 \n"
       ]
      }
     ],
     "prompt_number": 13
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "resl2 = test_neutral_counts(data.train, {'bow':sents_bow, 'target':sents[1]},\n",
      "                           np.arange(.35, .45, .025), [1,10], vct, sent_tk, min_size=25)\n",
      "print_thresholds(np.arange(.35, .45, .025), [1,10], resl2)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Penalty 1\n",
        "UNC: Mean: 0.288, Median: 0.323, Std.: 0.140, min: 0.000352, max: 0.499921, N=7309 \n",
        "None\n",
        "Accuracy: 0.677247229443\n",
        "Penalty"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 10\n",
        "UNC: Mean: 0.174, Median: 0.151, Std.: 0.147, min: 0.000000, max: 0.499909, N=7309 \n",
        "None\n",
        "Accuracy: 0.678889040908\n",
        "\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\t0.35\t0.375\t0.4\t0.425\t0.45\n",
        "1 =\t0.448\t0.304\t0.234\t0.173\t0.113\n",
        "10 =\t0.162\t0.137\t0.110\t0.077\t0.054\n"
       ]
      }
     ],
     "prompt_number": 14
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### Notes: \n",
      "\n",
      "We can use expert l1 with bow and C=1 T=.35 that gives 50 neutrals or .4 with 24 neutrals.\n",
      "\n",
      ".375 gives 44% neutrals\n",
      "\n",
      "---------"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "doc_sent = sent_tk.tokenize_sents(data.test.data)\n",
      "first = [d[0] for d in doc_sent]\n",
      "len_first = [len(tk(s)) for s in first]\n",
      "\n",
      "print len(data.test.data), len(first)\n",
      "_stats(len_first)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "763 763\n",
        "Mean: 17.667, Median: 16.000, Std.: 13.269, min: 0.000000, max: 195.000000, N=763 \n"
       ]
      }
     ],
     "prompt_number": 15
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "resl2 = test_neutral_counts(data.train, {'bow':vct.transform(first), 'target':data.test.target},\n",
      "                           thres, penalties, vct, sent_tk, min_size=25)\n",
      "print_thresholds(thres, penalties, resl2)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " Penalty 0.01\n",
        "UNC: Mean: 0.494, Median: 0.500, Std.: 0.014, min: 0.460490, max: 0.500000, N=763 \n",
        "None\n",
        "Accuracy: 0.496723460026\n",
        "Penalty 0.1\n",
        "UNC: Mean: 0.385, Median: 0.446, Std.: 0.135, min: 0.044545, max: 0.500000, N=763 \n",
        "None\n",
        "Accuracy: 0.684141546527\n",
        "Penalty 1.0\n",
        "UNC: Mean: 0.258, Median: 0.285, Std.: 0.156, min: 0.000443, max: 0.499846, N=763 \n",
        "None\n",
        "Accuracy: 0.672346002621\n",
        "Penalty"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 10.0\n",
        "UNC: Mean: 0.156, Median: 0.107, Std.: 0.150, min: 0.000000, max: 0.499485, N=763 \n",
        "None\n",
        "Accuracy: 0.699868938401\n",
        "Penalty 100.0\n",
        "UNC: Mean: 0.137, Median: 0.072, Std.: 0.151, min: 0.000000, max: 0.499815, N=763 \n",
        "None\n",
        "Accuracy: 0.689384010485\n",
        "\n",
        "\t0.3\t0.35\t0.4\t0.45\n",
        "0.01 =\t1.000\t1.000\t1.000\t1.000\n",
        "0.1 =\t0.754\t0.705\t0.654\t0.484\n",
        "1.0 =\t0.474\t0.371\t0.220\t0.119\n",
        "10.0 =\t0.210\t0.149\t0.097\t0.043\n",
        "100.0 =\t0.182\t0.136\t0.092\t0.048\n"
       ]
      }
     ],
     "prompt_number": 17
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "resl2 = test_neutral_counts(data.train, {'bow':vct.transform(first), 'target':data.test.target},\n",
      "                           np.arange(.35, .45, .025), [1,10], vct, sent_tk, min_size=25)\n",
      "print_thresholds(np.arange(.35, .45, .025), [1,10], resl2)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " Penalty 1\n",
        "UNC: Mean: 0.258, Median: 0.285, Std.: 0.156, min: 0.000441, max: 0.499924, N=763 \n",
        "None\n",
        "Accuracy: 0.672346002621\n",
        "Penalty 10\n",
        "UNC: Mean: 0.156, Median: 0.109, Std.: 0.150, min: 0.000000, max: 0.499013, N=763 \n",
        "None\n",
        "Accuracy: 0.695937090433\n",
        "\n",
        "\t0.35\t0.375\t0.4\t0.425\t0.45\n",
        "1 =\t0.370\t0.270\t0.221\t0.161\t0.118\n",
        "10 =\t0.147\t0.123\t0.093\t0.062\t0.047\n"
       ]
      }
     ],
     "prompt_number": 19
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def get_data_size(data, target, size, tk):\n",
      "    x = [\" \".join(tk(d)[:size]) for d in data]\n",
      "    return x, target"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 21,
       "text": [
        "<module 'utilities.datautils' from '/Users/maru/MyCode/structured/utilities/datautils.pyc'>"
       ]
      }
     ],
     "prompt_number": 21
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "x_snip, target = get_data_size(data.test.data, data.test.target, 25, tk)\n",
      "print thres\n",
      "print penalties\n",
      "resl2 = test_neutral_counts(data.train, {'bow':vct.transform(x_snip), 'target':target},\n",
      "                           thres, penalties, vct, sent_tk, min_size=25)\n",
      "print_thresholds(thres, penalties, resl2)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[ 0.3   0.35  0.4   0.45]\n",
        "[  1.00000000e-02   1.00000000e-01   1.00000000e+00   1.00000000e+01\n",
        "   1.00000000e+02]\n",
        "Penalty"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 0.01\n",
        "UNC: Mean: 0.493, Median: 0.500, Std.: 0.015, min: 0.460490, max: 0.500000, N=763 \n",
        "None\n",
        "Accuracy: 0.496723460026\n",
        "Penalty 0.1\n",
        "UNC: Mean: 0.359, Median: 0.421, Std.: 0.134, min: 0.037025, max: 0.500000, N=763 \n",
        "None\n",
        "Accuracy: 0.720838794233\n",
        "Penalty"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 1.0\n",
        "UNC: Mean: 0.223, Median: 0.211, Std.: 0.156, min: 0.000676, max: 0.499605, N=763 \n",
        "None\n",
        "Accuracy: 0.744429882045\n",
        "Penalty 10.0\n",
        "UNC: Mean: 0.131, Median: 0.059, Std.: 0.153, min: 0.000000, max: 0.494939, N=763 \n",
        "None\n",
        "Accuracy: 0.737876802097\n",
        "Penalty"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 100.0\n",
        "UNC: Mean: 0.099, Median: 0.025, Std.: 0.137, min: 0.000000, max: 0.495765, N=763 \n",
        "None\n",
        "Accuracy: 0.737876802097\n",
        "\n",
        "\t0.3\t0.35\t0.4\t0.45\n",
        "0.01 =\t1.000\t1.000\t1.000\t1.000\n",
        "0.1 =\t0.693\t0.630\t0.554\t0.350\n",
        "1.0 =\t0.370\t0.290\t0.182\t0.081\n",
        "10.0 =\t0.190\t0.149\t0.106\t0.046\n",
        "100.0 =\t0.121\t0.104\t0.063\t0.034\n"
       ]
      }
     ],
     "prompt_number": 22
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "resl2 = test_neutral_counts(data.train, {'bow':vct.transform(x_snip), 'target':target},\n",
      "                           np.arange(.35, .45, .025), penalties, vct, sent_tk, min_size=25)\n",
      "print_thresholds(np.arange(.35, .45, .025), penalties, resl2)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Penalty 0.01\n",
        "UNC: Mean: 0.493, Median: 0.500, Std.: 0.015, min: 0.460490, max: 0.500000, N=763 \n",
        "None\n",
        "Accuracy: 0.496723460026\n",
        "Penalty 0.1\n",
        "UNC: Mean: 0.359, Median: 0.421, Std.: 0.134, min: 0.037023, max: 0.500000, N=763 \n",
        "None\n",
        "Accuracy: 0.720838794233\n",
        "Penalty 1.0\n",
        "UNC: Mean: 0.223, Median: 0.211, Std.: 0.156, min: 0.000678, max: 0.499207, N=763 \n",
        "None\n",
        "Accuracy: 0.744429882045\n",
        "Penalty"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 10.0\n",
        "UNC: Mean: 0.131, Median: 0.063, Std.: 0.153, min: 0.000000, max: 0.499574, N=763 \n",
        "None\n",
        "Accuracy: 0.737876802097\n",
        "Penalty 100.0\n",
        "UNC: Mean: 0.101, Median: 0.026, Std.: 0.139, min: 0.000000, max: 0.499477, N=763 \n",
        "None\n",
        "Accuracy: 0.741808650066\n",
        "\n",
        "\t0.35\t0.375\t0.4\t0.425\t0.45\n",
        "0.01 =\t1.000\t1.000\t1.000\t1.000\t1.000\n",
        "0.1 =\t0.630\t0.596\t0.554\t0.490\t0.350\n",
        "1.0 =\t0.290\t0.231\t0.181\t0.131\t0.081\n",
        "10.0 =\t0.142\t0.122\t0.101\t0.080\t0.050\n",
        "100.0 =\t0.094\t0.081\t0.066\t0.055\t0.042\n"
       ]
      }
     ],
     "prompt_number": 25
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# IMDB and SRAA Testing the thersholds"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "vct1 = exputil.get_vectorizer({'vectorizer':\"bow\", 'limit':None, 'min_size':100})\n",
      "imdb, vct1 = load_data('imdb', IMDB_DATA, vct1)\n",
      "vct2 = exputil.get_vectorizer({'vectorizer':\"bow\", 'limit':None, 'min_size':100})\n",
      "sraa, vct2 = load_data('sraa', SRAA_DATA, vct2)\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 30
    },
    {
     "cell_type": "code",
     "collapsed": true,
     "input": [
      "print tk"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "<utilities.datautils.StemTokenizer object at 0x112a95510>\n"
       ]
      }
     ],
     "prompt_number": 31
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## IMDB test"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "thres1 = thres\n",
      "penalties1 = np.arange(.1, .5, .1)\n",
      "x_snip, target = get_data_size(imdb.test.data, imdb.test.target, 25, tk)\n",
      "resl2 = test_neutral_counts(imdb.train, {'bow':vct1.transform(x_snip), 'target':target},\n",
      "                           thres1, penalties, vct1, sent_tk, min_size=25)\n",
      "print_thresholds(thres1, penalties, resl2)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Penalty 0.01\n",
        "UNC: Mean: 0.411, Median: 0.438, Std.: 0.083, min: 0.014718, max: 0.499999, N=24989 \n",
        "None\n",
        "Accuracy: 0.65676897835\n",
        "Penalty"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 0.1\n",
        "UNC: Mean: 0.351, Median: 0.376, Std.: 0.112, min: 0.005261, max: 0.499999, N=24989 \n",
        "None\n",
        "Accuracy: 0.700068029933\n",
        "Penalty"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 1.0\n",
        "UNC: Mean: 0.247, Median: 0.247, Std.: 0.146, min: 0.000037, max: 0.499986, N=24989 \n",
        "None\n",
        "Accuracy: 0.694945776142\n",
        "Penalty"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 10.0\n",
        "UNC: Mean: 0.173, Median: 0.132, Std.: 0.153, min: 0.000000, max: 0.499985, N=24989 \n",
        "None\n",
        "Accuracy: 0.690944015367\n",
        "Penalty"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 100.0\n",
        "UNC: Mean: 0.169, Median: 0.126, Std.: 0.153, min: 0.000000, max: 0.499972, N=24989 \n",
        "None\n",
        "Accuracy: 0.702709192044\n",
        "\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\t0.3\t0.35\t0.4\t0.45\n",
        "0.01 =\t0.881\t0.793\t0.659\t0.435\n",
        "0.1 =\t0.704\t0.578\t0.417\t0.220\n",
        "1.0 =\t0.396\t0.294\t0.198\t0.100\n",
        "10.0 =\t0.243\t0.179\t0.120\t0.061\n",
        "100.0 =\t0.240\t0.178\t0.116\t0.058\n"
       ]
      }
     ],
     "prompt_number": 34
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "x_snip, target = get_data_size(imdb.test.data, imdb.test.target, 25, tk)\n",
      "resl2 = test_neutral_counts(imdb.train, {'bow':vct1.transform(x_snip), 'target':target},\n",
      "                           thres, [.1,.2,.3,.4], vct1, sent_tk, min_size=25)\n",
      "print_thresholds(thres, [.1,.2,.3,.4], resl2)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Penalty 0.1\n",
        "UNC: Mean: 0.351, Median: 0.376, Std.: 0.112, min: 0.005254, max: 0.499997, N=24989 \n",
        "None\n",
        "Accuracy: 0.700148065149\n",
        "Penalty"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 0.2\n",
        "UNC: Mean: 0.328, Median: 0.350, Std.: 0.122, min: 0.002770, max: 0.499996, N=24989 \n",
        "None\n",
        "Accuracy: 0.702188963144\n",
        "Penalty"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 0.3\n",
        "UNC: Mean: 0.310, Median: 0.330, Std.: 0.128, min: 0.001182, max: 0.499968, N=24989 \n",
        "None\n",
        "Accuracy: 0.699347712994\n",
        "Penalty"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 0.4\n",
        "UNC: Mean: 0.295, Median: 0.312, Std.: 0.133, min: 0.000580, max: 0.499968, N=24989 \n",
        "None\n",
        "Accuracy: 0.698107167154\n",
        "\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\t0.3\t0.35\t0.4\t0.45\n",
        "0.1 =\t0.704\t0.579\t0.417\t0.220\n",
        "0.2 =\t0.631\t0.500\t0.346\t0.178\n",
        "0.3 =\t0.574\t0.445\t0.305\t0.156\n",
        "0.4 =\t0.529\t0.408\t0.276\t0.139\n"
       ]
      }
     ],
     "prompt_number": 39
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "penalties1 = np.arange(.1, .5, .1)\n",
      "### Acording to user studies C=0.3, T=.4 -> 25 words = 32% neutrals, 10 words = 55% neutrals\n",
      "\n",
      "x_snip, target = get_data_size(imdb.test.data, imdb.test.target, 10, tk)\n",
      "resl2 = test_neutral_counts(imdb.train, {'bow':vct1.transform(x_snip), 'target':target},\n",
      "                           thres, penalties1, vct1, sent_tk, min_size=25)\n",
      "print_thresholds(thres, penalties1, resl2)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Penalty 0.1\n",
        "UNC: Mean: 0.403, Median: 0.429, Std.: 0.085, min: 0.036256, max: 0.499988, N=24989 \n",
        "None\n",
        "Accuracy: 0.639961583097\n",
        "Penalty"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 0.2\n",
        "UNC: Mean: 0.384, Median: 0.409, Std.: 0.094, min: 0.019110, max: 0.499997, N=24989 \n",
        "None\n",
        "Accuracy: 0.64096202329\n",
        "Penalty"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 0.3\n",
        "UNC: Mean: 0.371, Median: 0.395, Std.: 0.101, min: 0.012055, max: 0.499997, N=24989 \n",
        "None\n",
        "Accuracy: 0.641362199368\n",
        "Penalty"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 0.4\n",
        "UNC: Mean: 0.360, Median: 0.384, Std.: 0.107, min: 0.008561, max: 0.499999, N=24989 \n",
        "None\n",
        "Accuracy: 0.641482252191\n",
        "\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\t0.3\t0.35\t0.4\t0.45\n",
        "0.1 =\t0.875\t0.785\t0.636\t0.371\n",
        "0.2 =\t0.827\t0.717\t0.540\t0.286\n",
        "0.3 =\t0.784\t0.661\t0.480\t0.250\n",
        "0.4 =\t0.746\t0.617\t0.437\t0.226\n"
       ]
      }
     ],
     "prompt_number": 38
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## SRAA test\n"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print thres\n",
      "print penalties\n",
      "### Acording to user studies C=0.01, T=.3 -> 25 words = 48% neutrals, 10 words = 58% neutrals\n",
      "x_snip, target = get_data_size(sraa.test.data, sraa.test.target, 25, tk)\n",
      "resl2 = test_neutral_counts(sraa.train, {'bow':vct2.transform(x_snip), 'target':target},\n",
      "                           thres, penalties, vct2, sent_tk, min_size=25)\n",
      "print_thresholds(thres, penalties, resl2)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[ 0.3   0.35  0.4   0.45]\n",
        "[  1.00000000e-02   1.00000000e-01   1.00000000e+00   1.00000000e+01\n",
        "   1.00000000e+02]\n",
        "Penalty"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 0.01\n",
        "UNC: Mean: 0.246, Median: 0.260, Std.: 0.180, min: 0.000021, max: 0.499360, N=36609 \n",
        "None\n",
        "Accuracy: 0.803927995848\n",
        "Penalty"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 0.1\n",
        "UNC: Mean: 0.156, Median: 0.075, Std.: 0.168, min: 0.000000, max: 0.499973, N=36609 \n",
        "None\n",
        "Accuracy: 0.902045944986\n",
        "Penalty"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 1.0\n",
        "UNC: Mean: 0.083, Median: 0.008, Std.: 0.135, min: 0.000000, max: 0.499980, N=36609 \n",
        "None\n",
        "Accuracy: 0.940205960283\n",
        "Penalty"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 10.0\n",
        "UNC: Mean: 0.049, Median: 0.001, Std.: 0.108, min: 0.000000, max: 0.499898, N=36609 \n",
        "None\n",
        "Accuracy: 0.946625146822\n",
        "Penalty"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 100.0\n",
        "UNC: Mean: 0.044, Median: 0.002, Std.: 0.100, min: 0.000000, max: 0.499932, N=36609 \n",
        "None\n",
        "Accuracy: 0.959763992461\n",
        "\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\t0.3\t0.35\t0.4\t0.45\n",
        "0.01 =\t0.478\t0.464\t0.439\t0.053\n",
        "0.1 =\t0.267\t0.214\t0.142\t0.069\n",
        "1.0 =\t0.117\t0.089\t0.059\t0.029\n",
        "10.0 =\t0.063\t0.046\t0.031\t0.015\n",
        "100.0 =\t0.052\t0.038\t0.025\t0.012\n"
       ]
      }
     ],
     "prompt_number": 40
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "x_snip, target = get_data_size(sraa.test.data, sraa.test.target, 10, tk)\n",
      "resl2 = test_neutral_counts(sraa.train, {'bow':vct2.transform(x_snip), 'target':target},\n",
      "                           thres, penalties, vct2, sent_tk, min_size=25)\n",
      "print_thresholds(thres, penalties, resl2)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Penalty 0.01\n",
        "UNC: Mean: 0.285, Median: 0.422, Std.: 0.175, min: 0.000340, max: 0.499101, N=36609 \n",
        "None\n",
        "Accuracy: 0.748504466115\n",
        "Penalty"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 0.1\n",
        "UNC: Mean: 0.206, Median: 0.169, Std.: 0.177, min: 0.000003, max: 0.499980, N=36609 \n",
        "None\n",
        "Accuracy: 0.84350842689\n",
        "Penalty"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 1.0\n",
        "UNC: Mean: 0.134, Median: 0.035, Std.: 0.165, min: 0.000000, max: 0.499982, N=36609 \n",
        "None\n",
        "Accuracy: 0.899751427245\n",
        "Penalty"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 10.0\n",
        "UNC: Mean: 0.088, Median: 0.005, Std.: 0.143, min: 0.000000, max: 0.499985, N=36609 \n",
        "None\n",
        "Accuracy: 0.91335463957\n",
        "Penalty"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 100.0\n",
        "UNC: Mean: 0.081, Median: 0.008, Std.: 0.133, min: 0.000000, max: 0.499930, N=36609 \n",
        "None\n",
        "Accuracy: 0.931601518752\n",
        "\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\t0.3\t0.35\t0.4\t0.45\n",
        "0.01 =\t0.592\t0.583\t0.564\t0.049\n",
        "0.1 =\t0.396\t0.341\t0.236\t0.071\n",
        "1.0 =\t0.225\t0.177\t0.122\t0.061\n",
        "10.0 =\t0.135\t0.102\t0.067\t0.034\n",
        "100.0 =\t0.114\t0.084\t0.056\t0.028\n"
       ]
      }
     ],
     "prompt_number": 41
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Testing sentences tokenizer on SRAA \n",
      "\n",
      "Check that the sentences is split correctly for the subject line of the documents \n",
      "\n",
      "Check if 20 news groups has a subject"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "tmp = sent_tk.tokenize_sents(sraa.train.data[:10])\n",
      "\n",
      "for t in tmp:\n",
      "    print t[0]\n",
      "    print \"-\" * 20"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Subject: Re: <HELP>GPL crashes in win98\n",
        "Hi Eric,\n",
        "\n",
        "I'm using the intergraph reactor with the default rendition v1000\n",
        "driver.\n",
        "--------------------\n",
        "Subject: PP99 in UK?\n",
        "--------------------\n",
        "Subject: Re: next weekend at Suzuka (was: Possible to insert cars from Monoco...)\n",
        "Paul,\n",
        "\n",
        "Try the setups from this site.\n",
        "--------------------\n",
        "Subject: Re: Driving standards\n",
        "Sometimes if there is a large gap in speed people can misjudge braking and\n",
        "get over their heads.\n",
        "--------------------\n",
        "Subject: Real A320 simulators\n",
        "A while back in one of the aviation newsgroups, there was a story of a\n",
        "guy who\n",
        "for whatever reason, had to take the controls of his 757 airliner and\n",
        "land the\n",
        "plane.\n",
        "--------------------\n",
        "Subject: Re: Max framerate GPL\n",
        "On Sun, 04 Oct 1998 10:41:21 GMT,\n",
        "in msg <36174edd.30591353@news.sgi.net>,\n",
        "dafney1@sgi.net said :\n",
        "\n",
        ">Fooling around with different resolutions  and detail between\n",
        ">Stealth2 and V2 it appears frame rate maxes out at 36 fps.\n",
        "--------------------\n",
        "Subject: Re: Clicking noise\n",
        "It might be pinging.\n",
        "--------------------\n",
        "Subject: Re: ADDICTION -New NG\n",
        "\n",
        "--WebTV-Mail-87243911-1786\n",
        "Content-Type: Text/Plain; Charset=US-ASCII\n",
        "Content-Transfer-Encoding: 7Bit\n",
        "\n",
        "Rec.Airportbum.aviation,I expect lots of posts from this crowd.\n",
        "--------------------\n",
        "Subject: Re: PitsPatch99 for N99\n",
        "Where would one find these patches?\n",
        "\n",
        "--------------------\n",
        "Subject: TOCA 2 (PC) cheats for all tracks / cars\n",
        "can anyone give me the cheat codes for all tracks / all cars ?\n",
        "--------------------\n"
       ]
      }
     ],
     "prompt_number": 42
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "tmp = sent_tk.tokenize_sents(data.train.data[:10])\n",
      "\n",
      "for t in tmp:\n",
      "    print t[0]\n",
      "    print \"-\" * 20"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        ": Does anyone out there have any info on the up and coming fall comdex '93?\n",
        "--------------------\n",
        "...\n",
        "--------------------\n",
        "[stuff deleted]\n",
        "\n",
        "  Not only do you lose AccuColor, you also had to give up 1280x1024\n",
        "non-interlaced mode, the wider 135 Mhz bandwidth and the Mac\n",
        "and BNC inputs of the 5FG.\n",
        "--------------------\n",
        "I recently purchased a Diamond Stealth 24 Video card\n",
        "and received the wrong drivers.\n",
        "--------------------\n",
        "If anyone has any experience with the ALR ProVEISA 486DX2 system I would \n",
        "be interested to hear your impressions of it, and of ALR in general.\n",
        "--------------------\n",
        "I have a like new Hayes JT FAX for sale $125 or offer or trade!\n",
        "--------------------\n",
        "\n",
        " :Because of some contract, IBM is not allowed to sell its\n",
        " :486 chips to third parties, so these chips are unlikely to become\n",
        " :available in any non-IBM machines.\n",
        "--------------------\n",
        "-------------------------------------------------------------------------\n",
        "Anonymous,\n",
        "\n",
        "I saw a posting about the choice between 80486DX-50 and a 80486DX2-50.\n",
        "--------------------\n",
        "Due to the resolution and size it is in 14 parts.\n",
        "--------------------\n",
        "Please reply via EMail...\n",
        "--------------------\n"
       ]
      }
     ],
     "prompt_number": 43
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}