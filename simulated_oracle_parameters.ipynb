{
 "metadata": {
  "name": "",
  "signature": "sha256:dd93524367e8bd74ce2bc98641f5ac951904ee117e4c292739ebe715b41a080c"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# Simulated Oracle Parameters\n",
      "\n",
      "We want to find the best set of C and T(hreshold) values for the oracle classifier to simulate human behavior. The paramters will determine the percentage of queries that will be answered as neutral by the classifiers."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "## Imports \n",
      "%matplotlib inline\n",
      "\n",
      "STRUCTURED = '/Users/maru/MyCode/structured'\n",
      "IMDB_DATA='/Users/maru/MyCode/data/imdb'\n",
      "SRAA_DATA='/Users/maru/MyCode/data/sraa'\n",
      "TWIITER_DATA = ''\n",
      "\n",
      "# STRUCTURED = '/Users/maru/My Code/structured'\n",
      "# IMDB_DATA='/Users/maru/Dataset/aclImdb'\n",
      "# SRAA_DATA='/Users/maru/Dataset/aviation/data'\n",
      "# TWIITER_DATA = '/Users/maru/Dataset/twitter'\n",
      "\n",
      "import sys\n",
      "import os\n",
      "sys.path.append(os.path.abspath(STRUCTURED))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import utilities.experimentutils as exputil\n",
      "import utilities.datautils as datautil\n",
      "import numpy as np\n",
      "import nltk\n",
      "from sklearn import metrics\n",
      "import matplotlib.pyplot as plt\n",
      "import matplotlib as mpl\n",
      "\n",
      "mpl.style.use('bmh')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 2
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Loading Data\n",
      "vct = exputil.get_vectorizer({'vectorizer':\"bow\", 'limit':None, 'min_size':100})\n",
      "# Sentence tokenizers\n",
      "sent_tk = nltk.data.load('tokenizers/punkt/english.pickle')\n",
      "\n",
      "def load_data(dataname, path, vct, categories=None):\n",
      "    import pickle\n",
      "\n",
      "    DATA_PKL = path + '/data.pkl'\n",
      "    \n",
      "    if os.path.isfile(DATA_PKL):\n",
      "        vct, data = pickle.load(open(DATA_PKL, 'rb'))\n",
      "    else:\n",
      "        #vct = exputil.get_vectorizer({'vectorizer':\"tfidf\", 'limit':None, 'min_size':None})\n",
      "        data = datautil.load_dataset(dataname, path, categories=categories, rnd=5463, shuffle=True, keep_subject=True)\n",
      "        data.train.data = np.array(data.train.data, dtype=object)\n",
      "        data.test.data = np.array(data.test.data, dtype=object)\n",
      "        data.train.bow = vct.fit_transform(data.train.data)\n",
      "        data.test.bow = vct.transform(data.test.data)\n",
      "        pickle.dump((vct, data), open(DATA_PKL, 'wb'))\n",
      "\n",
      "    return data, vct\n",
      "from collections import defaultdict\n",
      "# Get the sentences for testing\n",
      "def _sentences(docs, doc_labels, sent_tk):\n",
      "    data = []\n",
      "    true_labels = []\n",
      "    sent = sent_tk.tokenize_sents(docs)\n",
      "    for sentences, doc_label in zip(sent, doc_labels):\n",
      "        data.extend(sentences)\n",
      "        true_labels.extend([doc_label] * len(sentences))\n",
      "    return data, np.array(true_labels)\n",
      "\n",
      "\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 96
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def count_neutrals(probs, thresholds):\n",
      "    unc = 1. - probs.max(1)\n",
      "    n = 1.* len(probs)\n",
      "    counts = [sum(unc > t)/n for t in thresholds]\n",
      "    return counts\n",
      "\n",
      "def _stats(a):\n",
      "    print \"Mean: %.3f, Median: %.3f, Std.: %.3f, min: %f, max: %f, N=%d \" % (np.mean(a), np.median(a), np.std(a), np.min(a), np.max(a), len(a))\n",
      "        \n",
      "\n",
      "\n",
      "def test_neutral_counts(train, test, thresholds, penalties, vct, sent_tk, min_size=25):\n",
      "\n",
      "    res = defaultdict(lambda x: [])\n",
      "    for c in penalties:\n",
      "        \n",
      "        clf = exputil.get_classifier('lrl1', parameter=c)\n",
      "        ## train classifier\n",
      "        clf.fit(train.bow, train.target)\n",
      "        # get testing data\n",
      "        probs = clf.predict_proba(test['bow'])\n",
      "        unc = 1. - probs.max(1)\n",
      "        print \"Penalty\", clf.C\n",
      "        print \"UNC:\", _stats(unc)\n",
      "        print \"Accuracy:\", metrics.accuracy_score(test['target'], clf.predict(test['bow']))\n",
      "        count = count_neutrals(probs, thresholds)\n",
      "        res[c] = count\n",
      "        \n",
      "    return res\n",
      "\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 85
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Load the dataset\n",
      "# imdb, vct = load_data('imdb', IMDB_DATA)\n",
      "data, vct = load_data('20news', '.', vct, categories='hardware')\n",
      "# get testing files for IMDB\n",
      "rnd = np.random.RandomState(2345)\n",
      "\n",
      "# Get the sentences snippets\n",
      "sents = _sentences(data.train.data, data.train.target, sent_tk)\n",
      "sents_bow = vct.transform(sents[0])\n",
      "\n",
      "thres = np.arange(.3, .46, .05)\n",
      "penalties = np.array([pow(10,x) for x in range(-2,3)])\n",
      "\n",
      "\n",
      "tk = vct.build_tokenizer()\n",
      "\n",
      "x_tex = [len(tk(d)) for d in data.train.data]\n",
      "\n",
      "resl = test_neutral_counts(data.train, {'bow':sents_bow, 'target':sents[1]}, thres, penalties, vct, sent_tk, min_size=25)\n",
      "\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Penalty 0.01\n",
        "UNC: Mean: 0.500, Median: 0.500, Std.: 0.000, min: 0.500000, max: 0.500000, N=6388 \n",
        "None\n",
        "Accuracy: 0.481840951785\n",
        "Penalty 0.1\n",
        "UNC: Mean: 0.435, Median: 0.483, Std.: 0.095, min: 0.086546, max: 0.500000, N=6388 \n",
        "None\n",
        "Accuracy: 0.614902943018\n",
        "Penalty"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 1.0\n",
        "UNC: Mean: 0.304, Median: 0.351, Std.: 0.136, min: 0.000154, max: 0.499951, N=6388 \n",
        "None\n",
        "Accuracy: 0.679398872887\n",
        "Penalty"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 10.0\n",
        "UNC: Mean: 0.186, Median: 0.161, Std.: 0.156, min: 0.000000, max: 0.499917, N=6388 \n",
        "None\n",
        "Accuracy: 0.659517845961\n",
        "Penalty"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 100.0\n",
        "UNC: Mean: 0.130, Median: 0.060, Std.: 0.148, min: 0.000000, max: 0.499395, N=6388 \n",
        "None\n",
        "Accuracy: 0.646837820914\n"
       ]
      }
     ],
     "prompt_number": 88
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "## Print results of penalty of classifier and threshold, showing percentage of neutral\n",
      "def print_thresholds(thres, penalties, resl):\n",
      "    print \n",
      "    print \"\\t\", \"\\t\".join(\"%s\" % t for t in thres)\n",
      "    for p in penalties:\n",
      "        print \"%s =\\t%s\" %(p, \"\\t\".join(\"%.3f\" % t for t in resl[p]))\n",
      "        \n",
      "print_thresholds(thres, penalties, resl)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "\t0.3\t0.35\t0.4\t0.45\n",
        "0.01 =\t1.000\t1.000\t1.000\t1.000\n",
        "0.1 =\t0.866\t0.825\t0.774\t0.686\n",
        "1.0 =\t0.603\t0.503\t0.255\t0.116\n",
        "10.0 =\t0.306\t0.191\t0.121\t0.057\n",
        "100.0 =\t0.209\t0.113\t0.073\t0.038\n"
       ]
      }
     ],
     "prompt_number": 89
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "sent_len = [len(tk(d)) for d in sents[0]]\n",
      "_stats(sent_len)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Mean: 26.221, Median: 14.000, Std.: 64.319, min: 0.000000, max: 1452.000000, N=6388 \n"
       ]
      }
     ],
     "prompt_number": 90
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "resl2 = test_neutral_counts(data.train, {'bow':sents_bow, 'target':sents[1]},\n",
      "                           np.arange(.35, .45, .025), [1,10], vct, sent_tk, min_size=25)\n",
      "print_thresholds(np.arange(.35, .45, .025), [1,10], resl2)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Penalty 1\n",
        "UNC: avg.: 0.304, min: 0.000, max: 0.500\n",
        "Accuracy: 0.679555416406\n",
        "Penalty"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 10\n",
        "UNC: avg.: 0.186, min: 0.000, max: 0.500\n",
        "Accuracy: 0.658108954289\n",
        "\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\t0.35\t0.375\t0.4\t0.425\t0.45\n",
        "1 =\t0.503\t0.437\t0.255\t0.179\t0.115\n",
        "10 =\t0.191\t0.153\t0.119\t0.083\t0.057\n"
       ]
      }
     ],
     "prompt_number": 63
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### Notes: \n",
      "\n",
      "We can use expert l1 with bow and C=1 T=.35 that gives 50 neutrals or .4 with 24 neutrals.\n",
      "\n",
      ".375 gives 44% neutrals\n",
      "\n",
      "---------"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "doc_sent = sent_tk.tokenize_sents(data.train.data)\n",
      "first = [d[0] for d in doc_sent]\n",
      "len_first = [len(tk(s)) for s in first]\n",
      "\n",
      "print len(data.train.data), len(first)\n",
      "_stats(len_first)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "832 832\n",
        "Mean: 19.327, Median: 14, Std.: 52.459, min: 0, max: 1452, N=832 \n"
       ]
      }
     ],
     "prompt_number": 76
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "resl2 = test_neutral_counts(data.train, {'bow':vct.transform(first), 'target':data.train.target},\n",
      "                           thres, penalties, vct, sent_tk, min_size=25)\n",
      "print_thresholds(thres, penalties, resl2)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Penalty 0.01\n",
        "UNC: Mean: 0.500, Median: 0.500, Std.: 0.000, min: 0, max: 0, N=832 \n",
        "None\n",
        "Accuracy: 0.491586538462\n",
        "Penalty 0.1\n",
        "UNC: Mean: 0.423, Median: 0.476, Std.: 0.106, min: 0, max: 0, N=832 \n",
        "None\n",
        "Accuracy: 0.661057692308\n",
        "Penalty 1.0\n",
        "UNC: Mean: 0.281, Median: 0.313, Std.: 0.143, min: 0, max: 0, N=832 \n",
        "None\n",
        "Accuracy: 0.747596153846\n",
        "Penalty 10.0\n",
        "UNC: Mean: 0.141, Median: 0.081, Std.: 0.144, min: 0, max: 0, N=832 \n",
        "None\n",
        "Accuracy: 0.786057692308\n",
        "Penalty"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 100.0\n",
        "UNC: Mean: 0.095, Median: 0.019, Std.: 0.135, min: 0, max: 0, N=832 \n",
        "None\n",
        "Accuracy: 0.788461538462\n",
        "\n",
        "\t0.3\t0.35\t0.4\t0.45\n",
        "0.01 =\t1.000\t1.000\t1.000\t1.000\n",
        "0.1 =\t0.834\t0.786\t0.726\t0.642\n",
        "1.0 =\t0.529\t0.438\t0.227\t0.099\n",
        "10.0 =\t0.204\t0.127\t0.081\t0.034\n",
        "100.0 =\t0.136\t0.082\t0.053\t0.032\n"
       ]
      }
     ],
     "prompt_number": 83
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "resl2 = test_neutral_counts(data.train, {'bow':vct.transform(first), 'target':data.train.target},\n",
      "                           np.arange(.35, .45, .025), [1,10], vct, sent_tk, min_size=25)\n",
      "print_thresholds(np.arange(.35, .45, .025), [1,10], resl2)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Penalty 1\n",
        "UNC: Mean: 0.281, Median: 0.313, Std.: 0.144, min: 0, max: 0, N=832 \n",
        "None\n",
        "Accuracy: 0.747596153846\n",
        "Penalty 10\n",
        "UNC: Mean: 0.141, Median: 0.082, Std.: 0.145, min: 0, max: 0, N=832 \n",
        "None\n",
        "Accuracy: 0.783653846154\n",
        "\n",
        "\t0.35\t0.375\t0.4\t0.425\t0.45\n",
        "1 =\t0.438\t0.367\t0.227\t0.162\t0.101\n",
        "10 =\t0.127\t0.107\t0.078\t0.048\t0.035\n"
       ]
      }
     ],
     "prompt_number": 84
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# IMDB and SRAA Testing the thersholds"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def get_data_size(data, target, size, tk):\n",
      "    x = [\" \".join(tk(d)[:size]) for d in data]\n",
      "    return x, target\n",
      "reload(datautil)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 102,
       "text": [
        "<module 'utilities.datautils' from '/Users/maru/MyCode/structured/utilities/datautils.pyc'>"
       ]
      }
     ],
     "prompt_number": 102
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "vct1 = exputil.get_vectorizer({'vectorizer':\"bow\", 'limit':None, 'min_size':100})\n",
      "imdb, vct1 = load_data('imdb', IMDB_DATA, vct1)\n",
      "vct2 = exputil.get_vectorizer({'vectorizer':\"bow\", 'limit':None, 'min_size':100})\n",
      "sraa, vct2 = load_data('sraa', SRAA_DATA, vct2)\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 103
    },
    {
     "cell_type": "code",
     "collapsed": true,
     "input": [
      "print tk"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "<utilities.datautils.StemTokenizer object at 0x113389e90>\n"
       ]
      }
     ],
     "prompt_number": 106
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "x_snip, target = get_data_size(imdb.train.data, imdb.train.target, 25, tk)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 109
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print thres\n",
      "print penalties\n",
      "resl2 = test_neutral_counts(imdb.train, {'bow':vct1.transform(x_snip), 'target':target},\n",
      "                           thres, penalties, vct1, sent_tk, min_size=25)\n",
      "print_thresholds(thres, penalties, resl2)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[ 0.3   0.35  0.4   0.45]\n",
        "[  1.00000000e-02   1.00000000e-01   1.00000000e+00   1.00000000e+01\n",
        "   1.00000000e+02]\n",
        "Penalty"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 0.01\n",
        "UNC: Mean: 0.411, Median: 0.438, Std.: 0.083, min: 0.034020, max: 0.499997, N=24991 \n",
        "None\n",
        "Accuracy: 0.663999039654\n",
        "Penalty"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 0.1\n",
        "UNC: Mean: 0.350, Median: 0.374, Std.: 0.111, min: 0.006890, max: 0.499994, N=24991 \n",
        "None\n",
        "Accuracy: 0.707654755712\n",
        "Penalty"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 1.0\n",
        "UNC: Mean: 0.243, Median: 0.241, Std.: 0.146, min: 0.000033, max: 0.499988, N=24991 \n",
        "None\n",
        "Accuracy: 0.727982073546\n",
        "Penalty"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 10.0\n",
        "UNC: Mean: 0.167, Median: 0.122, Std.: 0.152, min: 0.000000, max: 0.499994, N=24991 \n",
        "None\n",
        "Accuracy: 0.735664839342\n",
        "Penalty"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 100.0\n",
        "UNC: Mean: 0.159, Median: 0.109, Std.: 0.151, min: 0.000000, max: 0.499999, N=24991 \n",
        "None\n",
        "Accuracy: 0.758633107919\n",
        "\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\t0.3\t0.35\t0.4\t0.45\n",
        "0.01 =\t0.882\t0.794\t0.659\t0.435\n",
        "0.1 =\t0.702\t0.571\t0.410\t0.215\n",
        "1.0 =\t0.387\t0.288\t0.194\t0.096\n",
        "10.0 =\t0.236\t0.173\t0.115\t0.057\n",
        "100.0 =\t0.219\t0.161\t0.106\t0.054\n"
       ]
      }
     ],
     "prompt_number": 111
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "resl2 = test_neutral_counts(imdb.train, {'bow':vct1.transform(x_snip), 'target':target},\n",
      "                           thres, [.1,.2,.3,.4], vct1, sent_tk, min_size=25)\n",
      "print_thresholds(thres, [.1,.2,.3,.4], resl2)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Penalty 0.1\n",
        "UNC: Mean: 0.350, Median: 0.374, Std.: 0.111, min: 0.006899, max: 0.499998, N=24991 \n",
        "None\n",
        "Accuracy: 0.70725461166\n",
        "Penalty"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 0.2\n",
        "UNC: Mean: 0.324, Median: 0.344, Std.: 0.121, min: 0.004439, max: 0.499995, N=24991 \n",
        "None\n",
        "Accuracy: 0.71481733424\n",
        "Penalty"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 0.3\n",
        "UNC: Mean: 0.308, Median: 0.325, Std.: 0.128, min: 0.002053, max: 0.499964, N=24991 \n",
        "None\n",
        "Accuracy: 0.723020287303\n",
        "Penalty"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 0.4\n",
        "UNC: Mean: 0.293, Median: 0.306, Std.: 0.133, min: 0.000953, max: 0.499983, N=24991 \n",
        "None\n",
        "Accuracy: 0.725141050778\n",
        "\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\t0.3\t0.35\t0.4\t0.45\n",
        "0.1 =\t0.702\t0.570\t0.409\t0.214\n",
        "0.2 =\t0.615\t0.481\t0.331\t0.170\n",
        "0.3 =\t0.561\t0.435\t0.299\t0.153\n",
        "0.4 =\t0.515\t0.396\t0.269\t0.138\n"
       ]
      }
     ],
     "prompt_number": 112
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "x_snip, target = get_data_size(imdb.train.data, imdb.train.target, 10, tk)\n",
      "resl2 = test_neutral_counts(imdb.train, {'bow':vct1.transform(x_snip), 'target':target},\n",
      "                           thres, [.1,.2,.3,.4], vct1, sent_tk, min_size=25)\n",
      "print_thresholds(thres, [.1,.2,.3,.4], resl2)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Penalty 0.1\n",
        "UNC: Mean: 0.404, Median: 0.429, Std.: 0.085, min: 0.039685, max: 0.499999, N=24991 \n",
        "None\n",
        "Accuracy: 0.642151174423\n",
        "Penalty"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 0.2\n",
        "UNC: Mean: 0.383, Median: 0.407, Std.: 0.094, min: 0.025421, max: 0.499993, N=24991 \n",
        "None\n",
        "Accuracy: 0.643831779441\n",
        "Penalty"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 0.3\n",
        "UNC: Mean: 0.370, Median: 0.395, Std.: 0.102, min: 0.015045, max: 0.499984, N=24991 \n",
        "None\n",
        "Accuracy: 0.648913608899\n",
        "Penalty"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 0.4\n",
        "UNC: Mean: 0.359, Median: 0.384, Std.: 0.108, min: 0.010318, max: 0.499991, N=24991 \n",
        "None\n",
        "Accuracy: 0.649793925813\n",
        "\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\t0.3\t0.35\t0.4\t0.45\n",
        "0.1 =\t0.876\t0.788\t0.641\t0.369\n",
        "0.2 =\t0.823\t0.709\t0.534\t0.279\n",
        "0.3 =\t0.781\t0.657\t0.481\t0.252\n",
        "0.4 =\t0.743\t0.613\t0.438\t0.224\n"
       ]
      }
     ],
     "prompt_number": 113
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print thres\n",
      "print penalties\n",
      "x_snip, target = get_data_size(sraa.train.data, sraa.train.target, 25, tk)\n",
      "resl2 = test_neutral_counts(sraa.train, {'bow':vct2.transform(x_snip), 'target':target},\n",
      "                           thres, penalties, vct2, sent_tk, min_size=25)\n",
      "print_thresholds(thres, penalties, resl2)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[ 0.3   0.35  0.4   0.45]\n",
        "[  1.00000000e-02   1.00000000e-01   1.00000000e+00   1.00000000e+01\n",
        "   1.00000000e+02]\n",
        "Penalty"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 0.01\n",
        "UNC: Mean: 0.247, Median: 0.268, Std.: 0.180, min: 0.000098, max: 0.499870, N=36609 \n",
        "None\n",
        "Accuracy: 0.80075937611\n",
        "Penalty"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 0.1\n",
        "UNC: Mean: 0.156, Median: 0.076, Std.: 0.168, min: 0.000000, max: 0.499994, N=36609 \n",
        "None\n",
        "Accuracy: 0.90316588817\n",
        "Penalty"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 1.0\n",
        "UNC: Mean: 0.080, Median: 0.009, Std.: 0.132, min: 0.000000, max: 0.499947, N=36609 \n",
        "None\n",
        "Accuracy: 0.947034882133\n",
        "Penalty"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 10.0\n",
        "UNC: Mean: 0.044, Median: 0.001, Std.: 0.101, min: 0.000000, max: 0.499925, N=36609 \n",
        "None\n",
        "Accuracy: 0.955393482477\n",
        "Penalty"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 100.0\n",
        "UNC: Mean: 0.034, Median: 0.001, Std.: 0.090, min: 0.000000, max: 0.499843, N=36609 \n",
        "None\n",
        "Accuracy: 0.96743970062\n",
        "\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\t0.3\t0.35\t0.4\t0.45\n",
        "0.01 =\t0.481\t0.468\t0.440\t0.056\n",
        "0.1 =\t0.265\t0.214\t0.144\t0.067\n",
        "1.0 =\t0.109\t0.080\t0.053\t0.027\n",
        "10.0 =\t0.053\t0.039\t0.026\t0.012\n",
        "100.0 =\t0.040\t0.029\t0.019\t0.009\n"
       ]
      }
     ],
     "prompt_number": 115
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "x_snip, target = get_data_size(sraa.train.data, sraa.train.target, 10, tk)\n",
      "resl2 = test_neutral_counts(sraa.train, {'bow':vct2.transform(x_snip), 'target':target},\n",
      "                           thres, penalties, vct2, sent_tk, min_size=25)\n",
      "print_thresholds(thres, penalties, resl2)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Penalty 0.01\n",
        "UNC: Mean: 0.285, Median: 0.422, Std.: 0.175, min: 0.000340, max: 0.499293, N=36609 \n",
        "None\n",
        "Accuracy: 0.745636318938\n",
        "Penalty"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 0.1\n",
        "UNC: Mean: 0.206, Median: 0.168, Std.: 0.178, min: 0.000003, max: 0.499999, N=36609 \n",
        "None\n",
        "Accuracy: 0.843726952389\n",
        "Penalty"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 1.0\n",
        "UNC: Mean: 0.130, Median: 0.032, Std.: 0.163, min: 0.000000, max: 0.499864, N=36609 \n",
        "None\n",
        "Accuracy: 0.904149252916\n",
        "Penalty"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 10.0\n",
        "UNC: Mean: 0.084, Median: 0.005, Std.: 0.139, min: 0.000000, max: 0.499876, N=36609 \n",
        "None\n",
        "Accuracy: 0.920347455544\n",
        "Penalty"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 100.0\n",
        "UNC: Mean: 0.075, Median: 0.007, Std.: 0.128, min: 0.000000, max: 0.499987, N=36609 \n",
        "None\n",
        "Accuracy: 0.940697642656\n",
        "\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\t0.3\t0.35\t0.4\t0.45\n",
        "0.01 =\t0.590\t0.582\t0.563\t0.051\n",
        "0.1 =\t0.392\t0.340\t0.236\t0.073\n",
        "1.0 =\t0.216\t0.167\t0.112\t0.056\n",
        "10.0 =\t0.124\t0.094\t0.064\t0.032\n",
        "100.0 =\t0.102\t0.073\t0.048\t0.024\n"
       ]
      }
     ],
     "prompt_number": 117
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}