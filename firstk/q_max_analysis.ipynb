{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis of r $Q_{max}$ \n",
    "\n",
    "In this experiment we use $Q^*_{max}$ to understand the effect of $\\alpha$ on the selection of subinstances. \n",
    "\n",
    "Experiment settings: \n",
    "\n",
    " *  $Q^*$ is the oracle \n",
    " *  The oracle is a logistic regression $L_1$ regularized with $C=0.3$ for IMDB and $C=0.01$ for SRAA \n",
    " *  $Q_{max}$ is the confidence of the oracle for a subinstance of  size k: \n",
    "     - $Q_k = \\max_y Q^*(y|x_i^k)$\n",
    " \n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import sys\n",
    "import os\n",
    "sys.path.append(os.path.abspath('C:/cygwin/home/mramire8/python_code/sr/active'))\n",
    "sys.path.append(os.path.abspath('/Users/maru/MyCode/sr/active'))\n",
    "\n",
    "from sklearn import linear_model\n",
    "\n",
    "from datautil.textutils import StemTokenizer\n",
    "from datautil.load_data import *\n",
    "\n",
    "import numpy as np\n",
    "from time import time\n",
    "import pickle\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "import numpy as np\n",
    "\n",
    "mpl.style.use('bmh')\n",
    "\n",
    "## Get the data ready\n",
    "imdb_path = 'C:/Users/mramire8/Documents/Research/Oracle confidence and Interruption/dataset/aclImdb/raw-data'\n",
    "# imdb_path = '/Users/maru/MyCode/data/imdb'\n",
    "\n",
    "categories = [['alt.atheism', 'talk.religion.misc'],\n",
    "              ['comp.graphics', 'comp.windows.x'],\n",
    "              ['comp.os.ms-windows.misc', 'comp.sys.ibm.pc.hardware'],\n",
    "              ['rec.sport.baseball', 'sci.crypt']]\n",
    "\n",
    "vct = CountVectorizer(encoding='latin-1', min_df=5, max_df=1.0, binary=True, ngram_range=(1, 3),\n",
    "                      token_pattern='\\\\b\\\\w+\\\\b', tokenizer=StemTokenizer())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "dataset = load_dataset(\"imdb\", 100, categories[0], vct, 100, raw=True,  percent=.5, keep_subject=True)\n",
    "sraa = load_dataset(\"aviation\", 100, categories[0], vct2, 100, raw=True,  percent=.5, keep_subject=True)\n",
    "\n",
    "# data = load_dataset('imdb', None, categories[0], vct, 100, percent=.5, keep_subject=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data size 22267\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Data size %s\" % len(dataset.train.data))\n",
    "print\n",
    "\n",
    "kvalues = [10, 25, 50, 75, 100]\n",
    "cost = np.array([5.7, 8.2, 10.9, 15.9, 16.7])\n",
    "\n",
    "threshold = .4\n",
    "\n",
    "def compute_q_max(data_name, dataset, vct, penalty):\n",
    "    n = len(dataset.train.data)\n",
    "    print \"Data size: %s\" %  n\n",
    "    q_max = np.zeros((5,n))\n",
    "\n",
    "    for ki, fixk in enumerate(kvalues):\n",
    "\n",
    "        fixk_saved = \"{0}{1}.p\".format(data_name, fixk)\n",
    "\n",
    "        data = process_data(dataset, fixk, 100, vct, silent=True)\n",
    "\n",
    "        train_x = data.test.bow\n",
    "        train_y = data.test.target\n",
    "\n",
    "        test_x = data.train.bowk\n",
    "        test_y = data.train.target\n",
    "\n",
    "        print \"*\"*60\n",
    "        print\n",
    "        print(\"K= %s\" % fixk)\n",
    "        \n",
    "\n",
    "        clf = linear_model.LogisticRegression(penalty='l1', C=penalty)\n",
    "        print \"penalty: %s\" % penalty \n",
    "        clf.fit(train_x, train_y)\n",
    "\n",
    "\n",
    "        prob_y = clf.predict_proba(test_x)\n",
    "\n",
    "        q = prob_y.max(axis=1)\n",
    "\n",
    "        unc = prob_y.min(axis=1)\n",
    "\n",
    "        print \"N: %s\" % len(test_y)\n",
    "        print \"q: %s\" % q.shape\n",
    "\n",
    "        print \"Ave. unc: %s\" % unc.mean()\n",
    "        print \"Ave. qmax: %s\" % q.mean()\n",
    "        \n",
    "        q_max[ki] = q\n",
    "        \n",
    "    return q_max\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data size 22267\n",
      "\n",
      "Total Documents: 22267\n",
      "Minimum size: 100\n",
      "Fix k: 10\n",
      "Docs left: 22267\n",
      "Vectorizing ...\n",
      "************************************************************\n",
      "\n",
      "K= 10\n",
      "penalty: 0.3\n",
      "Ave. unc: 0.383709611847\n",
      "Ave. qmax: 0.616290388153\n",
      "Total Documents: 22267\n",
      "Minimum size: 100\n",
      "Fix k: 25\n",
      "Docs left: 22267\n",
      "Vectorizing ...\n",
      "************************************************************\n",
      "\n",
      "K= 25\n",
      "penalty: 0.3\n",
      "Ave. unc: 0.315394757857\n",
      "Ave. qmax: 0.684605242143\n",
      "Total Documents: 22267\n",
      "Minimum size: 100\n",
      "Fix k: 50\n",
      "Docs left: 22267\n",
      "Vectorizing ...\n",
      "************************************************************\n",
      "\n",
      "K= 50\n",
      "penalty: 0.3\n",
      "Ave. unc: 0.25426018805\n",
      "Ave. qmax: 0.74573981195\n",
      "Total Documents: 22267\n",
      "Minimum size: 100\n",
      "Fix k: 75\n",
      "Docs left: 22267\n",
      "Vectorizing ...\n",
      "************************************************************\n",
      "\n",
      "K= 75\n",
      "penalty: 0.3\n",
      "Ave. unc: 0.214129386017\n",
      "Ave. qmax: 0.785870613983\n",
      "Total Documents: 22267\n",
      "Minimum size: 100\n",
      "Fix k: 100\n",
      "Docs left: 22267\n",
      "Vectorizing ...\n",
      "************************************************************\n",
      "\n",
      "K= 100\n",
      "penalty: 0.3\n",
      "Ave. unc: 0.183778810241\n",
      "Ave. qmax: 0.816221189759\n"
     ]
    }
   ],
   "source": [
    "\n",
    "q_max = compute_q_max('imdb', dataset, vct, 0.3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(22267L,)\n"
     ]
    }
   ],
   "source": [
    "q_max_sel = q_max.argmax(axis=0)\n",
    "print q_max_sel.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.731\t0.511\t0.659\t0.505\t0.889\t0.516\t0.603\t0.760\t0.804\t0.631\n",
      "0.765\t0.582\t0.623\t0.541\t0.922\t0.655\t0.593\t0.953\t0.880\t0.747\n",
      "0.719\t0.726\t0.691\t0.529\t0.934\t0.862\t0.764\t0.988\t0.890\t0.818\n",
      "0.798\t0.590\t0.756\t0.652\t0.898\t0.777\t0.718\t0.999\t0.930\t0.770\n",
      "0.676\t0.563\t0.779\t0.635\t0.677\t0.522\t0.650\t0.999\t0.981\t0.588\n"
     ]
    }
   ],
   "source": [
    "for i in range(5):\n",
    "    print \"\\t\".join([\"{:.3f}\".format(a) for a in q_max[i][:10]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k=10\tcount=623\tmax=0.0280\n",
      "k=25\tcount=1767\tmax=0.0794\n",
      "k=50\tcount=2978\tmax=0.1337\n",
      "k=75\tcount=4540\tmax=0.2039\n",
      "k=100\tcount=12359\tmax=0.5550\n"
     ]
    }
   ],
   "source": [
    "# Percentage of k-word subinstances where Q_max = Q_k\n",
    "def print_q_max(q_max_sel):\n",
    "    for i in range(5):\n",
    "    #     print \"k=%s max=%s\" % (kvalues[i], 1. * sum((q_max_sel == 0) [(1-q_max[1]) < .4]) / len(q_max_sel) * 100)\n",
    "        print \"k=%s\\tcount=%s\\tmax=%.4f\" % (kvalues[i],sum(q_max_sel == i), np.mean(q_max_sel == i))\n",
    "\n",
    "print_q_max(q_max_sel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def fn(x, alpha):\n",
    "    return np.power(x,alpha)\n",
    "\n",
    "def fn_obj(x, cost, alpha):\n",
    "    ''' Objective function  x^alpha / cost '''\n",
    "    return fn(x,alpha) / cost\n",
    "\n",
    "def compute_alpha(q_max, alpha, cost):\n",
    "    q_obj = np.zeros(q_max.shape)\n",
    "    \n",
    "    # For every row = subinstance k, compute objective function\n",
    "    for i in range(len(q_obj)):\n",
    "        q_obj[i] = fn_obj(q_max[i], cost[i], alpha)\n",
    "        \n",
    "    return q_obj\n",
    "\n",
    "def max_alpha(q_max, alpha, cost, epsilon=0.0):\n",
    "    q = compute_alpha(q_max+epsilon, alpha, cost)\n",
    "    return q.argmax(axis=0)\n",
    "\n",
    "def stats_k(q_mx_sl, q_alpha_sl):\n",
    "    ''' Compares two matrix'''\n",
    "\n",
    "    stats ={}\n",
    "    stats['match'] = (np.sum(q_mx_sl == q_alpha_sl),np.mean(q_mx_sl == q_alpha_sl))\n",
    "    stats['cheaper'] = (np.sum(q_mx_sl > q_alpha_sl),np.mean(q_mx_sl > q_alpha_sl))\n",
    "    stats['expensive'] = (np.sum(q_mx_sl < q_alpha_sl),np.mean(q_mx_sl < q_alpha_sl))\n",
    "    \n",
    "    \n",
    "    for a in np.unique(q_mx_sl):\n",
    "        stats['k=%s'%kvalues[a]] = (np.sum((q_mx_sl[q_mx_sl == q_alpha_sl]) == a ),np.mean((q_mx_sl[q_mx_sl == q_alpha_sl]) == a ))\n",
    "    \n",
    "    \n",
    "    return stats\n",
    "\n",
    "def print_stats(stats):\n",
    "    for k,v in stats.items():\n",
    "        if k in ['match']:\n",
    "            print \"{}:\\t{}\\t{:.4f}\".format(k,*v)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis of $Q_{max}$ for $\\alpha$ values on IMDB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Alpha \t Count \t Percentage\n",
      "0 \tmatch:\t623\t0.0280\n",
      "1 \tmatch:\t849\t0.0381\n",
      "5 \tmatch:\t11881\t0.5336\n",
      "10 \tmatch:\t16543\t0.7429\n",
      "100 \tmatch:\t21593\t0.9697\n",
      "200 \tmatch:\t21890\t0.9831\n",
      "1000 \tmatch:\t22176\t0.9959\n",
      "2000 \tmatch:\t19992\t0.8978\n"
     ]
    }
   ],
   "source": [
    "alphas = np.array([0,1,5,10,100,200,1000,2000])\n",
    "print \"Alpha \\t Count \\t Percentage\" \n",
    "for a in alphas:\n",
    "    \n",
    "    st = stats_k(q_max_sel, max_alpha(q_max, a, cost))\n",
    "    print \"%s \\t\" % a,\n",
    "    print_stats(st)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis of $Q_{max}$ for $\\alpha$ values on SRAA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Documents: 36609\n",
      "Minimum size: 100\n",
      "Fix k: 100\n",
      "Docs left: 22451\n",
      "Vectorizing ...\n",
      "Data size: 22451\n",
      "Total Documents: 22451\n",
      "Minimum size: 100\n",
      "Fix k: 10\n",
      "Docs left: 22451\n",
      "Vectorizing ...\n",
      "************************************************************\n",
      "\n",
      "K= 10\n",
      "penalty: 0.01\n",
      "N: 22451\n",
      "q: 22451\n",
      "Ave. unc: 0.284436192237\n",
      "Ave. qmax: 0.715563807763\n",
      "Total Documents: 22451\n",
      "Minimum size: 100\n",
      "Fix k: 25\n",
      "Docs left: 22451\n",
      "Vectorizing ...\n",
      "************************************************************\n",
      "\n",
      "K= 25\n",
      "penalty: 0.01\n",
      "N: 22451\n",
      "q: 22451\n",
      "Ave. unc: 0.248522570855\n",
      "Ave. qmax: 0.751477429145\n",
      "Total Documents: 22451\n",
      "Minimum size: 100\n",
      "Fix k: 50\n",
      "Docs left: 22451\n",
      "Vectorizing ...\n",
      "************************************************************\n",
      "\n",
      "K= 50\n",
      "penalty: 0.01\n",
      "N: 22451\n",
      "q: 22451\n",
      "Ave. unc: 0.194642761251\n",
      "Ave. qmax: 0.805357238749\n",
      "Total Documents: 22451\n",
      "Minimum size: 100\n",
      "Fix k: 75\n",
      "Docs left: 22451\n",
      "Vectorizing ...\n",
      "************************************************************\n",
      "\n",
      "K= 75\n",
      "penalty: 0.01\n",
      "N: 22451\n",
      "q: 22451\n",
      "Ave. unc: 0.159299006342\n",
      "Ave. qmax: 0.840700993658\n",
      "Total Documents: 22451\n",
      "Minimum size: 100\n",
      "Fix k: 100\n",
      "Docs left: 22451\n",
      "Vectorizing ...\n",
      "************************************************************\n",
      "\n",
      "K= 100\n",
      "penalty: 0.01\n",
      "N: 22451\n",
      "q: 22451\n",
      "Ave. unc: 0.133994713936\n",
      "Ave. qmax: 0.866005286064\n",
      "k=10\tcount=2266\tmax=0.1009\n",
      "k=25\tcount=1349\tmax=0.0601\n",
      "k=50\tcount=3171\tmax=0.1412\n",
      "k=75\tcount=4719\tmax=0.2102\n",
      "k=100\tcount=10946\tmax=0.4876\n"
     ]
    }
   ],
   "source": [
    "vct2 = CountVectorizer(encoding='latin-1', min_df=5, max_df=1.0, binary=True, ngram_range=(1, 3),\n",
    "                      token_pattern='\\\\b\\\\w+\\\\b', tokenizer=StemTokenizer())\n",
    "\n",
    "sraa = load_dataset(\"aviation\", 100, categories[0], vct2, 100, raw=False,  percent=.5, keep_subject=True)\n",
    "\n",
    "q_max_sraa = compute_q_max('aviation', sraa, vct2, 0.01)\n",
    "q_max_sel_sraa = q_max_sraa.argmax(axis=0)\n",
    "print_q_max(q_max_sel_sraa)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Alpha \t Count \t Percentage\n",
      "0 \tmatch:\t2266\t0.1009\n",
      "1 \tmatch:\t2983\t0.1329\n",
      "5 \tmatch:\t7290\t0.3247\n",
      "10 \tmatch:\t8578\t0.3821\n",
      "100 \tmatch:\t13173\t0.5867\n",
      "200 \tmatch:\t14529\t0.6471\n",
      "1000 \tmatch:\t17408\t0.7754\n",
      "1254 \tmatch:\t17650\t0.7862\n",
      "2000 \tmatch:\t16070\t0.7158\n"
     ]
    }
   ],
   "source": [
    "alphas = np.array([0,1,5,10,100,200,1000,1254,2000])\n",
    "cost_sraa= np.array([5.2, 6.5, 7.6, 9.1, 10.3])\n",
    "\n",
    "print \"Alpha \\t Count \\t Percentage\" \n",
    "\n",
    "for a in alphas:\n",
    "    st = stats_k(q_max_sel_sraa, max_alpha(q_max_sraa, a, cost_sraa))\n",
    "    print \"%s \\t\" % a,\n",
    "    print_stats(st)\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Alpha \t Count \t Percentage\n",
      "\n",
      "== Alpha: 0 ==\n",
      "k=25:\t0\t0.0000\n",
      "k=100:\t0\t0.0000\n",
      "cheaper:\t20185\t0.8991\n",
      "match:\t2266\t0.1009\n",
      "k=50:\t0\t0.0000\n",
      "k=75:\t0\t0.0000\n",
      "k=10:\t2266\t1.0000\n",
      "expensive:\t0\t0.0000\n",
      "\n",
      "== Alpha: 1 ==\n",
      "k=25:\t239\t0.0801\n",
      "k=100:\t0\t0.0000\n",
      "cheaper:\t19468\t0.8671\n",
      "match:\t2983\t0.1329\n",
      "k=50:\t440\t0.1475\n",
      "k=75:\t38\t0.0127\n",
      "k=10:\t2266\t0.7596\n",
      "expensive:\t0\t0.0000\n",
      "\n",
      "== Alpha: 5 ==\n",
      "k=25:\t348\t0.0477\n",
      "k=100:\t2553\t0.3502\n",
      "cheaper:\t15161\t0.6753\n",
      "match:\t7290\t0.3247\n",
      "k=50:\t859\t0.1178\n",
      "k=75:\t1264\t0.1734\n",
      "k=10:\t2266\t0.3108\n",
      "expensive:\t0\t0.0000\n",
      "\n",
      "== Alpha: 10 ==\n",
      "k=25:\t421\t0.0491\n",
      "k=100:\t3361\t0.3918\n",
      "cheaper:\t13873\t0.6179\n",
      "match:\t8578\t0.3821\n",
      "k=50:\t990\t0.1154\n",
      "k=75:\t1540\t0.1795\n",
      "k=10:\t2266\t0.2642\n",
      "expensive:\t0\t0.0000\n",
      "\n",
      "== Alpha: 100 ==\n",
      "k=25:\t574\t0.0436\n",
      "k=100:\t6064\t0.4603\n",
      "cheaper:\t9278\t0.4133\n",
      "match:\t13173\t0.5867\n",
      "k=50:\t1656\t0.1257\n",
      "k=75:\t2613\t0.1984\n",
      "k=10:\t2266\t0.1720\n",
      "expensive:\t0\t0.0000\n",
      "\n",
      "== Alpha: 200 ==\n",
      "k=25:\t748\t0.0515\n",
      "k=100:\t6782\t0.4668\n",
      "cheaper:\t7922\t0.3529\n",
      "match:\t14529\t0.6471\n",
      "k=50:\t1858\t0.1279\n",
      "k=75:\t2875\t0.1979\n",
      "k=10:\t2266\t0.1560\n",
      "expensive:\t0\t0.0000\n",
      "\n",
      "== Alpha: 1000 ==\n",
      "k=25:\t1085\t0.0623\n",
      "k=100:\t8353\t0.4798\n",
      "cheaper:\t5043\t0.2246\n",
      "match:\t17408\t0.7754\n",
      "k=50:\t2088\t0.1199\n",
      "k=75:\t3616\t0.2077\n",
      "k=10:\t2266\t0.1302\n",
      "expensive:\t0\t0.0000\n",
      "\n",
      "== Alpha: 1300 ==\n",
      "k=25:\t944\t0.0539\n",
      "k=100:\t8502\t0.4858\n",
      "cheaper:\t4949\t0.2204\n",
      "match:\t17502\t0.7796\n",
      "k=50:\t2101\t0.1200\n",
      "k=75:\t3689\t0.2108\n",
      "k=10:\t2266\t0.1295\n",
      "expensive:\t0\t0.0000\n",
      "\n",
      "== Alpha: 2000 ==\n",
      "k=25:\t619\t0.0385\n",
      "k=100:\t8081\t0.5029\n",
      "cheaper:\t6381\t0.2842\n",
      "match:\t16070\t0.7158\n",
      "k=50:\t1774\t0.1104\n",
      "k=75:\t3330\t0.2072\n",
      "k=10:\t2266\t0.1410\n",
      "expensive:\t0\t0.0000\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def print_stats_all(stats):\n",
    "    keys = [k for k in sorted(stats.keys(), key= lambda x: x[0][2:])]\n",
    "    for k in keys:\n",
    "            v = stats[k]\n",
    "            print \"{}:\\t{}\\t{:.4f}\".format(k,*v)\n",
    "\n",
    "            \n",
    "alphas = np.array([0,1,5,10,100,200,1000,1300,2000])\n",
    "cost_sraa= np.array([5.2, 6.5, 7.6, 9.1, 10.3])\n",
    "\n",
    "print \"Alpha \\t Count \\t Percentage\" \n",
    "\n",
    "for a in alphas:\n",
    "    print \n",
    "    st = stats_k(q_max_sel_sraa, max_alpha(q_max_sraa, a, cost_sraa))\n",
    "    print \"== Alpha: %s ==\" % a\n",
    "    print_stats_all(st)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.997\t0.6602\t0.9999\t0.926\t0.9996\t0.7188\t0.9991\t0.9424\t0.9926\t0.9912\n",
      "0.997\t0.6602\t0.9999\t0.9259\t0.9996\t0.7188\t0.9991\t0.9424\t0.9925\t0.9912\n",
      "0.997\t0.6602\t0.9999\t0.9259\t0.9996\t0.7188\t0.9991\t0.9424\t0.9925\t0.9912\n"
     ]
    }
   ],
   "source": [
    "print \"\\t\".join(\"{:.4}\".format(rr) for rr in q_max_sraa.max(axis=0)[:10])\n",
    "print \"\\t\".join(\"{:.4}\".format(q_max_sraa[rr,i]) for i,rr in enumerate(sraa_sel[:10]))\n",
    "\n",
    "print \"\\t\".join(\"{:.4}\".format(rr) for rr in q_alpha[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recounting Matches within $\\epsilon$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0=\t17408\n",
      "0.1=\t22451\n",
      "0.01=\t22451\n",
      "0.001=\t22451\n",
      "0.0001=\t21424\n",
      "1e-05=\t18609\n",
      "1e-06=\t17751\n"
     ]
    }
   ],
   "source": [
    "# Q_alpha picked by formula\n",
    "sraa_sel = max_alpha(q_max_sraa, 1000, cost_sraa)\n",
    "q_alpha = np.array([q_max_sraa[rr,i] for i,rr in enumerate(sraa_sel)])\n",
    "\n",
    "# Q_max picked by max\n",
    "max_sraa = q_max_sraa.max(axis=0)\n",
    "\n",
    "for epsilon in [0,0.1,0.01,0.001,0.0001, 0.00001, 0.000001]:\n",
    "    count = sum((q_alpha + epsilon >= max_sraa)\n",
    "    print \"%s=\\t%s\" % (epsilon, count )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "alphas = np.array([0,1,5,10,100,200,1000,2000])\n",
    "cost_sraa= np.array([5.2, 6.5, 7.6, 9.1, 10.3])\n",
    "\n",
    "def compute_counts_epsilon(q_max, cost, alphas, epsilon):\n",
    "\n",
    "    print \"Alpha \\t Count \\t Percentage\" \n",
    "\n",
    "    for a in alphas:\n",
    "        q_alpha_sel = max_alpha(q_max, a, cost)\n",
    "        print \"%s \\t\" % a,\n",
    "\n",
    "        # Q_alpha picked by formula\n",
    "        \n",
    "        q_alpha = np.array([q_max[rr,i] for i,rr in enumerate(q_alpha_sel)])\n",
    "\n",
    "        # Q_max picked by max\n",
    "        q_max_sel = q_max.max(axis=0)\n",
    "\n",
    "        match = ((q_alpha + epsilon) >= q_max_sel)\n",
    "        count = sum(match)\n",
    "        print \"%s\\t%.4f\" % (count, np.mean(match))\n",
    "\n",
    "def all_epsilons(q_max, cost, alphas, eps):\n",
    "\n",
    "    for e in eps:\n",
    "        print \n",
    "        print \"Epsilon=%s\" % e\n",
    "        compute_counts_epsilon(q_max, cost, alphas, e)\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== IMDB ==\n",
      "Alpha \t Count \t Percentage\n",
      "0 \t760\t0.0341\n",
      "1 \t1021\t0.0459\n",
      "5 \t13225\t0.5939\n",
      "10 \t18094\t0.8126\n",
      "100 \t22267\t1.0000\n",
      "200 \t22267\t1.0000\n",
      "1000 \t22267\t1.0000\n",
      "2000 \t20112\t0.9032\n",
      "== SRAA ==\n",
      "Alpha \t Count \t Percentage\n",
      "0 \t6475\t0.2884\n",
      "1 \t8878\t0.3954\n",
      "5 \t15823\t0.7048\n",
      "10 \t18138\t0.8079\n",
      "100 \t22451\t1.0000\n",
      "200 \t22451\t1.0000\n",
      "1000 \t22451\t1.0000\n",
      "2000 \t21193\t0.9440\n"
     ]
    }
   ],
   "source": [
    "print \"== IMDB ==\"\n",
    "compute_counts_epsilon(q_max, cost, alphas, 0.01)\n",
    "\n",
    "print \"== SRAA ==\"\n",
    "compute_counts_epsilon(q_max_sraa, cost_sraa, alphas, 0.01)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== IMDB ==\n",
      "\n",
      "Epsilon=0.0\n",
      "Alpha \t Count \t Percentage\n",
      "0 \t623\t0.0280\n",
      "1 \t849\t0.0381\n",
      "5 \t11881\t0.5336\n",
      "10 \t16543\t0.7429\n",
      "25 \t19757\t0.8873\n",
      "50 \t20922\t0.9396\n",
      "75 \t21354\t0.9590\n",
      "100 \t21593\t0.9697\n",
      "1000 \t22176\t0.9959\n",
      "2000 \t19992\t0.8978\n",
      "\n",
      "Epsilon=0.001\n",
      "Alpha \t Count \t Percentage\n",
      "0 \t643\t0.0289\n",
      "1 \t872\t0.0392\n",
      "5 \t12019\t0.5398\n",
      "10 \t16747\t0.7521\n",
      "25 \t20051\t0.9005\n",
      "50 \t21267\t0.9551\n",
      "75 \t21672\t0.9733\n",
      "100 \t21879\t0.9826\n",
      "1000 \t22267\t1.0000\n",
      "2000 \t20044\t0.9002\n",
      "\n",
      "Epsilon=0.01\n",
      "Alpha \t Count \t Percentage\n",
      "0 \t760\t0.0341\n",
      "1 \t1021\t0.0459\n",
      "5 \t13225\t0.5939\n",
      "10 \t18094\t0.8126\n",
      "25 \t21379\t0.9601\n",
      "50 \t22196\t0.9968\n",
      "75 \t22264\t0.9999\n",
      "100 \t22267\t1.0000\n",
      "1000 \t22267\t1.0000\n",
      "2000 \t20112\t0.9032\n",
      "\n",
      "Epsilon=0.05\n",
      "Alpha \t Count \t Percentage\n",
      "0 \t1670\t0.0750\n",
      "1 \t2199\t0.0988\n",
      "5 \t17684\t0.7942\n",
      "10 \t21727\t0.9757\n",
      "25 \t22267\t1.0000\n",
      "50 \t22267\t1.0000\n",
      "75 \t22267\t1.0000\n",
      "100 \t22267\t1.0000\n",
      "1000 \t22267\t1.0000\n",
      "2000 \t20568\t0.9237\n",
      "\n",
      "Epsilon=0.1\n",
      "Alpha \t Count \t Percentage\n",
      "0 \t3591\t0.1613\n",
      "1 \t4528\t0.2034\n",
      "5 \t20998\t0.9430\n",
      "10 \t22267\t1.0000\n",
      "25 \t22267\t1.0000\n",
      "50 \t22267\t1.0000\n",
      "75 \t22267\t1.0000\n",
      "100 \t22267\t1.0000\n",
      "1000 \t22267\t1.0000\n",
      "2000 \t21354\t0.9590\n"
     ]
    }
   ],
   "source": [
    "print \"== IMDB ==\"\n",
    "alphas = np.array([0,1,5,10,25,50,75,100,1000,2000])\n",
    "all_epsilons(q_max, cost, alphas, [0., 0.001, 0.01, 0.05, 0.1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== SRAA ==\n",
      "\n",
      "Epsilon=0\n",
      "Alpha \t Count \t Percentage\n",
      "0 \t2266\t0.1009\n",
      "1 \t2983\t0.1329\n",
      "5 \t7290\t0.3247\n",
      "10 \t8578\t0.3821\n",
      "25 \t10413\t0.4638\n",
      "50 \t11998\t0.5344\n",
      "75 \t12674\t0.5645\n",
      "100 \t13173\t0.5867\n",
      "1000 \t17408\t0.7754\n",
      "2000 \t16070\t0.7158\n",
      "\n",
      "Epsilon=0.001\n",
      "Alpha \t Count \t Percentage\n",
      "0 \t4453\t0.1983\n",
      "1 \t6106\t0.2720\n",
      "5 \t12043\t0.5364\n",
      "10 \t13939\t0.6209\n",
      "25 \t16780\t0.7474\n",
      "50 \t18900\t0.8418\n",
      "75 \t19838\t0.8836\n",
      "100 \t20522\t0.9141\n",
      "1000 \t22451\t1.0000\n",
      "2000 \t20689\t0.9215\n",
      "\n",
      "Epsilon=0.01\n",
      "Alpha \t Count \t Percentage\n",
      "0 \t6475\t0.2884\n",
      "1 \t8878\t0.3954\n",
      "5 \t15823\t0.7048\n",
      "10 \t18138\t0.8079\n",
      "25 \t21186\t0.9437\n",
      "50 \t22397\t0.9976\n",
      "75 \t22451\t1.0000\n",
      "100 \t22451\t1.0000\n",
      "1000 \t22451\t1.0000\n",
      "2000 \t21193\t0.9440\n",
      "\n",
      "Epsilon=0.05\n",
      "Alpha \t Count \t Percentage\n",
      "0 \t10571\t0.4708\n",
      "1 \t13947\t0.6212\n",
      "5 \t21531\t0.9590\n",
      "10 \t22370\t0.9964\n",
      "25 \t22451\t1.0000\n",
      "50 \t22451\t1.0000\n",
      "75 \t22451\t1.0000\n",
      "100 \t22451\t1.0000\n",
      "1000 \t22451\t1.0000\n",
      "2000 \t21968\t0.9785\n",
      "\n",
      "Epsilon=0.1\n",
      "Alpha \t Count \t Percentage\n",
      "0 \t11846\t0.5276\n",
      "1 \t15968\t0.7112\n",
      "5 \t22350\t0.9955\n",
      "10 \t22451\t1.0000\n",
      "25 \t22451\t1.0000\n",
      "50 \t22451\t1.0000\n",
      "75 \t22451\t1.0000\n",
      "100 \t22451\t1.0000\n",
      "1000 \t22451\t1.0000\n",
      "2000 \t22348\t0.9954\n"
     ]
    }
   ],
   "source": [
    "print \"== SRAA ==\"\n",
    "\n",
    "all_epsilons(q_max_sraa, cost_sraa, alphas, [0, 0.001, 0.01, 0.05, 0.1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
