{
 "metadata": {
  "name": "",
  "signature": "sha256:8fa811daf36e1c75baa384434beda51f2148e7f7213759b04b56836c6eacdfb9"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# Structured Reading: User Studies\n",
      "\n",
      "## This Notebook\n",
      "\n",
      "The objective is to prepare the users studies data and test some configurations\n",
      "\n",
      "## Test Configuration\n",
      "\n",
      "* Set experiment\n",
      "* Load data\n",
      "* Select documents\n",
      "* Select snippets\n",
      "* Save data in a file"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "## Imports \n",
      "%matplotlib inline\n",
      "\n",
      "STRUCTURED = '/Users/maru/MyCode/structured'\n",
      "IMDB_DATA='/Users/maru/MyCode/data/imdb'\n",
      "SRAA_DATA='/Users/maru/MyCode/data/imdb'\n",
      "TWIITER_DATA = ''\n",
      "\n",
      "STRUCTURED = '../structured'\n",
      "IMDB_DATA = 'C:/Users/mramire8/Documents/Research/Oracle confidence and Interruption/dataset/aclImdb/raw-data'\n",
      "SRAA_DATA = 'C:/Users/mramire8/Documents/Research/Oracle confidence and Interruption/dataset/sraa/sraa/sraa/partition1/data'\n",
      "\n",
      "# STRUCTURED = '/Users/maru/My Code/structured'\n",
      "# IMDB_DATA='/Users/maru/Dataset/aclImdb'\n",
      "# SRAA_DATA='/Users/maru/Dataset/aviation/data'\n",
      "# TWIITER_DATA = '/Users/maru/Dataset/twitter'\n",
      "\n",
      "import sys\n",
      "import os\n",
      "sys.path.append(os.path.abspath(STRUCTURED))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 2
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import utilities.experimentutils as exputil\n",
      "import utilities.datautils as datautil\n",
      "import numpy as np\n",
      "import nltk\n",
      "from sklearn import metrics\n",
      "import matplotlib.pyplot as plt\n",
      "import matplotlib as mpl\n",
      "\n",
      "mpl.style.use('bmh')\n",
      "\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 3
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Loading Data\n",
      "vct = exputil.get_vectorizer({'vectorizer':\"tfidf\", 'limit':None, 'min_size':None})\n",
      "# Sentence tokenizers\n",
      "sent_tk = nltk.data.load('tokenizers/punkt/english.pickle')\n",
      "\n",
      "def load_data(dataname, path):\n",
      "    import pickle\n",
      "\n",
      "    DATA_PKL = path + '/data.pkl'\n",
      "\n",
      "    if os.path.isfile(DATA_PKL):\n",
      "        vct, data = pickle.load(open(DATA_PKL, 'rb'))\n",
      "    else:\n",
      "        vct = exputil.get_vectorizer({'vectorizer':\"tfidf\", 'limit':None, 'min_size':None})\n",
      "        data = datautil.load_dataset(dataname, path, categories=None, rnd=5463, shuffle=True)\n",
      "        data.train.data = np.array(data.train.data, dtype=object)\n",
      "        data.test.data = np.array(data.test.data, dtype=object)\n",
      "        data.train.bow = vct.fit_transform(data.train.data)\n",
      "        data.test.bow = vct.transform(data.test.data)\n",
      "        pickle.dump((vct, data), open(DATA_PKL, 'wb'))\n",
      "\n",
      "    return data, vct\n",
      "\n",
      "\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 4
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Get the sentences for testing\n",
      "def _sentences(docs, doc_labels, sent_tk):\n",
      "    data = []\n",
      "    true_labels = []\n",
      "    sent = sent_tk.tokenize_sents(docs)\n",
      "    for sentences, doc_label in zip(sent, doc_labels):\n",
      "        data.extend(sentences)\n",
      "        true_labels.extend([doc_label] * len(sentences))\n",
      "    return data, np.array(true_labels)\n",
      "\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 5
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# select random snippets\n",
      "def select_random_snippets(data, rnd, sent_tk, n=1000):\n",
      "    rnd_docs = rnd.permutation(len(data.target))\n",
      "    docs_text = data.data[rnd_docs[:n]]\n",
      "    docs_lbl  = data.target[rnd_docs[:n]]\n",
      "    docs_sent = sent_tk.tokenize_sents(docs_text)\n",
      "    # docs_sents = _sentences(cost_text, docs_lbl, sent_tk)\n",
      "    rnd_st = np.random.RandomState(543210)\n",
      "    selected = []\n",
      "    for lbl, sents in zip(docs_lbl, docs_sent):\n",
      "        if len(sents) > 1:\n",
      "            picked = np.random.random_integers(len(sents)-1)\n",
      "        else:\n",
      "            picked = 0\n",
      "        selected.append(sents[picked])\n",
      "    return docs_text, docs_lbl, selected    \n",
      "\n",
      "# print snippets into a file\n",
      "def output_test(name, doc, lbl, snip):\n",
      "    file_name = \"./output/rnd_\" + name + \".txt\"\n",
      "    if not os.path.exists(\"./output/\"):\n",
      "        os.makedirs(\"./output\")\n",
      "    f = open(file_name, \"w\")\n",
      "    f.write(\"LABEL\\tSENT\\tDOC\\n\")\n",
      "    for a, b, c in zip(lbl, snip, doc):\n",
      "#         print \"{}\\t{}\\t{}\\n\".format(a, b, c)\n",
      "        f.write(\"{}\\t{}\\t{}\\n\".format(a, b.encode('utf-8'), c.encode('utf-8').replace(\"\\n\",\". \")))\n",
      "    f.close()\n",
      "    "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 6
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# Create User Study Samples\n",
      "\n",
      "For all dataset we :\n",
      "\n",
      "* Load data\n",
      "* Sample 1k documents\n",
      "* Sample a random snippet per document\n",
      "* Save selected documents into a file"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Load the dataset\n",
      "imdb, vct = load_data('imdb', IMDB_DATA)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# get testing files for IMDB\n",
      "rnd = np.random.RandomState(2345)\n",
      "# Get the sampled snippets\n",
      "docs, lbl, snip = select_random_snippets(imdb.train, rnd, sent_tk, n=1000)\n",
      "output_test(\"imdb\", docs,lbl, snip)\n",
      "\n",
      "\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 42
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "\"this is a sentence.\\n This is the other sentence.\".replace(\"\\n\", \". \")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 35,
       "text": [
        "'this is a sentence..  This is the other sentence.'"
       ]
      }
     ],
     "prompt_number": 35
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Load the dataset\n",
      "rnd = np.random.RandomState(2345)\n",
      "sraa, vct = load_data('sraa', SRAA_DATA)\n",
      "docs, lbl, snip = select_random_snippets(sraa.train, rnd, sent_tk, n=1000)\n",
      "output_test(\"sraa\", docs,lbl, snip)\n",
      "\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 7
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Load the dataset\n",
      "twitter, vct = load_data('twitter', SRAA_DATA)\n",
      "tw_tk = exputil.get_tokenizer('tweets')\n",
      "docs, lbl, snip = select_random_snippets(twitter.train, rnd, tw_tk, n=1000)\n",
      "output_test(\"twitter\", docs,lbl, snip)\n",
      "\n",
      "\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 39
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# User Labeled Data"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Testing Models on User Study Data: IMDB\n",
      "\n",
      "* Load documents\n",
      "* Train expert\n",
      "* Test expert on documents\n",
      "\n",
      "We train the expert on the test split so it does not see the snippets used for the study. The models are L1 and L2 with various values of C penalty. \n",
      "\n",
      "Threshold for neutral values is set manually. We tested T=.4 and .35"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def load_study(filename):\n",
      "    f = open(filename)\n",
      "    with f:\n",
      "        lines = f.readlines() \n",
      "    data =  [l.strip().split(\"\\t\") for l in lines[1:]] #discard first line\n",
      "    data = np.array(data, dtype=object)\n",
      "    return data\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 43
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "imdb, vct = load_data('imdb', IMDB_DATA)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 45
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Get the snippets from the saved file\n",
      "docs_study = load_study('./output/rnd_imdb.txt')\n",
      "lbl = [float(d[0]) for d in docs_study]\n",
      "snippets = [d[1] for d in docs_study]\n",
      "snip_bow = vct.transform(snippets)\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 57
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#Get Human oracle labels\n",
      "f = open(\"./output/user1_rnd_imdb_labels.txt\")\n",
      "user_labels = np.loadtxt(f)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 81
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "## Get the expert data and snippets\n",
      "exp_sent, exp_lbl = _sentences(imdb.test.data, imdb.test.target, sent_tk)\n",
      "exp_sent_bow = vct.transform(exp_sent)\n",
      "print \"Sentences:\", len(exp_sent), len(exp_lbl)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Sentences: 265781 265781\n"
       ]
      }
     ],
     "prompt_number": 60
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from collections import defaultdict\n",
      "\n",
      "def neutral_label(threshold, p, lbl):\n",
      "    ''' Labels are $\\{0, 1, 2\\}$ where 2 is neutral ''' \n",
      "    return lbl if (1 - p.max()) < threshold else 2\n",
      "\n",
      "def test_parameters(clf_str, C, data, threshold, name=\"noname\"):\n",
      "    # print predicted values of the expert on the study snippets\n",
      "    print \"Parameters for %s and T > %s\" %(clf_str, threshold)\n",
      "    results = defaultdict(lambda: [])\n",
      "    for c in C: \n",
      "        print \"Testing ... C=\", c\n",
      "#         expert = exputil.get_classifier('lrl2', parameter=c)\n",
      "        expert = eval(clf_str.format(c))\n",
      "        expert.fit(data['bow'], data['target'])\n",
      "        pred = expert.predict(snip_bow)\n",
      "        prob = expert.predict_proba(snip_bow)\n",
      "        results[c] = [neutral_label(threshold, p, t) for t, p in zip(pred,prob)]\n",
      "    return results\n",
      "\n",
      "def print_results(results, C, name=\"noname\"):\n",
      "    print \"\\t\".join(\"{}-C={}\".format(name, k) for k in results.keys())\n",
      "    for i in range(len(results[C[0]])):\n",
      "        print \"\\t\".join(\"{}\".format(results[c][i]) for c in C)\n",
      "\n",
      "        \n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 215
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "## See test predictions \n",
      "print_results(results, C)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "noname-C=1\tnoname-C=10\tnoname-C=100\tnoname-C=0.1\tnoname-C=0.01\n",
        "2\t2\t0\t0\t2\n",
        "2\t2\t2\t2\t2\n",
        "0\t0\t0\t0\t0\n",
        "2\t0\t0\t0\t0\n",
        "2\t2\t1\t1\t1\n",
        "2\t1\t1\t1\t1\n",
        "1\t1\t1\t1\t1\n",
        "2\t2\t1\t1\t1\n",
        "2\t1\t1\t2\t2\n",
        "2\t2\t0\t0\t0\n",
        "0\t0\t0\t0\t0\n",
        "0\t0\t0\t0\t0\n",
        "2\t2\t0\t0\t0\n",
        "2\t2\t2\t2\t2\n",
        "2\t2\t1\t1\t1\n",
        "1\t1\t1\t1\t1\n",
        "2\t1\t2\t0\t0\n",
        "2\t2\t2\t2\t2\n",
        "2\t2\t2\t2\t2\n",
        "2\t0\t0\t0\t0\n",
        "0\t0\t0\t0\t0\n",
        "2\t1\t1\t1\t1\n",
        "0\t0\t0\t0\t0\n",
        "0\t0\t0\t0\t0\n",
        "1\t1\t1\t1\t1\n",
        "2\t2\t1\t1\t2\n",
        "2\t2\t2\t1\t1\n",
        "0\t0\t0\t0\t0\n",
        "2\t1\t1\t1\t1\n",
        "2\t2\t2\t1\t1\n",
        "2\t0\t0\t0\t0\n",
        "2\t2\t2\t2\t2\n",
        "2\t0\t0\t0\t0\n",
        "2\t1\t1\t0\t0\n",
        "0\t0\t0\t0\t0\n",
        "2\t2\t2\t0\t0\n",
        "1\t1\t1\t1\t1\n",
        "2\t2\t1\t1\t1\n",
        "2\t0\t0\t0\t0\n",
        "0\t0\t0\t0\t0\n",
        "1\t1\t1\t1\t1\n",
        "2\t2\t0\t0\t0\n",
        "2\t1\t1\t1\t1\n",
        "2\t1\t1\t2\t2\n",
        "2\t2\t2\t0\t0\n",
        "2\t0\t0\t0\t0\n",
        "1\t1\t1\t1\t1\n",
        "2\t2\t1\t1\t1\n",
        "2\t0\t0\t0\t0\n",
        "2\t2\t2\t2\t2\n",
        "2\t2\t0\t2\t1\n",
        "2\t2\t2\t2\t1\n",
        "2\t1\t1\t1\t1\n",
        "2\t1\t1\t1\t1\n",
        "2\t2\t2\t2\t0\n",
        "0\t0\t0\t0\t0\n",
        "2\t2\t2\t2\t0\n",
        "2\t0\t2\t1\t1\n",
        "2\t1\t1\t1\t1\n",
        "2\t2\t2\t2\t2\n",
        "2\t2\t2\t2\t2\n",
        "2\t2\t1\t1\t1\n",
        "2\t0\t0\t0\t0\n",
        "2\t1\t1\t1\t1\n",
        "2\t1\t1\t1\t1\n",
        "2\t2\t0\t0\t0\n",
        "0\t0\t0\t0\t0\n",
        "2\t0\t0\t0\t0\n",
        "2\t1\t1\t1\t1\n",
        "2\t2\t2\t2\t2\n",
        "2\t1\t1\t1\t1\n",
        "2\t0\t0\t0\t0\n",
        "2\t1\t1\t1\t1\n",
        "0\t0\t0\t0\t0\n",
        "2\t2\t2\t0\t0\n",
        "2\t1\t1\t1\t1\n",
        "0\t0\t0\t1\t1\n",
        "2\t2\t0\t0\t0\n",
        "2\t2\t2\t2\t2\n",
        "2\t2\t2\t2\t2\n",
        "2\t2\t1\t1\t1\n",
        "2\t2\t2\t2\t1\n",
        "1\t1\t1\t1\t1\n",
        "2\t2\t1\t1\t1\n",
        "2\t2\t2\t2\t2\n",
        "2\t2\t0\t0\t0\n",
        "0\t0\t0\t0\t0\n",
        "0\t0\t0\t0\t0\n",
        "2\t0\t0\t0\t0\n",
        "2\t2\t1\t1\t1\n",
        "0\t0\t0\t0\t0\n",
        "0\t0\t0\t0\t0\n",
        "2\t2\t2\t2\t0\n",
        "1\t1\t1\t1\t2\n",
        "2\t1\t1\t1\t1\n",
        "2\t1\t2\t2\t2\n",
        "0\t0\t0\t0\t0\n",
        "2\t2\t2\t1\t1\n",
        "2\t2\t1\t1\t1\n",
        "2\t2\t2\t2\t1\n",
        "0\t0\t0\t0\t0\n",
        "2\t0\t0\t0\t0\n",
        "2\t0\t2\t1\t1\n",
        "2\t2\t1\t1\t1\n",
        "1\t1\t1\t1\t1\n",
        "2\t0\t0\t0\t0\n",
        "2\t0\t0\t0\t0\n",
        "1\t1\t1\t1\t1\n",
        "2\t2\t1\t1\t1\n",
        "1\t1\t1\t1\t1\n",
        "2\t0\t0\t0\t0\n",
        "0\t0\t0\t0\t0\n",
        "2\t2\t2\t2\t2\n",
        "2\t0\t2\t1\t1\n",
        "0\t0\t0\t0\t0\n",
        "2\t1\t1\t1\t1\n",
        "2\t2\t2\t2\t2\n",
        "2\t0\t0\t0\t0\n",
        "2\t1\t1\t1\t1\n",
        "2\t0\t2\t1\t1\n",
        "2\t1\t1\t1\t1\n",
        "1\t1\t1\t1\t1\n",
        "2\t2\t0\t0\t0\n",
        "2\t2\t2\t2\t0\n",
        "0\t0\t0\t0\t0\n",
        "1\t1\t1\t1\t1\n",
        "2\t2\t2\t2\t2\n",
        "2\t2\t2\t1\t1\n",
        "2\t2\t0\t0\t0\n",
        "0\t0\t0\t0\t0\n",
        "2\t1\t1\t1\t1\n",
        "2\t2\t2\t2\t2\n",
        "2\t2\t2\t0\t0\n",
        "2\t0\t0\t0\t0\n",
        "2\t2\t2\t0\t0\n",
        "2\t1\t1\t1\t1\n",
        "0\t0\t0\t0\t0\n",
        "1\t1\t1\t1\t1\n",
        "2\t2\t0\t2\t1\n",
        "2\t1\t1\t1\t1\n",
        "2\t1\t1\t1\t1\n",
        "2\t2\t2\t2\t0\n",
        "2\t1\t1\t1\t1\n",
        "2\t1\t1\t2\t0\n",
        "2\t2\t2\t0\t0\n",
        "2\t1\t1\t1\t1\n",
        "2\t1\t1\t2\t0\n",
        "2\t2\t2\t2\t2\n",
        "2\t0\t0\t0\t0\n",
        "2\t0\t0\t1\t1\n",
        "2\t2\t2\t2\t2\n",
        "2\t2\t2\t2\t2\n",
        "0\t0\t0\t2\t1\n",
        "0\t0\t0\t0\t0\n",
        "2\t0\t0\t0\t2\n",
        "2\t0\t0\t0\t0\n",
        "2\t0\t0\t0\t0\n",
        "2\t0\t0\t0\t0\n",
        "2\t2\t2\t1\t1\n",
        "2\t2\t0\t0\t0\n",
        "2\t2\t2\t0\t0\n",
        "2\t0\t0\t0\t0\n",
        "2\t2\t2\t2\t2\n",
        "0\t0\t0\t0\t0\n",
        "0\t0\t0\t0\t0\n",
        "2\t2\t0\t0\t0\n",
        "2\t2\t2\t2\t0\n",
        "1\t1\t1\t1\t1\n",
        "0\t0\t0\t0\t0\n",
        "1\t1\t1\t1\t1\n",
        "2\t2\t2\t2\t2\n",
        "2\t2\t1\t1\t1\n",
        "2\t1\t1\t1\t1\n",
        "2\t0\t0\t0\t0\n",
        "2\t0\t0\t0\t0\n",
        "2\t2\t2\t2\t2\n",
        "2\t1\t1\t1\t1\n",
        "2\t1\t1\t1\t1\n",
        "2\t1\t1\t1\t1\n",
        "2\t1\t1\t1\t1\n",
        "2\t2\t0\t0\t0\n",
        "2\t1\t1\t1\t1\n",
        "2\t2\t2\t2\t2\n",
        "2\t0\t0\t0\t0\n",
        "2\t1\t1\t1\t1\n",
        "1\t1\t1\t1\t1\n",
        "2\t1\t1\t1\t1\n",
        "2\t2\t0\t0\t0\n",
        "2\t0\t2\t1\t1\n",
        "2\t2\t2\t2\t0\n",
        "2\t0\t0\t2\t2\n",
        "2\t2\t1\t1\t1\n",
        "2\t1\t1\t1\t1\n",
        "1\t1\t1\t1\t1\n",
        "2\t0\t0\t0\t0\n",
        "2\t1\t1\t1\t1\n",
        "2\t2\t0\t0\t0\n",
        "2\t0\t0\t0\t0\n",
        "2\t1\t1\t0\t0\n",
        "2\t2\t1\t1\t1\n",
        "2\t0\t0\t0\t0\n",
        "2\t2\t2\t2\t2\n",
        "2\t1\t1\t1\t1\n",
        "2\t2\t0\t0\t0\n",
        "2\t2\t2\t2\t0\n",
        "2\t2\t1\t1\t1\n",
        "2\t0\t0\t0\t0\n",
        "2\t2\t0\t0\t0\n",
        "0\t0\t0\t0\t0\n",
        "2\t2\t2\t1\t1\n",
        "2\t0\t2\t2\t1\n",
        "2\t0\t0\t0\t0\n",
        "2\t0\t0\t0\t0\n",
        "2\t2\t2\t2\t2\n",
        "2\t2\t2\t2\t1\n",
        "1\t1\t1\t1\t1\n",
        "2\t1\t1\t2\t2\n",
        "2\t1\t1\t2\t0\n",
        "2\t2\t0\t0\t0\n",
        "0\t0\t2\t2\t2\n",
        "2\t2\t1\t1\t1\n",
        "2\t1\t1\t1\t1\n",
        "2\t1\t2\t2\t2\n",
        "2\t0\t0\t0\t0\n",
        "2\t1\t1\t1\t1\n",
        "2\t2\t0\t0\t0\n",
        "2\t2\t2\t2\t1\n",
        "2\t2\t0\t0\t0\n",
        "2\t1\t1\t1\t1\n",
        "2\t2\t1\t1\t1\n",
        "2\t1\t1\t1\t1\n",
        "2\t2\t2\t2\t2\n",
        "2\t2\t2\t0\t0\n",
        "0\t0\t0\t2\t2\n",
        "2\t2\t2\t2\t2\n",
        "2\t1\t1\t1\t1\n",
        "2\t1\t1\t1\t1\n",
        "2\t2\t2\t1\t1\n",
        "2\t0\t0\t0\t0\n",
        "0\t0\t0\t0\t0\n",
        "0\t0\t0\t0\t0\n",
        "2\t2\t2\t2\t2\n",
        "2\t2\t2\t1\t1\n",
        "2\t2\t2\t2\t2\n",
        "2\t0\t0\t0\t0\n",
        "2\t2\t2\t1\t1\n",
        "2\t1\t2\t2\t2\n",
        "2\t0\t0\t0\t0\n",
        "0\t0\t0\t0\t0\n",
        "0\t0\t0\t0\t0\n",
        "0\t0\t0\t0\t0\n",
        "2\t2\t2\t2\t2\n",
        "0\t0\t0\t0\t0\n",
        "2\t2\t2\t2\t1\n",
        "2\t2\t0\t0\t0\n",
        "2\t2\t0\t2\t1\n",
        "2\t0\t0\t0\t0\n",
        "2\t2\t0\t0\t0\n",
        "1\t1\t1\t1\t1\n",
        "0\t0\t0\t2\t2\n",
        "2\t2\t1\t2\t2\n",
        "2\t1\t1\t1\t1\n",
        "0\t0\t0\t0\t0\n",
        "2\t1\t1\t1\t1\n",
        "2\t2\t2\t2\t0\n",
        "2\t1\t1\t1\t1\n",
        "2\t2\t1\t1\t0\n",
        "2\t1\t1\t1\t1\n",
        "2\t0\t0\t2\t2\n",
        "2\t2\t2\t2\t1\n",
        "0\t0\t0\t0\t0\n",
        "2\t2\t0\t0\t0\n",
        "2\t0\t0\t0\t0\n",
        "2\t0\t0\t0\t0\n",
        "2\t0\t0\t0\t0\n",
        "1\t1\t1\t1\t1\n",
        "2\t2\t2\t2\t2\n",
        "2\t0\t0\t0\t0\n",
        "2\t2\t2\t0\t0\n",
        "2\t1\t1\t1\t1\n",
        "0\t0\t0\t0\t0\n",
        "0\t0\t0\t0\t0\n",
        "2\t1\t1\t1\t1\n",
        "2\t2\t2\t2\t2\n",
        "2\t0\t0\t0\t2\n",
        "2\t1\t1\t1\t1\n",
        "0\t0\t0\t0\t0\n",
        "2\t2\t0\t0\t0\n",
        "2\t1\t1\t1\t1\n",
        "2\t0\t0\t0\t0\n",
        "2\t1\t1\t1\t1\n",
        "2\t2\t0\t0\t0\n",
        "0\t0\t0\t0\t0\n",
        "2\t0\t0\t0\t0\n",
        "2\t2\t2\t2\t2\n",
        "0\t0\t2\t2\t2\n",
        "0\t0\t0\t0\t0\n",
        "1\t1\t1\t1\t1\n",
        "2\t1\t1\t1\t1\n",
        "2\t2\t1\t1\t1\n",
        "0\t0\t0\t0\t0\n",
        "2\t2\t1\t1\t1\n",
        "2\t2\t2\t2\t0\n",
        "2\t2\t2\t0\t0\n",
        "2\t1\t1\t2\t2\n",
        "2\t2\t1\t1\t1\n",
        "0\t0\t0\t0\t0\n",
        "2\t1\t2\t0\t0\n",
        "0\t0\t0\t0\t0\n",
        "2\t2\t2\t2\t2\n",
        "2\t1\t1\t1\t2\n",
        "2\t0\t0\t2\t2\n",
        "1\t1\t1\t1\t1\n",
        "2\t2\t2\t2\t2\n",
        "2\t1\t1\t1\t1\n",
        "0\t0\t0\t0\t0\n",
        "2\t2\t2\t2\t0\n",
        "2\t1\t1\t1\t1\n",
        "2\t2\t1\t1\t1\n",
        "1\t1\t1\t1\t1\n",
        "2\t0\t0\t0\t0\n",
        "0\t0\t2\t2\t2\n",
        "2\t1\t1\t1\t1\n",
        "2\t2\t2\t2\t2\n",
        "2\t2\t2\t2\t1\n",
        "2\t0\t0\t0\t0\n",
        "2\t2\t2\t2\t2\n",
        "1\t1\t1\t2\t2\n",
        "1\t1\t1\t1\t1\n",
        "0\t0\t0\t0\t0\n",
        "2\t2\t2\t2\t0\n",
        "0\t0\t0\t0\t0\n",
        "2\t2\t2\t2\t2\n",
        "2\t2\t0\t0\t0\n",
        "2\t0\t0\t0\t0\n",
        "1\t1\t1\t1\t1\n",
        "2\t0\t0\t2\t2\n",
        "1\t1\t1\t1\t1\n",
        "2\t0\t0\t2\t2\n",
        "2\t1\t1\t1\t1\n",
        "2\t1\t1\t1\t1\n",
        "2\t1\t1\t1\t1\n",
        "2\t2\t0\t2\t1\n",
        "2\t2\t0\t2\t2\n",
        "2\t1\t1\t1\t1\n",
        "0\t0\t0\t0\t0\n",
        "2\t2\t2\t1\t1\n",
        "1\t1\t1\t1\t1\n",
        "2\t2\t0\t0\t0\n",
        "2\t0\t0\t0\t0\n",
        "2\t1\t1\t1\t1\n",
        "0\t0\t0\t2\t2\n",
        "2\t0\t0\t0\t0\n",
        "2\t2\t2\t2\t2\n",
        "2\t0\t0\t0\t0\n",
        "0\t0\t0\t0\t0\n",
        "0\t0\t0\t0\t0\n",
        "2\t0\t0\t0\t0\n",
        "2\t2\t1\t1\t2\n",
        "0\t0\t0\t0\t0\n",
        "2\t2\t0\t0\t0\n",
        "2\t2\t1\t1\t1\n",
        "0\t0\t0\t0\t0\n",
        "2\t2\t0\t2\t2\n",
        "2\t0\t0\t0\t0\n",
        "2\t2\t2\t0\t0\n",
        "2\t2\t2\t0\t0\n",
        "2\t1\t1\t1\t1\n",
        "2\t0\t0\t0\t0\n",
        "1\t1\t1\t1\t1\n",
        "2\t2\t2\t2\t2\n",
        "0\t0\t0\t0\t0\n",
        "2\t1\t1\t2\t0\n",
        "0\t0\t0\t0\t0\n",
        "2\t1\t1\t1\t1\n",
        "2\t1\t1\t1\t1\n",
        "2\t0\t0\t0\t0\n",
        "2\t0\t0\t2\t2\n",
        "0\t0\t0\t0\t0\n",
        "0\t0\t0\t0\t0\n",
        "1\t1\t1\t1\t1\n",
        "2\t0\t2\t2\t2\n",
        "2\t1\t1\t1\t1\n",
        "2\t2\t1\t1\t1\n",
        "2\t1\t1\t1\t1\n",
        "2\t2\t2\t2\t2\n",
        "2\t0\t0\t0\t0\n",
        "2\t2\t2\t2\t2\n",
        "2\t2\t1\t1\t1\n",
        "1\t1\t1\t1\t1\n",
        "2\t2\t2\t0\t0\n",
        "2\t2\t2\t1\t1\n",
        "2\t1\t1\t1\t1\n",
        "2\t0\t0\t0\t0\n",
        "2\t2\t0\t0\t0\n",
        "2\t2\t2\t2\t2\n",
        "2\t2\t2\t2\t0\n",
        "0\t0\t0\t0\t0\n",
        "2\t0\t0\t0\t0\n",
        "2\t0\t0\t0\t0\n",
        "0\t0\t0\t0\t0\n",
        "2\t0\t0\t0\t0\n",
        "1\t1\t1\t1\t1\n",
        "2\t1\t1\t1\t1\n",
        "2\t0\t0\t0\t0\n",
        "2\t1\t1\t1\t1\n",
        "0\t0\t0\t0\t0\n",
        "2\t1\t1\t1\t1\n",
        "0\t0\t0\t0\t0\n",
        "2\t0\t0\t1\t1\n",
        "0\t0\t0\t0\t0\n",
        "1\t1\t1\t1\t1\n",
        "0\t0\t0\t0\t0\n",
        "2\t2\t0\t0\t0\n",
        "2\t2\t2\t2\t2\n",
        "2\t2\t0\t0\t0\n",
        "1\t1\t1\t1\t1\n",
        "2\t1\t1\t2\t2\n",
        "2\t1\t1\t1\t1\n",
        "1\t1\t1\t1\t1\n",
        "2\t0\t0\t0\t0\n",
        "2\t2\t1\t1\t1\n",
        "2\t1\t1\t2\t2\n",
        "1\t1\t1\t1\t1\n",
        "0\t0\t0\t0\t0\n",
        "2\t2\t0\t0\t0\n",
        "2\t2\t2\t2\t2\n",
        "2\t1\t1\t1\t1\n",
        "2\t0\t0\t0\t0\n",
        "2\t2\t1\t1\t1\n",
        "1\t1\t1\t1\t1\n",
        "0\t0\t0\t0\t0\n",
        "2\t1\t1\t1\t1\n",
        "2\t2\t1\t1\t1\n",
        "2\t2\t2\t0\t0\n",
        "2\t2\t2\t2\t2\n",
        "2\t2\t2\t2\t2\n",
        "2\t1\t1\t1\t1\n",
        "2\t0\t0\t0\t0\n",
        "2\t2\t1\t1\t1\n",
        "2\t0\t0\t2\t2\n",
        "2\t2\t0\t0\t0\n",
        "2\t2\t2\t2\t2\n",
        "0\t0\t0\t0\t0\n",
        "2\t2\t0\t0\t0\n",
        "2\t2\t1\t1\t1\n",
        "0\t0\t0\t0\t0\n",
        "2\t1\t1\t1\t1\n",
        "0\t0\t0\t0\t0\n",
        "2\t1\t1\t1\t1\n",
        "2\t0\t0\t0\t0\n",
        "2\t2\t0\t0\t0\n",
        "0\t0\t0\t0\t0\n",
        "0\t0\t0\t0\t0\n",
        "2\t2\t2\t1\t1\n",
        "2\t2\t2\t2\t2\n",
        "2\t0\t0\t0\t0\n",
        "2\t2\t2\t2\t2\n",
        "2\t0\t0\t0\t0\n",
        "2\t2\t0\t0\t0\n",
        "1\t1\t1\t1\t1\n",
        "0\t0\t0\t0\t0\n",
        "0\t0\t0\t0\t0\n",
        "1\t1\t1\t1\t1\n",
        "2\t2\t2\t2\t2\n",
        "2\t2\t0\t0\t0\n",
        "2\t1\t2\t0\t0\n",
        "2\t2\t2\t2\t1\n",
        "2\t0\t0\t0\t0\n",
        "0\t0\t0\t0\t0\n",
        "2\t2\t2\t2\t2\n",
        "2\t1\t1\t1\t1\n",
        "1\t1\t1\t1\t1\n",
        "2\t1\t1\t1\t1\n",
        "2\t2\t2\t2\t2\n",
        "2\t2\t0\t0\t0\n",
        "2\t2\t2\t2\t1\n",
        "1\t1\t1\t1\t1\n",
        "2\t2\t1\t1\t1\n",
        "2\t1\t1\t1\t1\n",
        "1\t1\t1\t1\t1\n",
        "2\t2\t1\t1\t1\n",
        "2\t0\t0\t0\t0\n",
        "2\t2\t2\t0\t0\n",
        "2\t2\t1\t1\t1\n",
        "2\t2\t2\t2\t0\n",
        "0\t0\t0\t0\t0\n",
        "2\t2\t1\t1\t1\n",
        "2\t2\t1\t1\t1\n",
        "2\t1\t1\t1\t1\n",
        "2\t2\t0\t0\t0\n",
        "2\t1\t1\t1\t1\n",
        "2\t0\t0\t2\t2\n",
        "2\t2\t0\t0\t0\n",
        "0\t0\t0\t0\t0\n",
        "2\t1\t1\t1\t1\n",
        "2\t2\t2\t2\t0\n",
        "2\t0\t0\t0\t0\n",
        "0\t0\t0\t0\t0\n",
        "2\t0\t0\t2\t1\n",
        "2\t2\t0\t0\t0\n",
        "2\t1\t1\t1\t1\n",
        "2\t0\t0\t0\t0\n",
        "2\t2\t2\t0\t0\n",
        "1\t1\t1\t1\t1\n",
        "2\t0\t0\t0\t0\n",
        "2\t0\t0\t0\t2\n",
        "2\t1\t2\t0\t0\n",
        "2\t1\t1\t1\t1\n",
        "2\t0\t0\t0\t0\n",
        "2\t2\t2\t2\t2\n",
        "0\t0\t0\t0\t0\n",
        "2\t2\t2\t0\t0\n",
        "2\t0\t0\t0\t0\n",
        "2\t2\t2\t0\t0\n",
        "2\t1\t1\t2\t0\n",
        "2\t2\t0\t0\t2\n",
        "0\t0\t0\t0\t0\n",
        "2\t1\t1\t1\t1\n",
        "1\t1\t1\t1\t1\n",
        "2\t2\t0\t0\t0\n",
        "2\t2\t0\t0\t0\n",
        "2\t1\t1\t2\t2\n",
        "2\t2\t2\t2\t2\n",
        "2\t0\t0\t0\t0\n",
        "2\t1\t1\t1\t1\n",
        "2\t2\t2\t2\t2\n",
        "2\t2\t2\t2\t2\n",
        "2\t2\t2\t0\t0\n",
        "0\t0\t0\t0\t0\n",
        "2\t2\t2\t0\t0\n",
        "2\t0\t0\t0\t0\n",
        "2\t1\t1\t1\t1\n",
        "0\t0\t0\t0\t0\n",
        "2\t2\t2\t1\t1\n",
        "2\t2\t1\t1\t1\n",
        "2\t2\t2\t2\t2\n",
        "2\t2\t1\t1\t1\n",
        "2\t0\t0\t0\t0\n",
        "1\t1\t1\t1\t1\n",
        "0\t0\t0\t0\t0\n",
        "2\t1\t1\t1\t1\n",
        "2\t0\t0\t0\t0\n",
        "1\t1\t1\t1\t1\n",
        "0\t0\t0\t0\t0\n",
        "2\t1\t1\t1\t1\n",
        "1\t1\t1\t1\t1\n",
        "2\t2\t1\t1\t1\n",
        "2\t2\t2\t2\t2\n",
        "2\t2\t0\t0\t0\n",
        "2\t2\t2\t1\t1\n",
        "0\t0\t0\t0\t0\n",
        "2\t1\t1\t1\t1\n",
        "2\t2\t0\t0\t0\n",
        "2\t0\t0\t0\t0\n",
        "2\t2\t2\t2\t2\n",
        "1\t1\t1\t1\t1\n",
        "2\t2\t2\t2\t0\n",
        "2\t1\t1\t1\t1\n",
        "2\t2\t2\t1\t1\n",
        "2\t1\t1\t1\t1\n",
        "2\t2\t0\t0\t0\n",
        "2\t2\t2\t2\t2\n",
        "2\t2\t2\t0\t0\n",
        "2\t2\t0\t0\t0\n",
        "0\t0\t0\t0\t0\n",
        "2\t2\t2\t2\t0\n",
        "2\t2\t2\t2\t2\n",
        "2\t1\t1\t1\t1\n",
        "2\t1\t1\t1\t1\n",
        "2\t2\t2\t1\t1\n",
        "2\t1\t1\t1\t1\n",
        "2\t1\t1\t1\t1\n",
        "2\t1\t1\t1\t1\n",
        "0\t0\t0\t0\t0\n",
        "2\t2\t2\t2\t2\n",
        "2\t1\t1\t2\t0\n",
        "2\t0\t0\t0\t0\n",
        "0\t0\t0\t0\t0\n",
        "2\t2\t1\t1\t1\n",
        "0\t0\t0\t0\t0\n",
        "2\t1\t1\t1\t1\n",
        "2\t1\t1\t1\t1\n",
        "2\t0\t0\t0\t0\n",
        "2\t0\t0\t0\t0\n",
        "1\t1\t1\t1\t1\n",
        "0\t0\t0\t0\t0\n",
        "2\t0\t0\t0\t0\n",
        "0\t0\t0\t0\t0\n",
        "2\t2\t1\t2\t0\n",
        "2\t0\t0\t0\t0\n",
        "1\t1\t1\t1\t1\n",
        "2\t2\t0\t0\t0\n",
        "0\t0\t0\t0\t0\n",
        "2\t2\t2\t2\t2\n",
        "2\t0\t0\t2\t1\n",
        "0\t0\t0\t0\t0\n",
        "2\t2\t2\t1\t1\n",
        "2\t2\t0\t0\t0\n",
        "2\t2\t2\t2\t2\n",
        "2\t2\t2\t2\t2\n",
        "2\t2\t2\t2\t2\n",
        "2\t1\t1\t2\t2\n",
        "1\t1\t1\t1\t1\n",
        "2\t0\t0\t0\t0\n",
        "2\t1\t1\t1\t1\n",
        "0\t0\t0\t0\t0\n",
        "2\t1\t1\t1\t1\n",
        "2\t0\t0\t0\t0\n",
        "2\t1\t2\t2\t2\n",
        "2\t2\t2\t2\t0\n",
        "2\t2\t1\t1\t1\n",
        "2\t1\t1\t1\t1\n",
        "2\t2\t2\t2\t2\n",
        "1\t1\t1\t1\t1\n",
        "2\t2\t2\t2\t2\n",
        "2\t1\t1\t1\t1\n",
        "2\t2\t0\t0\t0\n",
        "1\t1\t1\t1\t1\n",
        "2\t1\t1\t1\t1\n",
        "2\t2\t2\t2\t2\n",
        "2\t2\t2\t2\t2\n",
        "2\t1\t1\t1\t1\n",
        "0\t0\t0\t0\t0\n",
        "2\t0\t0\t0\t0\n",
        "0\t0\t0\t0\t0\n",
        "2\t2\t0\t0\t0\n",
        "0\t0\t0\t0\t0\n",
        "2\t0\t0\t0\t0\n",
        "1\t1\t1\t1\t1\n",
        "2\t0\t0\t0\t0\n",
        "2\t0\t0\t0\t0\n",
        "2\t2\t2\t2\t2\n",
        "2\t2\t2\t1\t1\n",
        "2\t1\t2\t2\t2\n",
        "2\t0\t0\t0\t0\n",
        "2\t2\t0\t2\t2\n",
        "2\t1\t1\t1\t1\n",
        "1\t1\t1\t1\t1\n",
        "2\t0\t0\t0\t2\n",
        "2\t0\t0\t0\t0\n",
        "2\t2\t2\t2\t2\n",
        "2\t0\t0\t0\t0\n",
        "0\t0\t0\t0\t0\n",
        "2\t1\t1\t1\t2\n",
        "2\t2\t2\t2\t2\n",
        "2\t2\t1\t2\t0\n",
        "2\t2\t1\t1\t1\n",
        "2\t1\t1\t1\t1\n",
        "2\t2\t2\t2\t0\n",
        "0\t0\t0\t0\t0\n",
        "0\t0\t0\t0\t0\n",
        "0\t0\t0\t0\t0\n",
        "2\t2\t1\t1\t1\n",
        "2\t2\t0\t0\t0\n",
        "2\t2\t0\t0\t0\n",
        "2\t2\t2\t0\t0\n",
        "2\t2\t2\t2\t1\n",
        "2\t0\t0\t0\t0\n",
        "2\t2\t0\t0\t0\n",
        "2\t2\t2\t1\t1\n",
        "2\t0\t0\t0\t0\n",
        "2\t0\t0\t0\t0\n",
        "1\t1\t1\t2\t2\n",
        "2\t0\t2\t1\t1\n",
        "0\t0\t0\t0\t0\n",
        "2\t2\t2\t1\t1\n",
        "2\t2\t0\t0\t0\n",
        "2\t0\t0\t0\t0\n",
        "0\t0\t0\t0\t0\n",
        "0\t0\t0\t0\t0\n",
        "2\t1\t1\t1\t1\n",
        "0\t0\t0\t0\t0\n",
        "2\t2\t2\t2\t2\n",
        "1\t1\t1\t1\t1\n",
        "2\t2\t2\t2\t2\n",
        "2\t2\t0\t0\t0\n",
        "2\t1\t1\t1\t1\n",
        "2\t2\t1\t1\t1\n",
        "2\t2\t1\t1\t1\n",
        "2\t2\t2\t0\t0\n",
        "2\t1\t1\t1\t1\n",
        "2\t0\t0\t0\t0\n",
        "2\t2\t0\t0\t0\n",
        "2\t1\t1\t1\t1\n",
        "2\t2\t2\t2\t1\n",
        "2\t1\t1\t1\t1\n",
        "2\t0\t0\t0\t0\n",
        "2\t2\t2\t2\t2\n",
        "2\t1\t1\t1\t1\n",
        "2\t2\t1\t2\t2\n",
        "2\t2\t2\t0\t0\n",
        "2\t1\t1\t1\t1\n",
        "1\t1\t1\t1\t1\n",
        "2\t1\t1\t1\t1\n",
        "2\t1\t1\t1\t1\n",
        "2\t2\t2\t2\t2\n",
        "1\t1\t1\t1\t1\n",
        "2\t0\t2\t2\t2\n",
        "2\t1\t1\t2\t2\n",
        "2\t2\t0\t0\t0\n",
        "2\t2\t2\t2\t2\n",
        "2\t2\t2\t0\t0\n",
        "2\t2\t2\t2\t2\n",
        "0\t0\t0\t0\t0\n",
        "2\t2\t2\t1\t1\n",
        "0\t0\t0\t0\t0\n",
        "2\t2\t2\t2\t2\n",
        "2\t0\t0\t0\t0\n",
        "2\t1\t1\t1\t1\n",
        "2\t1\t1\t1\t1\n",
        "2\t1\t1\t1\t1\n",
        "2\t2\t2\t2\t2\n",
        "2\t0\t0\t0\t0\n",
        "1\t1\t1\t1\t1\n",
        "2\t2\t2\t2\t2\n",
        "2\t2\t0\t0\t0\n",
        "2\t0\t0\t0\t0\n",
        "2\t1\t1\t1\t1\n",
        "2\t1\t1\t1\t1\n",
        "2\t2\t2\t2\t0\n",
        "2\t1\t2\t2\t0\n",
        "2\t2\t1\t1\t1\n",
        "2\t2\t1\t1\t1\n",
        "2\t1\t1\t1\t1\n",
        "2\t2\t0\t0\t0\n",
        "2\t0\t0\t0\t0\n",
        "2\t2\t2\t2\t2\n",
        "2\t1\t1\t2\t0\n",
        "2\t2\t2\t2\t0\n",
        "0\t0\t0\t0\t0\n",
        "2\t0\t0\t0\t0\n",
        "2\t2\t2\t2\t2\n",
        "0\t0\t0\t0\t0\n",
        "2\t1\t1\t1\t1\n",
        "2\t2\t2\t2\t2\n",
        "2\t0\t0\t0\t0\n",
        "2\t2\t2\t2\t2\n",
        "2\t1\t1\t1\t1\n",
        "2\t1\t1\t1\t1\n",
        "2\t0\t0\t0\t0\n",
        "0\t0\t0\t0\t0\n",
        "2\t0\t0\t0\t0\n",
        "2\t1\t1\t1\t1\n",
        "2\t2\t2\t2\t2\n",
        "2\t2\t2\t2\t2\n",
        "2\t0\t0\t0\t0\n",
        "2\t0\t0\t0\t0\n",
        "0\t0\t0\t0\t0\n",
        "2\t0\t0\t0\t0\n",
        "2\t2\t0\t0\t0\n",
        "0\t0\t0\t0\t0\n",
        "2\t0\t0\t0\t0\n",
        "0\t0\t0\t0\t0\n",
        "0\t0\t0\t0\t0\n",
        "0\t0\t0\t0\t0\n",
        "2\t2\t1\t1\t1\n",
        "2\t2\t2\t1\t1\n",
        "2\t2\t2\t2\t2\n",
        "0\t0\t0\t0\t0\n",
        "2\t2\t2\t2\t1\n",
        "2\t2\t1\t1\t1\n",
        "2\t1\t1\t1\t1\n",
        "2\t2\t2\t2\t2\n",
        "2\t2\t2\t0\t0\n",
        "2\t1\t1\t1\t1\n",
        "2\t2\t1\t1\t1\n",
        "2\t1\t1\t1\t1\n",
        "2\t2\t0\t0\t0\n",
        "1\t1\t2\t0\t0\n",
        "2\t2\t0\t0\t0\n",
        "2\t0\t0\t0\t0\n",
        "0\t0\t0\t0\t0\n",
        "0\t0\t0\t0\t0\n",
        "2\t2\t2\t2\t2\n",
        "0\t0\t0\t0\t0\n",
        "2\t2\t0\t0\t0\n",
        "1\t1\t1\t1\t1\n",
        "0\t0\t0\t0\t0\n",
        "0\t0\t0\t0\t0\n",
        "2\t2\t2\t2\t1\n",
        "2\t1\t1\t1\t1\n",
        "2\t1\t1\t2\t0\n",
        "2\t2\t1\t1\t1\n",
        "2\t0\t0\t0\t0\n",
        "2\t0\t0\t2\t0\n",
        "2\t2\t1\t1\t1\n",
        "0\t0\t0\t0\t0\n",
        "1\t1\t1\t1\t1\n",
        "2\t2\t0\t0\t2\n",
        "2\t0\t0\t0\t0\n",
        "2\t2\t2\t2\t2\n",
        "2\t1\t1\t1\t1\n",
        "0\t0\t0\t0\t0\n",
        "1\t1\t1\t1\t1\n",
        "0\t0\t0\t0\t0\n",
        "2\t1\t1\t1\t1\n",
        "2\t0\t0\t0\t0\n",
        "0\t0\t0\t0\t0\n",
        "2\t1\t1\t1\t1\n",
        "2\t1\t1\t1\t1\n",
        "1\t1\t1\t1\t1\n",
        "2\t2\t2\t2\t1\n",
        "2\t0\t0\t0\t0\n",
        "2\t2\t1\t1\t1\n",
        "2\t2\t1\t1\t1\n",
        "2\t2\t2\t2\t2\n",
        "1\t1\t1\t1\t1\n",
        "2\t2\t2\t1\t1\n",
        "2\t1\t1\t1\t1\n",
        "2\t2\t0\t0\t0\n",
        "2\t2\t0\t0\t0\n",
        "2\t1\t1\t1\t1\n",
        "2\t0\t0\t0\t0\n",
        "2\t1\t1\t1\t1\n",
        "2\t2\t2\t2\t1\n",
        "2\t1\t1\t1\t1\n",
        "2\t2\t1\t1\t1\n",
        "2\t1\t1\t1\t1\n",
        "0\t0\t0\t0\t0\n",
        "0\t0\t0\t0\t0\n",
        "2\t2\t1\t1\t1\n",
        "0\t0\t0\t0\t0\n",
        "1\t1\t1\t1\t1\n",
        "2\t0\t0\t0\t0\n",
        "0\t0\t0\t0\t0\n",
        "2\t2\t1\t1\t1\n",
        "2\t1\t1\t1\t1\n",
        "2\t2\t2\t1\t1\n",
        "0\t0\t0\t0\t0\n",
        "2\t2\t1\t1\t1\n",
        "2\t2\t1\t1\t2\n",
        "2\t0\t0\t0\t0\n",
        "2\t2\t0\t0\t0\n",
        "2\t2\t2\t2\t1\n",
        "2\t2\t2\t0\t0\n",
        "2\t2\t2\t2\t2\n",
        "1\t1\t1\t1\t1\n",
        "2\t1\t1\t2\t0\n",
        "2\t1\t1\t1\t1\n",
        "2\t2\t0\t0\t0\n",
        "2\t2\t2\t2\t0\n",
        "0\t0\t0\t0\t0\n",
        "0\t0\t0\t0\t0\n",
        "1\t1\t1\t1\t1\n",
        "2\t0\t0\t2\t2\n",
        "2\t2\t0\t0\t0\n",
        "2\t0\t0\t2\t1\n",
        "1\t1\t1\t1\t1\n",
        "2\t1\t1\t1\t1\n",
        "2\t0\t0\t0\t0\n",
        "1\t1\t1\t1\t1\n",
        "1\t1\t1\t1\t1\n",
        "1\t1\t1\t1\t1\n",
        "1\t1\t1\t1\t1\n",
        "2\t0\t2\t2\t2\n",
        "2\t2\t2\t2\t2\n",
        "2\t1\t1\t1\t1\n",
        "2\t2\t2\t2\t2\n",
        "1\t1\t1\t1\t1\n",
        "2\t0\t2\t1\t1\n",
        "2\t0\t0\t0\t0\n",
        "2\t1\t1\t1\t1\n",
        "2\t1\t1\t1\t1\n",
        "0\t0\t0\t0\t0\n",
        "2\t2\t2\t1\t1\n",
        "0\t0\t0\t0\t0\n",
        "1\t1\t1\t1\t1\n",
        "2\t2\t2\t0\t0\n",
        "2\t1\t1\t1\t1\n",
        "2\t0\t0\t0\t0\n",
        "0\t0\t0\t0\t0\n",
        "2\t1\t2\t2\t0\n",
        "2\t0\t0\t0\t0\n",
        "2\t1\t1\t1\t1\n",
        "2\t0\t0\t0\t0\n",
        "2\t2\t2\t2\t2\n",
        "2\t2\t0\t0\t0\n",
        "2\t1\t1\t1\t1\n",
        "2\t1\t1\t1\t1\n",
        "0\t0\t0\t0\t0\n",
        "2\t0\t2\t1\t1\n",
        "0\t0\t0\t0\t0\n",
        "2\t2\t2\t1\t1\n",
        "2\t1\t1\t1\t1\n",
        "0\t0\t0\t0\t0\n",
        "2\t1\t0\t0\t0\n",
        "1\t1\t1\t1\t1\n",
        "2\t1\t1\t1\t1\n",
        "2\t1\t1\t1\t1\n",
        "2\t2\t1\t1\t1\n",
        "2\t1\t1\t1\t1\n",
        "0\t0\t0\t0\t0\n",
        "2\t0\t0\t0\t0\n",
        "2\t2\t0\t0\t0\n",
        "2\t2\t1\t1\t1\n",
        "2\t2\t2\t1\t1\n",
        "1\t1\t1\t2\t0\n",
        "0\t0\t0\t0\t0\n",
        "1\t1\t1\t1\t1\n",
        "2\t2\t1\t1\t1\n",
        "2\t2\t0\t0\t0\n",
        "2\t1\t1\t1\t1\n",
        "2\t1\t1\t1\t1\n",
        "2\t2\t2\t1\t1\n",
        "0\t0\t0\t0\t0\n",
        "2\t1\t1\t1\t1\n",
        "2\t1\t1\t1\t1\n",
        "2\t2\t2\t1\t1\n",
        "2\t2\t2\t2\t2\n",
        "2\t1\t1\t1\t1\n",
        "2\t2\t2\t2\t2\n",
        "1\t1\t1\t0\t0\n",
        "1\t1\t1\t1\t1\n",
        "2\t2\t2\t0\t0\n",
        "2\t0\t0\t0\t0\n",
        "2\t2\t0\t0\t0\n",
        "0\t0\t0\t0\t0\n",
        "2\t1\t1\t1\t1\n",
        "2\t0\t0\t0\t0\n",
        "2\t0\t0\t0\t0\n",
        "2\t0\t0\t0\t0\n",
        "2\t2\t2\t2\t2\n",
        "2\t1\t1\t1\t1\n",
        "2\t1\t1\t1\t1\n",
        "1\t1\t1\t1\t1\n",
        "2\t1\t1\t1\t1\n",
        "2\t2\t2\t1\t1\n",
        "2\t2\t1\t1\t1\n",
        "2\t0\t0\t0\t0\n",
        "2\t2\t2\t2\t1\n",
        "0\t0\t0\t0\t0\n",
        "1\t1\t1\t1\t1\n",
        "2\t2\t0\t0\t0\n",
        "2\t2\t1\t1\t1\n",
        "2\t1\t1\t1\t1\n",
        "2\t1\t1\t1\t1\n",
        "2\t2\t2\t0\t0\n",
        "1\t1\t1\t1\t1\n",
        "2\t2\t0\t0\t0\n",
        "2\t2\t2\t2\t2\n",
        "1\t1\t1\t1\t2\n",
        "2\t0\t0\t0\t0\n",
        "2\t2\t2\t2\t2\n",
        "2\t0\t0\t0\t2\n",
        "2\t2\t2\t2\t2\n",
        "2\t2\t0\t0\t0\n",
        "2\t2\t0\t0\t2\n",
        "2\t0\t0\t0\t0\n",
        "2\t2\t0\t0\t0\n",
        "2\t2\t2\t2\t2\n",
        "2\t1\t1\t1\t1\n",
        "2\t2\t2\t2\t2\n",
        "2\t2\t0\t0\t0\n",
        "2\t2\t2\t2\t2\n",
        "2\t2\t1\t1\t1\n",
        "2\t0\t0\t0\t0\n",
        "2\t2\t2\t2\t2\n",
        "0\t0\t0\t0\t0\n",
        "0\t0\t0\t0\t0\n",
        "2\t2\t1\t1\t1\n",
        "2\t0\t0\t0\t0\n",
        "2\t1\t1\t1\t1\n",
        "2\t1\t1\t1\t1\n",
        "2\t0\t0\t0\t0\n",
        "2\t2\t2\t0\t0\n",
        "2\t1\t1\t1\t1\n",
        "1\t1\t1\t1\t1\n",
        "0\t0\t0\t0\t0\n",
        "2\t2\t0\t2\t2\n",
        "2\t2\t2\t1\t1\n",
        "2\t2\t2\t0\t0\n",
        "2\t2\t2\t2\t2\n",
        "2\t2\t0\t0\t0\n",
        "2\t2\t1\t1\t1\n",
        "1\t1\t1\t1\t1\n",
        "2\t1\t1\t1\t1\n",
        "2\t2\t0\t0\t0\n",
        "2\t0\t0\t0\t0\n",
        "2\t2\t2\t2\t2\n",
        "2\t1\t1\t2\t2\n",
        "2\t2\t2\t1\t1\n",
        "2\t0\t0\t0\t0\n",
        "2\t2\t2\t2\t2\n",
        "0\t0\t0\t0\t0\n",
        "2\t2\t0\t0\t0\n",
        "2\t0\t0\t0\t0\n",
        "2\t2\t2\t2\t2\n",
        "2\t2\t0\t0\t0\n",
        "2\t0\t0\t0\t0\n",
        "2\t0\t0\t0\t0\n",
        "2\t1\t1\t1\t1\n",
        "2\t0\t0\t0\t0\n",
        "2\t1\t1\t1\t1\n",
        "2\t2\t2\t2\t2\n",
        "2\t0\t0\t0\t0\n",
        "0\t0\t0\t0\t0\n",
        "2\t2\t2\t2\t0\n",
        "2\t0\t0\t0\t0\n",
        "2\t0\t0\t0\t0\n"
       ]
      }
     ],
     "prompt_number": 77
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Test Report \n",
      "\n",
      "For every classifier we test a set of parameters and produce statistics comparing predictions of the models to human oracle predictions. \n",
      "\n",
      "We report: \n",
      "\n",
      "* Accuracy\n",
      "* Confusion Matrix\n",
      "* Label distribution\n",
      "* Precision, recall, f1\n",
      "* Class 0 distribution\n"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# compute metrics\n",
      "def print_cm(cm):\n",
      "    return \"\\n\".join([\"{}\\t{}\\t{}\".format(*r) for r in cm])\n",
      "\n",
      "def print_report(user_labels, results, C, threshold, name=\"noname\"):\n",
      "    from sklearn import metrics \n",
      "    \n",
      "    for c in C:  \n",
      "        print \"\\nREPORT %s C=%s T=%s\" % (name.upper(),c, threshold)\n",
      "        print \"-\"*20\n",
      "        print \"Accuracy:\", metrics.accuracy_score(user_labels, results[c][:500])\n",
      "        print metrics.classification_report(user_labels, results[c][:500])\n",
      "        cm = metrics.confusion_matrix(user_labels, results[c][:500])\n",
      "        print \"\\nConfusion Matrix\\n%s\" % print_cm(cm)\n",
      "\n",
      "        print \"\\nDistribution (%):\"\n",
      "        print \"\\n\".join([\"Class {0}: {1:.2f}\".format(l, 1.*d/cm.sum()) for l, d in enumerate(cm.sum(0))] )\n",
      "        try:\n",
      "            print \"\\nNon-neutral distribution (C0/C0+C1): %.3f\" % (1. * cm.sum(0)[0] / (cm.sum(0)[0]+cm.sum(0)[1]))\n",
      "        except ZeroDivisionError:\n",
      "            print \"Non-neutral distribution: N/A\" \n",
      "        "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 289
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# Testing Models Trained on Sentences: IMDB\n",
      "\n",
      "We test several value of parameters per classifier. We tested: \n",
      "\n",
      "* LRL2\n",
      "* LRL1\n",
      "* LinearSVC: does not have probability estimation\n",
      "* DecisionTree: Requires dense representation\n",
      "* MNB\n",
      "\n",
      "## Testing LR-L2 over C values\n",
      "\n",
      "We tested $C=\\{10^{-2},10^{-1},10^0,10^1,10^2,\\}$ for LR classifiers, we use human expert labels as ground truth"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Test LRL2 sentences\n",
      "C = [pow(10,x) for x in range(-2,3)]\n",
      "data = {'bow':exp_sent_bow, 'target':exp_lbl}\n",
      "results = test_parameters(\"LogisticRegression(penalty='l2', C={})\", C, data, .4 )\n",
      "print print_report(user_labels, results, C, name=\"lrl2\")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Parameters for LogisticRegression(penalty='l2', C={}) and T > 0.4\n",
        "Testing ... C= 0.01\n",
        "Testing ... C="
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 0.1\n",
        "Testing ... C="
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 1\n",
        "Testing ... C="
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 10\n",
        "Testing ... C="
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 100\n",
        "\n",
        "REPORT LRL2 C=0.01"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "--------------------\n",
        "Accuracy: 0.476\n",
        "             precision    recall  f1-score   support\n",
        "\n",
        "        0.0       0.67      0.32      0.43       175\n",
        "        1.0       0.81      0.23      0.35       155\n",
        "        2.0       0.39      0.86      0.54       170\n",
        "\n",
        "avg / total       0.62      0.48      0.45       500\n",
        "\n",
        "\n",
        "Confusion Matrix\n",
        "56\t4\t115\n",
        "8\t35\t112\n",
        "19\t4\t147\n",
        "\n",
        "Distribution (%):\n",
        "Class 0: 0.17\n",
        "Class 1: 0.09\n",
        "Class 2: 0.75\n",
        "\n",
        "Non-neutral distribution (C0/C0+C1): 0.659\n",
        "\n",
        "REPORT LRL2 C=0.1\n",
        "--------------------\n",
        "Accuracy: 0.568\n",
        "             precision    recall  f1-score   support\n",
        "\n",
        "        0.0       0.64      0.62      0.63       175\n",
        "        1.0       0.62      0.57      0.59       155\n",
        "        2.0       0.47      0.52      0.49       170\n",
        "\n",
        "avg / total       0.57      0.57      0.57       500\n",
        "\n",
        "\n",
        "Confusion Matrix\n",
        "108\t16\t51\n",
        "17\t88\t50\n",
        "45\t37\t88\n",
        "\n",
        "Distribution (%):\n",
        "Class 0: 0.34\n",
        "Class 1: 0.28\n",
        "Class 2: 0.38\n",
        "\n",
        "Non-neutral distribution (C0/C0+C1): 0.547\n",
        "\n",
        "REPORT LRL2 C=1\n",
        "--------------------\n",
        "Accuracy: 0.548\n",
        "             precision    recall  f1-score   support\n",
        "\n",
        "        0.0       0.58      0.67      0.62       175\n",
        "        1.0       0.57      0.65      0.61       155\n",
        "        2.0       0.46      0.33      0.38       170\n",
        "\n",
        "avg / total       0.54      0.55      0.54       500\n",
        "\n",
        "\n",
        "Confusion Matrix\n",
        "118\t23\t34\n",
        "24\t100\t31\n",
        "63\t51\t56\n",
        "\n",
        "Distribution (%):\n",
        "Class 0: 0.41\n",
        "Class 1: 0.35\n",
        "Class 2: 0.24\n",
        "\n",
        "Non-neutral distribution (C0/C0+C1): 0.541\n",
        "\n",
        "REPORT LRL2 C=10\n",
        "--------------------\n",
        "Accuracy: 0.52\n",
        "             precision    recall  f1-score   support\n",
        "\n",
        "        0.0       0.56      0.65      0.60       175\n",
        "        1.0       0.54      0.63      0.59       155\n",
        "        2.0       0.42      0.29      0.34       170\n",
        "\n",
        "avg / total       0.51      0.52      0.51       500\n",
        "\n",
        "\n",
        "Confusion Matrix\n",
        "113\t24\t38\n",
        "27\t98\t30\n",
        "63\t58\t49\n",
        "\n",
        "Distribution (%):\n",
        "Class 0: 0.41\n",
        "Class 1: 0.36\n",
        "Class 2: 0.23\n",
        "\n",
        "Non-neutral distribution (C0/C0+C1): 0.530\n",
        "\n",
        "REPORT LRL2 C=100\n",
        "--------------------\n",
        "Accuracy: 0.5\n",
        "             precision    recall  f1-score   support\n",
        "\n",
        "        0.0       0.53      0.66      0.59       175\n",
        "        1.0       0.53      0.65      0.58       155\n",
        "        2.0       0.38      0.19      0.26       170\n",
        "\n",
        "avg / total       0.48      0.50      0.47       500\n",
        "\n",
        "\n",
        "Confusion Matrix\n",
        "116\t28\t31\n",
        "30\t101\t24\n",
        "74\t63\t33\n",
        "\n",
        "Distribution (%):\n",
        "Class 0: 0.44\n",
        "Class 1: 0.38\n",
        "Class 2: 0.18\n",
        "\n",
        "Non-neutral distribution (C0/C0+C1): 0.534\n",
        "None\n"
       ]
      }
     ],
     "prompt_number": 199
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Testing Threshold .35\n",
      "data = {'bow':exp_sent_bow, 'target':exp_lbl}\n",
      "results = test_parameters(\"LogisticRegression(penalty='l2', C={})\", C, data, .35 )\n",
      "print print_report(user_labels, results, C, name=\"lrl2\")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Testing Parameters for LogisticRegression(penalty='l2', C={}) and T > 0.35\n",
        "Testing ... C= 0.01\n",
        "Testing ... C="
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 0.1\n",
        "Testing ... C="
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 1\n",
        "Testing ... C="
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 10\n",
        "Testing ... C="
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 100\n",
        "\n",
        "REPORT LRL2 C=0.01"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "--------------------\n",
        "Accuracy: 0.402\n",
        "             precision    recall  f1-score   support\n",
        "\n",
        "        0.0       0.76      0.17      0.27       175\n",
        "        1.0       0.89      0.05      0.10       155\n",
        "        2.0       0.36      0.96      0.53       170\n",
        "\n",
        "avg / total       0.67      0.40      0.30       500\n",
        "\n",
        "\n",
        "Confusion Matrix\n",
        "29\t1\t145\n",
        "3\t8\t144\n",
        "6\t0\t164\n",
        "\n",
        "Distribution (%):\n",
        "Class 0: 0.08\n",
        "Class 1: 0.02\n",
        "Class 2: 0.91\n",
        "\n",
        "Non-neutral distribution (C0/C0+C1): 0.809\n",
        "\n",
        "REPORT LRL2 C=0.1\n",
        "--------------------\n",
        "Accuracy: 0.546\n",
        "             precision    recall  f1-score   support\n",
        "\n",
        "        0.0       0.68      0.47      0.56       175\n",
        "        1.0       0.70      0.44      0.54       155\n",
        "        2.0       0.43      0.72      0.54       170\n",
        "\n",
        "avg / total       0.60      0.55      0.55       500\n",
        "\n",
        "\n",
        "Confusion Matrix\n",
        "83\t8\t84\n",
        "12\t68\t75\n",
        "27\t21\t122\n",
        "\n",
        "Distribution (%):\n",
        "Class 0: 0.24\n",
        "Class 1: 0.19\n",
        "Class 2: 0.56\n",
        "\n",
        "Non-neutral distribution (C0/C0+C1): 0.557\n",
        "\n",
        "REPORT LRL2 C=1\n",
        "--------------------\n",
        "Accuracy: 0.558\n",
        "             precision    recall  f1-score   support\n",
        "\n",
        "        0.0       0.64      0.61      0.63       175\n",
        "        1.0       0.60      0.56      0.58       155\n",
        "        2.0       0.45      0.50      0.47       170\n",
        "\n",
        "avg / total       0.56      0.56      0.56       500\n",
        "\n",
        "\n",
        "Confusion Matrix\n",
        "107\t17\t51\n",
        "15\t87\t53\n",
        "44\t41\t85\n",
        "\n",
        "Distribution (%):\n",
        "Class 0: 0.33\n",
        "Class 1: 0.29\n",
        "Class 2: 0.38\n",
        "\n",
        "Non-neutral distribution (C0/C0+C1): 0.534\n",
        "\n",
        "REPORT LRL2 C=10\n",
        "--------------------\n",
        "Accuracy: 0.514\n",
        "             precision    recall  f1-score   support\n",
        "\n",
        "        0.0       0.57      0.61      0.59       175\n",
        "        1.0       0.56      0.58      0.57       155\n",
        "        2.0       0.40      0.36      0.38       170\n",
        "\n",
        "avg / total       0.51      0.51      0.51       500\n",
        "\n",
        "\n",
        "Confusion Matrix\n",
        "106\t20\t49\n",
        "23\t90\t42\n",
        "58\t51\t61\n",
        "\n",
        "Distribution (%):\n",
        "Class 0: 0.37\n",
        "Class 1: 0.32\n",
        "Class 2: 0.30\n",
        "\n",
        "Non-neutral distribution (C0/C0+C1): 0.537\n",
        "\n",
        "REPORT LRL2 C=100\n",
        "--------------------\n",
        "Accuracy: 0.484\n",
        "             precision    recall  f1-score   support\n",
        "\n",
        "        0.0       0.53      0.62      0.57       175\n",
        "        1.0       0.52      0.58      0.55       155\n",
        "        2.0       0.35      0.25      0.29       170\n",
        "\n",
        "avg / total       0.47      0.48      0.47       500\n",
        "\n",
        "\n",
        "Confusion Matrix\n",
        "109\t24\t42\n",
        "28\t90\t37\n",
        "68\t59\t43\n",
        "\n",
        "Distribution (%):\n",
        "Class 0: 0.41\n",
        "Class 1: 0.35\n",
        "Class 2: 0.24\n",
        "\n",
        "Non-neutral distribution (C0/C0+C1): 0.542\n",
        "None\n"
       ]
      }
     ],
     "prompt_number": 143
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "##Testing LRL1 C values"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Test LRL1 sentences\n",
      "C = [pow(10,x) for x in range(-2,3)]\n",
      "data = {'bow':exp_sent_bow, 'target':exp_lbl}\n",
      "results = test_parameters(\"LogisticRegression(penalty='l1', C={})\", C, data, .4 )\n",
      "print print_report(user_labels, results, C, name=\"lrl1\")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Testing Parameters for LogisticRegression(penalty='l1', C={}) and T > 0.4\n",
        "Testing ... C= 0.01\n",
        "Testing ... C="
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 0.1\n",
        "Testing ... C="
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 1\n",
        "Testing ... C="
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 10\n",
        "Testing ... C="
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 100\n",
        "\n",
        "REPORT LRL1 C=0.01"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "--------------------\n",
        "Accuracy: 0.414\n",
        "             precision    recall  f1-score   support\n",
        "\n",
        "        0.0       0.73      0.18      0.29       175\n",
        "        1.0       0.76      0.08      0.15       155\n",
        "        2.0       0.37      0.95      0.53       170\n",
        "\n",
        "avg / total       0.62      0.41      0.33       500\n",
        "\n",
        "\n",
        "Confusion Matrix\n",
        "32\t4\t139\n",
        "4\t13\t138\n",
        "8\t0\t162\n",
        "\n",
        "Distribution (%):\n",
        "Class 0: 0.09\n",
        "Class 1: 0.03\n",
        "Class 2: 0.88\n",
        "\n",
        "Non-neutral distribution (C0/C0+C1): 0.721\n",
        "\n",
        "REPORT LRL1 C=0.1\n",
        "--------------------\n",
        "Accuracy: 0.574\n",
        "             precision    recall  f1-score   support\n",
        "\n",
        "        0.0       0.66      0.59      0.62       175\n",
        "        1.0       0.62      0.55      0.58       155\n",
        "        2.0       0.48      0.58      0.53       170\n",
        "\n",
        "avg / total       0.59      0.57      0.58       500\n",
        "\n",
        "\n",
        "Confusion Matrix\n",
        "103\t17\t55\n",
        "17\t85\t53\n",
        "35\t36\t99\n",
        "\n",
        "Distribution (%):\n",
        "Class 0: 0.31\n",
        "Class 1: 0.28\n",
        "Class 2: 0.41\n",
        "\n",
        "Non-neutral distribution (C0/C0+C1): 0.529\n",
        "\n",
        "REPORT LRL1 C=1\n",
        "--------------------\n",
        "Accuracy: 0.562\n",
        "             precision    recall  f1-score   support\n",
        "\n",
        "        0.0       0.60      0.70      0.64       175\n",
        "        1.0       0.57      0.64      0.60       155\n",
        "        2.0       0.50      0.35      0.41       170\n",
        "\n",
        "avg / total       0.55      0.56      0.55       500\n",
        "\n",
        "\n",
        "Confusion Matrix\n",
        "122\t23\t30\n",
        "25\t99\t31\n",
        "58\t52\t60\n",
        "\n",
        "Distribution (%):\n",
        "Class 0: 0.41\n",
        "Class 1: 0.35\n",
        "Class 2: 0.24\n",
        "\n",
        "Non-neutral distribution (C0/C0+C1): 0.541\n",
        "\n",
        "REPORT LRL1 C=10\n",
        "--------------------\n",
        "Accuracy: 0.5\n",
        "             precision    recall  f1-score   support\n",
        "\n",
        "        0.0       0.54      0.65      0.59       175\n",
        "        1.0       0.52      0.65      0.57       155\n",
        "        2.0       0.38      0.21      0.27       170\n",
        "\n",
        "avg / total       0.48      0.50      0.48       500\n",
        "\n",
        "\n",
        "Confusion Matrix\n",
        "114\t28\t33\n",
        "28\t100\t27\n",
        "69\t65\t36\n",
        "\n",
        "Distribution (%):\n",
        "Class 0: 0.42\n",
        "Class 1: 0.39\n",
        "Class 2: 0.19\n",
        "\n",
        "Non-neutral distribution (C0/C0+C1): 0.522\n",
        "\n",
        "REPORT LRL1 C=100\n",
        "--------------------\n",
        "Accuracy: 0.494\n",
        "             precision    recall  f1-score   support\n",
        "\n",
        "        0.0       0.52      0.66      0.59       175\n",
        "        1.0       0.52      0.65      0.57       155\n",
        "        2.0       0.36      0.18      0.24       170\n",
        "\n",
        "avg / total       0.47      0.49      0.47       500\n",
        "\n",
        "\n",
        "Confusion Matrix\n",
        "116\t29\t30\n",
        "31\t100\t24\n",
        "74\t65\t31\n",
        "\n",
        "Distribution (%):\n",
        "Class 0: 0.44\n",
        "Class 1: 0.39\n",
        "Class 2: 0.17\n",
        "\n",
        "Non-neutral distribution (C0/C0+C1): 0.533\n",
        "None\n"
       ]
      }
     ],
     "prompt_number": 145
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "C = [pow(10,x) for x in range(-2,3)]\n",
      "data = {'bow':exp_sent_bow, 'target':exp_lbl}\n",
      "results = test_parameters(\"LogisticRegression(penalty='l1', C={})\", C, data, .35 )\n",
      "print print_report(user_labels, results, C, name=\"lrl1\")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Testing Parameters for LogisticRegression(penalty='l1', C={}) and T > 0.35\n",
        "Testing ... C= 0.01\n",
        "Testing ... C="
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 0.1\n",
        "Testing ... C="
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 1\n",
        "Testing ... C="
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 10\n",
        "Testing ... C="
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 100\n",
        "\n",
        "REPORT LRL1 C=0.01"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "--------------------\n",
        "Accuracy: 0.374\n",
        "             precision    recall  f1-score   support\n",
        "\n",
        "        0.0       0.74      0.10      0.17       175\n",
        "        1.0       0.80      0.03      0.05       155\n",
        "        2.0       0.35      0.98      0.52       170\n",
        "\n",
        "avg / total       0.63      0.37      0.25       500\n",
        "\n",
        "\n",
        "Confusion Matrix\n",
        "17\t1\t157\n",
        "2\t4\t149\n",
        "4\t0\t166\n",
        "\n",
        "Distribution (%):\n",
        "Class 0: 0.05\n",
        "Class 1: 0.01\n",
        "Class 2: 0.94\n",
        "\n",
        "Non-neutral distribution (C0/C0+C1): 0.821\n",
        "\n",
        "REPORT LRL1 C=0.1\n",
        "--------------------\n",
        "Accuracy: 0.56\n",
        "             precision    recall  f1-score   support\n",
        "\n",
        "        0.0       0.71      0.47      0.56       175\n",
        "        1.0       0.71      0.43      0.54       155\n",
        "        2.0       0.45      0.77      0.57       170\n",
        "\n",
        "avg / total       0.62      0.56      0.56       500\n",
        "\n",
        "\n",
        "Confusion Matrix\n",
        "82\t11\t82\n",
        "12\t67\t76\n",
        "22\t17\t131\n",
        "\n",
        "Distribution (%):\n",
        "Class 0: 0.23\n",
        "Class 1: 0.19\n",
        "Class 2: 0.58\n",
        "\n",
        "Non-neutral distribution (C0/C0+C1): 0.550\n",
        "\n",
        "REPORT LRL1 C=1\n",
        "--------------------\n",
        "Accuracy: 0.546\n",
        "             precision    recall  f1-score   support\n",
        "\n",
        "        0.0       0.64      0.61      0.62       175\n",
        "        1.0       0.57      0.53      0.55       155\n",
        "        2.0       0.45      0.50      0.47       170\n",
        "\n",
        "avg / total       0.55      0.55      0.55       500\n",
        "\n",
        "\n",
        "Confusion Matrix\n",
        "106\t20\t49\n",
        "16\t82\t57\n",
        "44\t41\t85\n",
        "\n",
        "Distribution (%):\n",
        "Class 0: 0.33\n",
        "Class 1: 0.29\n",
        "Class 2: 0.38\n",
        "\n",
        "Non-neutral distribution (C0/C0+C1): 0.537\n",
        "\n",
        "REPORT LRL1 C=10\n",
        "--------------------\n",
        "Accuracy: 0.498\n",
        "             precision    recall  f1-score   support\n",
        "\n",
        "        0.0       0.55      0.61      0.58       175\n",
        "        1.0       0.53      0.58      0.56       155\n",
        "        2.0       0.38      0.31      0.34       170\n",
        "\n",
        "avg / total       0.49      0.50      0.49       500\n",
        "\n",
        "\n",
        "Confusion Matrix\n",
        "107\t23\t45\n",
        "25\t90\t40\n",
        "62\t56\t52\n",
        "\n",
        "Distribution (%):\n",
        "Class 0: 0.39\n",
        "Class 1: 0.34\n",
        "Class 2: 0.27\n",
        "\n",
        "Non-neutral distribution (C0/C0+C1): 0.534\n",
        "\n",
        "REPORT LRL1 C=100\n",
        "--------------------\n",
        "Accuracy: 0.488\n",
        "             precision    recall  f1-score   support\n",
        "\n",
        "        0.0       0.53      0.63      0.58       175\n",
        "        1.0       0.51      0.58      0.55       155\n",
        "        2.0       0.37      0.25      0.30       170\n",
        "\n",
        "avg / total       0.47      0.49      0.47       500\n",
        "\n",
        "\n",
        "Confusion Matrix\n",
        "111\t26\t38\n",
        "29\t90\t36\n",
        "68\t59\t43\n",
        "\n",
        "Distribution (%):\n",
        "Class 0: 0.42\n",
        "Class 1: 0.35\n",
        "Class 2: 0.23\n",
        "\n",
        "Non-neutral distribution (C0/C0+C1): 0.543\n",
        "None\n"
       ]
      }
     ],
     "prompt_number": 144
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Test LRL2 sentences\n",
      "from sklearn.svm import LinearSVC\n",
      "C = [pow(10,x) for x in range(-2,3)]\n",
      "results = test_parameters(\"LinearSVC(C={}, probability=True)\", C, imdb.test, .4 )\n",
      "print print_report(user_labels, results, C, .4, name=\"LinearSVC\")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Testing Parameters for LinearSVC(C={}, probability=True) and T > 0.4\n",
        "Testing ... C= 0.01\n"
       ]
      },
      {
       "ename": "TypeError",
       "evalue": "__init__() got an unexpected keyword argument 'probability'",
       "output_type": "pyerr",
       "traceback": [
        "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
        "\u001b[0;32m<ipython-input-161-3271edc28193>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mC\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mpow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m'bow'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mexp_sent_bow\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'target'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mexp_lbl\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest_parameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"LinearSVC(C={}, probability=True)\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mC\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimdb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m.4\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;32mprint\u001b[0m \u001b[0mprint_report\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muser_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mC\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"LinearSVC\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;32m<ipython-input-90-a1a68181d2b8>\u001b[0m in \u001b[0;36mtest_parameters\u001b[0;34m(clf_str, C, data, threshold, name)\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0;32mprint\u001b[0m \u001b[0;34m\"Testing ... C=\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;31m#         expert = exputil.get_classifier('lrl2', parameter=c)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m         \u001b[0mexpert\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclf_str\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m         \u001b[0mexpert\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'bow'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'target'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mexpert\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msnip_bow\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;32m<string>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n",
        "\u001b[0;31mTypeError\u001b[0m: __init__() got an unexpected keyword argument 'probability'"
       ]
      }
     ],
     "prompt_number": 161
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "#Testing Models Trained on Documents\n",
      "\n",
      "\n"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Test LRL2 documents\n",
      "C = [pow(10,x) for x in range(-2,3)]\n",
      "results = test_parameters(\"LogisticRegression(penalty='l2', C={})\", C, imdb.test, .4 )\n",
      "print print_report(user_labels, results, C, name=\"lrl2\")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Parameters for LogisticRegression(penalty='l2', C={}) and T > 0.4\n",
        "Testing ... C= 0.01\n",
        "Testing ... C="
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 0.1\n",
        "Testing ... C="
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 1\n",
        "Testing ... C="
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 10\n",
        "Testing ... C="
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 100\n",
        "\n",
        "REPORT LRL2 C=0.01"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "--------------------\n",
        "Accuracy: 0.354\n",
        "             precision    recall  f1-score   support\n",
        "\n",
        "        0.0       0.83      0.03      0.06       175\n",
        "        1.0       1.00      0.02      0.04       155\n",
        "        2.0       0.34      0.99      0.51       170\n",
        "\n",
        "avg / total       0.72      0.35      0.20       500\n",
        "\n",
        "\n",
        "Confusion Matrix\n",
        "5\t0\t170\n",
        "0\t3\t152\n",
        "1\t0\t169\n",
        "\n",
        "Distribution (%):\n",
        "Class 0: 0.01\n",
        "Class 1: 0.01\n",
        "Class 2: 0.98\n",
        "\n",
        "Non-neutral distribution (C0/C0+C1): 0.667\n",
        "\n",
        "REPORT LRL2 C=0.1\n",
        "--------------------\n",
        "Accuracy: 0.536\n",
        "             precision    recall  f1-score   support\n",
        "\n",
        "        0.0       0.68      0.41      0.51       175\n",
        "        1.0       0.61      0.54      0.57       155\n",
        "        2.0       0.44      0.66      0.53       170\n",
        "\n",
        "avg / total       0.58      0.54      0.54       500\n",
        "\n",
        "\n",
        "Confusion Matrix\n",
        "71\t18\t86\n",
        "12\t84\t59\n",
        "21\t36\t113\n",
        "\n",
        "Distribution (%):\n",
        "Class 0: 0.21\n",
        "Class 1: 0.28\n",
        "Class 2: 0.52\n",
        "\n",
        "Non-neutral distribution (C0/C0+C1): 0.430\n",
        "\n",
        "REPORT LRL2 C=1\n",
        "--------------------\n",
        "Accuracy: 0.566\n",
        "             precision    recall  f1-score   support\n",
        "\n",
        "        0.0       0.61      0.70      0.66       175\n",
        "        1.0       0.55      0.66      0.60       155\n",
        "        2.0       0.50      0.34      0.40       170\n",
        "\n",
        "avg / total       0.56      0.57      0.55       500\n",
        "\n",
        "\n",
        "Confusion Matrix\n",
        "123\t26\t26\n",
        "21\t103\t31\n",
        "56\t57\t57\n",
        "\n",
        "Distribution (%):\n",
        "Class 0: 0.40\n",
        "Class 1: 0.37\n",
        "Class 2: 0.23\n",
        "\n",
        "Non-neutral distribution (C0/C0+C1): 0.518\n",
        "\n",
        "REPORT LRL2 C=10\n",
        "--------------------\n",
        "Accuracy: 0.532\n",
        "             precision    recall  f1-score   support\n",
        "\n",
        "        0.0       0.56      0.75      0.64       175\n",
        "        1.0       0.52      0.67      0.59       155\n",
        "        2.0       0.47      0.18      0.26       170\n",
        "\n",
        "avg / total       0.52      0.53      0.50       500\n",
        "\n",
        "\n",
        "Confusion Matrix\n",
        "131\t29\t15\n",
        "31\t104\t20\n",
        "72\t67\t31\n",
        "\n",
        "Distribution (%):\n",
        "Class 0: 0.47\n",
        "Class 1: 0.40\n",
        "Class 2: 0.13\n",
        "\n",
        "Non-neutral distribution (C0/C0+C1): 0.539\n",
        "\n",
        "REPORT LRL2 C=100\n",
        "--------------------\n",
        "Accuracy: 0.504\n",
        "             precision    recall  f1-score   support\n",
        "\n",
        "        0.0       0.53      0.76      0.62       175\n",
        "        1.0       0.49      0.68      0.57       155\n",
        "        2.0       0.41      0.08      0.13       170\n",
        "\n",
        "avg / total       0.47      0.50      0.44       500\n",
        "\n",
        "\n",
        "Confusion Matrix\n",
        "133\t33\t9\n",
        "39\t106\t10\n",
        "80\t77\t13\n",
        "\n",
        "Distribution (%):\n",
        "Class 0: 0.50\n",
        "Class 1: 0.43\n",
        "Class 2: 0.06\n",
        "\n",
        "Non-neutral distribution (C0/C0+C1): 0.538\n",
        "None\n"
       ]
      }
     ],
     "prompt_number": 273
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "imdb.test.bow.shape"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 274,
       "text": [
        "(25000, 27316)"
       ]
      }
     ],
     "prompt_number": 274
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Test LRL1 documents\n",
      "C = [pow(10,x) for x in range(-1,3)]\n",
      "results = test_parameters(\"LogisticRegression(penalty='l1', C={})\", C, imdb.test, .4 )\n",
      "print print_report(user_labels, results, C, .4, name=\"lrl1\")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Parameters for LogisticRegression(penalty='l1', C={}) and T > 0.4\n",
        "Testing ... C= 0.1\n",
        "Testing ... C="
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 1\n",
        "Testing ... C="
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 10\n",
        "Testing ... C="
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 100\n",
        "\n",
        "REPORT LRL1 C=0.1 T=0.4"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "--------------------\n",
        "Accuracy: 0.534\n",
        "             precision    recall  f1-score   support\n",
        "\n",
        "        0.0       0.65      0.42      0.51       175\n",
        "        1.0       0.56      0.47      0.51       155\n",
        "        2.0       0.47      0.71      0.56       170\n",
        "\n",
        "avg / total       0.56      0.53      0.53       500\n",
        "\n",
        "\n",
        "Confusion Matrix\n",
        "74\t29\t72\n",
        "19\t73\t63\n",
        "21\t29\t120\n",
        "\n",
        "Distribution (%):\n",
        "Class 0: 0.23\n",
        "Class 1: 0.26\n",
        "Class 2: 0.51\n",
        "\n",
        "Non-neutral distribution (C0/C0+C1): 0.465\n",
        "\n",
        "REPORT LRL1 C=1 T=0.4\n",
        "--------------------\n",
        "Accuracy: 0.556\n",
        "             precision    recall  f1-score   support\n",
        "\n",
        "        0.0       0.62      0.70      0.65       175\n",
        "        1.0       0.53      0.67      0.59       155\n",
        "        2.0       0.50      0.31      0.38       170\n",
        "\n",
        "avg / total       0.55      0.56      0.54       500\n",
        "\n",
        "\n",
        "Confusion Matrix\n",
        "122\t27\t26\n",
        "24\t104\t27\n",
        "52\t66\t52\n",
        "\n",
        "Distribution (%):\n",
        "Class 0: 0.40\n",
        "Class 1: 0.39\n",
        "Class 2: 0.21\n",
        "\n",
        "Non-neutral distribution (C0/C0+C1): 0.501\n",
        "\n",
        "REPORT LRL1 C=10 T=0.4\n",
        "--------------------\n",
        "Accuracy: 0.516\n",
        "             precision    recall  f1-score   support\n",
        "\n",
        "        0.0       0.54      0.73      0.62       175\n",
        "        1.0       0.51      0.72      0.60       155\n",
        "        2.0       0.43      0.11      0.17       170\n",
        "\n",
        "avg / total       0.49      0.52      0.46       500\n",
        "\n",
        "\n",
        "Confusion Matrix\n",
        "128\t33\t14\n",
        "33\t112\t10\n",
        "77\t75\t18\n",
        "\n",
        "Distribution (%):\n",
        "Class 0: 0.48\n",
        "Class 1: 0.44\n",
        "Class 2: 0.08\n",
        "\n",
        "Non-neutral distribution (C0/C0+C1): 0.520\n",
        "\n",
        "REPORT LRL1 C=100 T=0.4\n",
        "--------------------\n",
        "Accuracy: 0.5\n",
        "             precision    recall  f1-score   support\n",
        "\n",
        "        0.0       0.53      0.73      0.61       175\n",
        "        1.0       0.48      0.72      0.58       155\n",
        "        2.0       0.42      0.06      0.11       170\n",
        "\n",
        "avg / total       0.48      0.50      0.43       500\n",
        "\n",
        "\n",
        "Confusion Matrix\n",
        "128\t40\t7\n",
        "36\t111\t8\n",
        "79\t80\t11\n",
        "\n",
        "Distribution (%):\n",
        "Class 0: 0.49\n",
        "Class 1: 0.46\n",
        "Class 2: 0.05\n",
        "\n",
        "Non-neutral distribution (C0/C0+C1): 0.513\n",
        "None\n"
       ]
      }
     ],
     "prompt_number": 323
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Test LRL2 documents\n",
      "C = [pow(10,x) for x in range(-1,3)]\n",
      "results = test_parameters(\"LogisticRegression(penalty='l2', C={})\", C, imdb.test, .35 )\n",
      "print print_report(user_labels, results, C, .35, name=\"lrl2\")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Parameters for LogisticRegression(penalty='l2', C={}) and T > 0.35\n",
        "Testing ... C= 0.1\n",
        "Testing ... C="
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 1\n",
        "Testing ... C="
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 10\n",
        "Testing ... C="
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 100\n",
        "\n",
        "REPORT LRL2 C=0.1 T=0.35"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "--------------------\n",
        "Accuracy: 0.512\n",
        "             precision    recall  f1-score   support\n",
        "\n",
        "        0.0       0.71      0.31      0.43       175\n",
        "        1.0       0.71      0.37      0.49       155\n",
        "        2.0       0.42      0.84      0.56       170\n",
        "\n",
        "avg / total       0.61      0.51      0.49       500\n",
        "\n",
        "\n",
        "Confusion Matrix\n",
        "55\t11\t109\n",
        "9\t58\t88\n",
        "14\t13\t143\n",
        "\n",
        "Distribution (%):\n",
        "Class 0: 0.16\n",
        "Class 1: 0.16\n",
        "Class 2: 0.68\n",
        "\n",
        "Non-neutral distribution (C0/C0+C1): 0.487\n",
        "\n",
        "REPORT LRL2 C=1 T=0.35\n",
        "--------------------\n",
        "Accuracy: 0.588\n",
        "             precision    recall  f1-score   support\n",
        "\n",
        "        0.0       0.66      0.66      0.66       175\n",
        "        1.0       0.59      0.61      0.60       155\n",
        "        2.0       0.51      0.50      0.50       170\n",
        "\n",
        "avg / total       0.59      0.59      0.59       500\n",
        "\n",
        "\n",
        "Confusion Matrix\n",
        "115\t21\t39\n",
        "18\t94\t43\n",
        "42\t43\t85\n",
        "\n",
        "Distribution (%):\n",
        "Class 0: 0.35\n",
        "Class 1: 0.32\n",
        "Class 2: 0.33\n",
        "\n",
        "Non-neutral distribution (C0/C0+C1): 0.526\n",
        "\n",
        "REPORT LRL2 C=10 T=0.35\n",
        "--------------------\n",
        "Accuracy: 0.556\n",
        "             precision    recall  f1-score   support\n",
        "\n",
        "        0.0       0.59      0.74      0.66       175\n",
        "        1.0       0.54      0.65      0.59       155\n",
        "        2.0       0.50      0.28      0.36       170\n",
        "\n",
        "avg / total       0.55      0.56      0.54       500\n",
        "\n",
        "\n",
        "Confusion Matrix\n",
        "130\t26\t19\n",
        "26\t100\t29\n",
        "63\t59\t48\n",
        "\n",
        "Distribution (%):\n",
        "Class 0: 0.44\n",
        "Class 1: 0.37\n",
        "Class 2: 0.19\n",
        "\n",
        "Non-neutral distribution (C0/C0+C1): 0.542\n",
        "\n",
        "REPORT LRL2 C=100 T=0.35\n",
        "--------------------\n",
        "Accuracy: 0.502\n",
        "             precision    recall  f1-score   support\n",
        "\n",
        "        0.0       0.53      0.74      0.62       175\n",
        "        1.0       0.50      0.66      0.57       155\n",
        "        2.0       0.37      0.11      0.17       170\n",
        "\n",
        "avg / total       0.47      0.50      0.45       500\n",
        "\n",
        "\n",
        "Confusion Matrix\n",
        "129\t29\t17\n",
        "37\t103\t15\n",
        "77\t74\t19\n",
        "\n",
        "Distribution (%):\n",
        "Class 0: 0.49\n",
        "Class 1: 0.41\n",
        "Class 2: 0.10\n",
        "\n",
        "Non-neutral distribution (C0/C0+C1): 0.541\n",
        "None\n"
       ]
      }
     ],
     "prompt_number": 325
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Test LRL2 documents\n",
      "C = [pow(10,x) for x in range(-2,3)]\n",
      "\n",
      "results = test_parameters(\"LogisticRegression(penalty='l2', C={})\", C, imdb.test, .4 )\n",
      "print print_report(user_labels, results, C, .4, name=\"lrl2\")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Parameters for LogisticRegression(penalty='l2', C={}) and T > 0.4\n",
        "Testing ... C= 0.01\n",
        "Testing ... C="
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 0.1\n",
        "Testing ... C="
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 1\n",
        "Testing ... C="
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 10\n",
        "Testing ... C="
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 100\n",
        "\n",
        "REPORT LRL2 C=0.01 T=0.4"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "--------------------\n",
        "Accuracy: 0.354\n",
        "             precision    recall  f1-score   support\n",
        "\n",
        "        0.0       0.83      0.03      0.06       175\n",
        "        1.0       1.00      0.02      0.04       155\n",
        "        2.0       0.34      0.99      0.51       170\n",
        "\n",
        "avg / total       0.72      0.35      0.20       500\n",
        "\n",
        "\n",
        "Confusion Matrix\n",
        "5\t0\t170\n",
        "0\t3\t152\n",
        "1\t0\t169\n",
        "\n",
        "Distribution (%):\n",
        "Class 0: 0.01\n",
        "Class 1: 0.01\n",
        "Class 2: 0.98\n",
        "\n",
        "Non-neutral distribution (C0/C0+C1): 0.667\n",
        "\n",
        "REPORT LRL2 C=0.1 T=0.4\n",
        "--------------------\n",
        "Accuracy: 0.536\n",
        "             precision    recall  f1-score   support\n",
        "\n",
        "        0.0       0.68      0.41      0.51       175\n",
        "        1.0       0.61      0.54      0.57       155\n",
        "        2.0       0.44      0.66      0.53       170\n",
        "\n",
        "avg / total       0.58      0.54      0.54       500\n",
        "\n",
        "\n",
        "Confusion Matrix\n",
        "71\t18\t86\n",
        "12\t84\t59\n",
        "21\t36\t113\n",
        "\n",
        "Distribution (%):\n",
        "Class 0: 0.21\n",
        "Class 1: 0.28\n",
        "Class 2: 0.52\n",
        "\n",
        "Non-neutral distribution (C0/C0+C1): 0.430\n",
        "\n",
        "REPORT LRL2 C=1 T=0.4\n",
        "--------------------\n",
        "Accuracy: 0.566\n",
        "             precision    recall  f1-score   support\n",
        "\n",
        "        0.0       0.61      0.70      0.66       175\n",
        "        1.0       0.55      0.66      0.60       155\n",
        "        2.0       0.50      0.34      0.40       170\n",
        "\n",
        "avg / total       0.56      0.57      0.55       500\n",
        "\n",
        "\n",
        "Confusion Matrix\n",
        "123\t26\t26\n",
        "21\t103\t31\n",
        "56\t57\t57\n",
        "\n",
        "Distribution (%):\n",
        "Class 0: 0.40\n",
        "Class 1: 0.37\n",
        "Class 2: 0.23\n",
        "\n",
        "Non-neutral distribution (C0/C0+C1): 0.518\n",
        "\n",
        "REPORT LRL2 C=10 T=0.4\n",
        "--------------------\n",
        "Accuracy: 0.532\n",
        "             precision    recall  f1-score   support\n",
        "\n",
        "        0.0       0.56      0.75      0.64       175\n",
        "        1.0       0.52      0.67      0.59       155\n",
        "        2.0       0.47      0.18      0.26       170\n",
        "\n",
        "avg / total       0.52      0.53      0.50       500\n",
        "\n",
        "\n",
        "Confusion Matrix\n",
        "131\t29\t15\n",
        "31\t104\t20\n",
        "72\t67\t31\n",
        "\n",
        "Distribution (%):\n",
        "Class 0: 0.47\n",
        "Class 1: 0.40\n",
        "Class 2: 0.13\n",
        "\n",
        "Non-neutral distribution (C0/C0+C1): 0.539\n",
        "\n",
        "REPORT LRL2 C=100 T=0.4\n",
        "--------------------\n",
        "Accuracy: 0.504\n",
        "             precision    recall  f1-score   support\n",
        "\n",
        "        0.0       0.53      0.76      0.62       175\n",
        "        1.0       0.49      0.68      0.57       155\n",
        "        2.0       0.41      0.08      0.13       170\n",
        "\n",
        "avg / total       0.47      0.50      0.44       500\n",
        "\n",
        "\n",
        "Confusion Matrix\n",
        "133\t33\t9\n",
        "39\t106\t10\n",
        "80\t77\t13\n",
        "\n",
        "Distribution (%):\n",
        "Class 0: 0.50\n",
        "Class 1: 0.43\n",
        "Class 2: 0.06\n",
        "\n",
        "Non-neutral distribution (C0/C0+C1): 0.538\n",
        "None\n"
       ]
      }
     ],
     "prompt_number": 332
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Test MNB sentences\n",
      "from sklearn.naive_bayes import MultinomialNB\n",
      "C = [1, 2]\n",
      "results = test_parameters(\"MultinomialNB(alpha={})\", C, imdb.test, .42 )\n",
      "print print_report(user_labels, results, C, .42, name=\"MNB\")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Parameters for MultinomialNB(alpha={}) and T > 0.42\n",
        "Testing ... C= 1\n",
        "Testing ... C= 2\n",
        "\n",
        "REPORT MNB C=1 T=0.42"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "--------------------\n",
        "Accuracy: 0.518\n",
        "             precision    recall  f1-score   support\n",
        "\n",
        "        0.0       0.62      0.61      0.61       175\n",
        "        1.0       0.55      0.49      0.52       155\n",
        "        2.0       0.40      0.45      0.43       170\n",
        "\n",
        "avg / total       0.52      0.52      0.52       500\n",
        "\n",
        "\n",
        "Confusion Matrix\n",
        "106\t18\t51\n",
        "16\t76\t63\n",
        "48\t45\t77\n",
        "\n",
        "Distribution (%):\n",
        "Class 0: 0.34\n",
        "Class 1: 0.28\n",
        "Class 2: 0.38\n",
        "\n",
        "Non-neutral distribution (C0/C0+C1): 0.550\n",
        "\n",
        "REPORT MNB C=2 T=0.42\n",
        "--------------------\n",
        "Accuracy: 0.532\n",
        "             precision    recall  f1-score   support\n",
        "\n",
        "        0.0       0.64      0.60      0.62       175\n",
        "        1.0       0.57      0.48      0.52       155\n",
        "        2.0       0.42      0.51      0.46       170\n",
        "\n",
        "avg / total       0.54      0.53      0.54       500\n",
        "\n",
        "\n",
        "Confusion Matrix\n",
        "105\t15\t55\n",
        "16\t75\t64\n",
        "42\t42\t86\n",
        "\n",
        "Distribution (%):\n",
        "Class 0: 0.33\n",
        "Class 1: 0.26\n",
        "Class 2: 0.41\n",
        "\n",
        "Non-neutral distribution (C0/C0+C1): 0.553\n",
        "None\n"
       ]
      }
     ],
     "prompt_number": 336
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Test LRL2 sentences\n",
      "C = [pow(10,x) for x in range(-2,3)]\n",
      "results = test_parameters(\"LinearSVC(penalty='l1', C={})\", C, imdb.test, .45 )\n",
      "print print_report(user_labels, results, C, name=\"LinearSVC\")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Parameters for LinearSVC(penalty='l1', C={}) and T > 0.45\n",
        "Testing ... C= 0.01\n"
       ]
      },
      {
       "ename": "ValueError",
       "evalue": "Unsupported set of arguments: penalty='l1' is only supported when dual='false'., Parameters: penalty='l1', loss='l2', dual=True",
       "output_type": "pyerr",
       "traceback": [
        "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
        "\u001b[0;32m<ipython-input-326-1ef82aae8224>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Test LRL2 sentences\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mC\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mpow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest_parameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"LinearSVC(penalty='l1', C={})\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mC\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimdb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m.45\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;32mprint\u001b[0m \u001b[0mprint_report\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muser_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mC\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"LinearSVC\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;32m<ipython-input-215-bc3ebf4544a1>\u001b[0m in \u001b[0;36mtest_parameters\u001b[0;34m(clf_str, C, data, threshold, name)\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0;32mprint\u001b[0m \u001b[0;34m\"Testing ... C=\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;31m#         expert = exputil.get_classifier('lrl2', parameter=c)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m         \u001b[0mexpert\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclf_str\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m         \u001b[0mexpert\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'bow'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'target'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mexpert\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msnip_bow\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;32m<string>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n",
        "\u001b[0;32m/opt/local/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/site-packages/sklearn/svm/classes.pyc\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, penalty, loss, dual, tol, C, multi_class, fit_intercept, intercept_scaling, class_weight, verbose, random_state)\u001b[0m\n\u001b[1;32m    140\u001b[0m             \u001b[0mintercept_scaling\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mintercept_scaling\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m             \u001b[0mclass_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 142\u001b[0;31m             random_state=random_state)\n\u001b[0m\u001b[1;32m    143\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    144\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;32m/opt/local/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/site-packages/sklearn/svm/base.pyc\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, penalty, loss, dual, tol, C, multi_class, fit_intercept, intercept_scaling, class_weight, verbose, random_state)\u001b[0m\n\u001b[1;32m    617\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    618\u001b[0m         \u001b[0;31m# Check that the arguments given are valid:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 619\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_solver_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    620\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    621\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_get_solver_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;32m/opt/local/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/site-packages/sklearn/svm/base.pyc\u001b[0m in \u001b[0;36m_get_solver_type\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    651\u001b[0m                              \u001b[0;34m'Parameters: penalty=%r, loss=%r, dual=%r'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    652\u001b[0m                              % (error_string, self.penalty,\n\u001b[0;32m--> 653\u001b[0;31m                                 self.loss, self.dual))\n\u001b[0m\u001b[1;32m    654\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_solver_type_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msolver_type\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    655\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;31mValueError\u001b[0m: Unsupported set of arguments: penalty='l1' is only supported when dual='false'., Parameters: penalty='l1', loss='l2', dual=True"
       ]
      }
     ],
     "prompt_number": 326
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "---------------\n",
      "# Test with User Defined Dictionary\n",
      "\n",
      "From Prof. Bilgic description: \n",
      "\n",
      "Picked relevant terms for IMDB by hand. I did not go through all 27K words, but instead I trained a classifier that is not highly regularized, printed the words and weights and went through most of the non-zero weighted words (+ words that looked similar to those and many words that start with un- and dis-, etc) and created a dictionary. \n",
      "\n",
      "*  Train an expert on the test using the attached dictionary\n",
      "*  Predict the labels of the sentences in the user study and \n",
      "*  See if it gives a better model of the user than the classifiers that use all 27K words.\n",
      "\n",
      "Dictionary: ./dictoinary.txt\n"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Create a vectorizer and get feature vector representation\n",
      "from sklearn.feature_extraction.text import  TfidfVectorizer\n",
      "\n",
      "vocab = open(\"../../data/vocab.txt\").readlines()\n",
      "vocab = np.array([x.strip() for x in vocab])\n",
      "\n",
      "\n",
      "print \"Dictionary size:\", len(vocab)\n",
      "\n",
      "#Create vectorizer and fit \n",
      "vct_dict = TfidfVectorizer(encoding='ISO-8859-1', min_df=5, max_df=1.0, binary=False, ngram_range=(1, 1), vocabulary=vocab)\n",
      "vct_dict.fit(imdb.train.data)\n",
      "exp_fix_bow = vct_dict.transform(exp_sent)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Dictionary size: 878\n"
       ]
      }
     ],
     "prompt_number": 337
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "\n",
      "## Testing User Defined Dictionary: Training on Sentences\n",
      "\n",
      "\n",
      "Sentence data to train the expert: exp_sent, exp_lbl \n",
      "\n",
      "### Configuration of the Experiment\n",
      "\n",
      "* Two classifier L1 and L2, \n",
      "* Training documents: sentences and documents to train the expert.\n",
      "* C: 1 \u2026 10^5\n",
      "* Thresholds: .4, .45, .5 (no neutrals)\n",
      "* Vectorizer trained on train split but with a fixed vocabulary \n"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def test_parameters2(clf_str, C, data, threshold, snip_bow, name=\"noname\"):\n",
      "    # print predicted values of the expert on the study snippets\n",
      "    print \"Parameters for %s and T > %s\" %(clf_str, threshold)\n",
      "    results = defaultdict(lambda: [])\n",
      "    for c in C: \n",
      "        print \"Testing ... C=\", c, \"T=\", threshold\n",
      "        expert = eval(clf_str.format(c))\n",
      "        expert.fit(data['bow'], data['target'])\n",
      "        pred = expert.predict(snip_bow)\n",
      "        prob = expert.predict_proba(snip_bow)\n",
      "        \n",
      "        results[c] = [neutral_label(threshold, p, t) for t, p in zip(pred,prob)]\n",
      "    return results\n",
      "\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 338
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Fixed Dictionary: Training on Sentences\n",
      "\n",
      "Here the result of the test shows that the expert classifies everything as class 0 with a high uncertanty. The expert is not able to learn any classes. "
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Test LRL2 sentences\n",
      "C = [pow(10,x) for x in range(1,8)]\n",
      "snip_dict = vct_dict.transform(snippets)\n",
      "data2 = {'bow':exp_fix_bow, 'target':exp_lbl}\n",
      "results = test_parameters2(\"LogisticRegression(penalty='l2', C={})\", C, data2, .4, snip_dict)\n",
      "print print_report(user_labels, results, C, .4, name=\"lrl2\")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Parameters for LogisticRegression(penalty='l2', C={}) and T > 0.4\n",
        "Testing ... C= 10 T= 0.4\n",
        "Testing ... C="
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 100 T= 0.4\n",
        "Testing ... C="
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 1000 T= 0.4\n",
        "Testing ... C="
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 10000 T= 0.4\n",
        "Testing ... C="
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 100000 T= 0.4\n",
        "Testing ... C="
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 1000000 T= 0.4\n",
        "Testing ... C="
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 10000000 T= 0.4\n",
        "\n",
        "REPORT LRL2 C=10 T=0.4"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "--------------------\n",
        "Accuracy: 0.63\n",
        "             precision    recall  f1-score   support\n",
        "\n",
        "        0.0       0.71      0.62      0.66       175\n",
        "        1.0       0.72      0.50      0.59       155\n",
        "        2.0       0.54      0.76      0.63       170\n",
        "\n",
        "avg / total       0.65      0.63      0.63       500\n",
        "\n",
        "\n",
        "Confusion Matrix\n",
        "108\t15\t52\n",
        "20\t78\t57\n",
        "25\t16\t129\n",
        "\n",
        "Distribution (%):\n",
        "Class 0: 0.31\n",
        "Class 1: 0.22\n",
        "Class 2: 0.48\n",
        "\n",
        "Non-neutral distribution (C0/C0+C1): 0.584\n",
        "\n",
        "REPORT LRL2 C=100 T=0.4\n",
        "--------------------\n",
        "Accuracy: 0.63\n",
        "             precision    recall  f1-score   support\n",
        "\n",
        "        0.0       0.71      0.62      0.66       175\n",
        "        1.0       0.72      0.50      0.59       155\n",
        "        2.0       0.54      0.76      0.63       170\n",
        "\n",
        "avg / total       0.65      0.63      0.63       500\n",
        "\n",
        "\n",
        "Confusion Matrix\n",
        "108\t15\t52\n",
        "20\t78\t57\n",
        "25\t16\t129\n",
        "\n",
        "Distribution (%):\n",
        "Class 0: 0.31\n",
        "Class 1: 0.22\n",
        "Class 2: 0.48\n",
        "\n",
        "Non-neutral distribution (C0/C0+C1): 0.584\n",
        "\n",
        "REPORT LRL2 C=1000 T=0.4\n",
        "--------------------\n",
        "Accuracy: 0.63\n",
        "             precision    recall  f1-score   support\n",
        "\n",
        "        0.0       0.71      0.62      0.66       175\n",
        "        1.0       0.72      0.50      0.59       155\n",
        "        2.0       0.54      0.76      0.63       170\n",
        "\n",
        "avg / total       0.65      0.63      0.63       500\n",
        "\n",
        "\n",
        "Confusion Matrix\n",
        "108\t15\t52\n",
        "20\t78\t57\n",
        "25\t16\t129\n",
        "\n",
        "Distribution (%):\n",
        "Class 0: 0.31\n",
        "Class 1: 0.22\n",
        "Class 2: 0.48\n",
        "\n",
        "Non-neutral distribution (C0/C0+C1): 0.584\n",
        "\n",
        "REPORT LRL2 C=10000 T=0.4\n",
        "--------------------\n",
        "Accuracy: 0.63\n",
        "             precision    recall  f1-score   support\n",
        "\n",
        "        0.0       0.71      0.62      0.66       175\n",
        "        1.0       0.72      0.50      0.59       155\n",
        "        2.0       0.54      0.76      0.63       170\n",
        "\n",
        "avg / total       0.65      0.63      0.63       500\n",
        "\n",
        "\n",
        "Confusion Matrix\n",
        "108\t15\t52\n",
        "20\t78\t57\n",
        "25\t16\t129\n",
        "\n",
        "Distribution (%):\n",
        "Class 0: 0.31\n",
        "Class 1: 0.22\n",
        "Class 2: 0.48\n",
        "\n",
        "Non-neutral distribution (C0/C0+C1): 0.584\n",
        "\n",
        "REPORT LRL2 C=100000 T=0.4\n",
        "--------------------\n",
        "Accuracy: 0.63\n",
        "             precision    recall  f1-score   support\n",
        "\n",
        "        0.0       0.71      0.62      0.66       175\n",
        "        1.0       0.72      0.50      0.59       155\n",
        "        2.0       0.54      0.76      0.63       170\n",
        "\n",
        "avg / total       0.65      0.63      0.63       500\n",
        "\n",
        "\n",
        "Confusion Matrix\n",
        "108\t15\t52\n",
        "20\t78\t57\n",
        "25\t16\t129\n",
        "\n",
        "Distribution (%):\n",
        "Class 0: 0.31\n",
        "Class 1: 0.22\n",
        "Class 2: 0.48\n",
        "\n",
        "Non-neutral distribution (C0/C0+C1): 0.584\n",
        "\n",
        "REPORT LRL2 C=1000000 T=0.4\n",
        "--------------------\n",
        "Accuracy: 0.63\n",
        "             precision    recall  f1-score   support\n",
        "\n",
        "        0.0       0.71      0.62      0.66       175\n",
        "        1.0       0.72      0.50      0.59       155\n",
        "        2.0       0.54      0.76      0.63       170\n",
        "\n",
        "avg / total       0.65      0.63      0.63       500\n",
        "\n",
        "\n",
        "Confusion Matrix\n",
        "108\t15\t52\n",
        "20\t78\t57\n",
        "25\t16\t129\n",
        "\n",
        "Distribution (%):\n",
        "Class 0: 0.31\n",
        "Class 1: 0.22\n",
        "Class 2: 0.48\n",
        "\n",
        "Non-neutral distribution (C0/C0+C1): 0.584\n",
        "\n",
        "REPORT LRL2 C=10000000 T=0.4\n",
        "--------------------\n",
        "Accuracy: 0.63\n",
        "             precision    recall  f1-score   support\n",
        "\n",
        "        0.0       0.71      0.62      0.66       175\n",
        "        1.0       0.72      0.50      0.59       155\n",
        "        2.0       0.54      0.76      0.63       170\n",
        "\n",
        "avg / total       0.65      0.63      0.63       500\n",
        "\n",
        "\n",
        "Confusion Matrix\n",
        "108\t15\t52\n",
        "20\t78\t57\n",
        "25\t16\t129\n",
        "\n",
        "Distribution (%):\n",
        "Class 0: 0.31\n",
        "Class 1: 0.22\n",
        "Class 2: 0.48\n",
        "\n",
        "Non-neutral distribution (C0/C0+C1): 0.584\n",
        "None\n"
       ]
      }
     ],
     "prompt_number": 321
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Test LRL2 sentences\n",
      "C = [pow(10,x) for x in range(-1,5)]\n",
      "snip_dict = vct_dict.transform(snippets)\n",
      "data2 = {'bow':exp_fix_bow, 'target':exp_lbl}\n",
      "results = test_parameters2(\"LogisticRegression(penalty='l2', C={})\", C, data2, .48, snip_dict)\n",
      "print print_report(user_labels, results, C, .48, name=\"lrl2\")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Parameters for LogisticRegression(penalty='l2', C={}) and T > 0.48\n",
        "Testing ... C= 0.1 T= 0.48\n",
        "Testing ... C="
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 1 T= 0.48\n",
        "Testing ... C="
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 10 T= 0.48\n",
        "Testing ... C="
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 100 T= 0.48\n",
        "Testing ... C="
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 1000 T= 0.48\n",
        "Testing ... C="
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 10000 T= 0.48\n",
        "\n",
        "REPORT LRL2 C=0.1 T=0.48"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "--------------------\n",
        "Accuracy: 0.654\n",
        "             precision    recall  f1-score   support\n",
        "\n",
        "        0.0       0.65      0.67      0.66       175\n",
        "        1.0       0.70      0.57      0.63       155\n",
        "        2.0       0.62      0.72      0.67       170\n",
        "\n",
        "avg / total       0.66      0.65      0.65       500\n",
        "\n",
        "\n",
        "Confusion Matrix\n",
        "117\t19\t39\n",
        "32\t88\t35\n",
        "30\t18\t122\n",
        "\n",
        "Distribution (%):\n",
        "Class 0: 0.36\n",
        "Class 1: 0.25\n",
        "Class 2: 0.39\n",
        "\n",
        "Non-neutral distribution (C0/C0+C1): 0.589\n",
        "\n",
        "REPORT LRL2 C=1 T=0.48\n",
        "--------------------\n",
        "Accuracy: 0.646\n",
        "             precision    recall  f1-score   support\n",
        "\n",
        "        0.0       0.64      0.66      0.65       175\n",
        "        1.0       0.68      0.57      0.62       155\n",
        "        2.0       0.62      0.70      0.66       170\n",
        "\n",
        "avg / total       0.65      0.65      0.65       500\n",
        "\n",
        "\n",
        "Confusion Matrix\n",
        "116\t21\t38\n",
        "33\t88\t34\n",
        "31\t20\t119\n",
        "\n",
        "Distribution (%):\n",
        "Class 0: 0.36\n",
        "Class 1: 0.26\n",
        "Class 2: 0.38\n",
        "\n",
        "Non-neutral distribution (C0/C0+C1): 0.583\n",
        "\n",
        "REPORT LRL2 C=10 T=0.48\n",
        "--------------------\n",
        "Accuracy: 0.644\n",
        "             precision    recall  f1-score   support\n",
        "\n",
        "        0.0       0.64      0.66      0.65       175\n",
        "        1.0       0.68      0.57      0.62       155\n",
        "        2.0       0.62      0.69      0.66       170\n",
        "\n",
        "avg / total       0.65      0.64      0.64       500\n",
        "\n",
        "\n",
        "Confusion Matrix\n",
        "116\t21\t38\n",
        "33\t88\t34\n",
        "31\t21\t118\n",
        "\n",
        "Distribution (%):\n",
        "Class 0: 0.36\n",
        "Class 1: 0.26\n",
        "Class 2: 0.38\n",
        "\n",
        "Non-neutral distribution (C0/C0+C1): 0.581\n",
        "\n",
        "REPORT LRL2 C=100 T=0.48\n",
        "--------------------\n",
        "Accuracy: 0.644\n",
        "             precision    recall  f1-score   support\n",
        "\n",
        "        0.0       0.64      0.66      0.65       175\n",
        "        1.0       0.68      0.57      0.62       155\n",
        "        2.0       0.62      0.69      0.66       170\n",
        "\n",
        "avg / total       0.65      0.64      0.64       500\n",
        "\n",
        "\n",
        "Confusion Matrix\n",
        "116\t21\t38\n",
        "33\t88\t34\n",
        "31\t21\t118\n",
        "\n",
        "Distribution (%):\n",
        "Class 0: 0.36\n",
        "Class 1: 0.26\n",
        "Class 2: 0.38\n",
        "\n",
        "Non-neutral distribution (C0/C0+C1): 0.581\n",
        "\n",
        "REPORT LRL2 C=1000 T=0.48\n",
        "--------------------\n",
        "Accuracy: 0.644\n",
        "             precision    recall  f1-score   support\n",
        "\n",
        "        0.0       0.64      0.66      0.65       175\n",
        "        1.0       0.68      0.57      0.62       155\n",
        "        2.0       0.62      0.69      0.66       170\n",
        "\n",
        "avg / total       0.65      0.64      0.64       500\n",
        "\n",
        "\n",
        "Confusion Matrix\n",
        "116\t21\t38\n",
        "33\t88\t34\n",
        "31\t21\t118\n",
        "\n",
        "Distribution (%):\n",
        "Class 0: 0.36\n",
        "Class 1: 0.26\n",
        "Class 2: 0.38\n",
        "\n",
        "Non-neutral distribution (C0/C0+C1): 0.581\n",
        "\n",
        "REPORT LRL2 C=10000 T=0.48\n",
        "--------------------\n",
        "Accuracy: 0.644\n",
        "             precision    recall  f1-score   support\n",
        "\n",
        "        0.0       0.64      0.66      0.65       175\n",
        "        1.0       0.68      0.57      0.62       155\n",
        "        2.0       0.62      0.69      0.66       170\n",
        "\n",
        "avg / total       0.65      0.64      0.64       500\n",
        "\n",
        "\n",
        "Confusion Matrix\n",
        "116\t21\t38\n",
        "33\t88\t34\n",
        "31\t21\t118\n",
        "\n",
        "Distribution (%):\n",
        "Class 0: 0.36\n",
        "Class 1: 0.26\n",
        "Class 2: 0.38\n",
        "\n",
        "Non-neutral distribution (C0/C0+C1): 0.581\n",
        "None\n"
       ]
      }
     ],
     "prompt_number": 304
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Fixed Dictionary: Training on Documents\n",
      "\n"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "C = [pow(10,x) for x in range(-1,5)]\n",
      "snip_dict = vct_dict.transform(snippets)\n",
      "data = {'bow':vct_dict.transform(imdb.test.data), 'target':imdb.test.target}\n",
      "results = test_parameters2(\"LogisticRegression(penalty='l2', C={})\", C, data, .4, snip_dict)\n",
      "print print_report(user_labels, results, C, .4, name=\"lrl2\")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Parameters for LogisticRegression(penalty='l2', C={}) and T > 0.4\n",
        "Testing ... C= 0.1 T= 0.4\n",
        "Testing ... C="
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 1 T= 0.4\n",
        "Testing ... C="
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 10 T= 0.4\n",
        "Testing ... C="
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 100 T= 0.4\n",
        "Testing ... C="
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 1000 T= 0.4\n",
        "Testing ... C="
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 10000 T= 0.4\n",
        "\n",
        "REPORT LRL2 C=0.1 T=0.4"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "--------------------\n",
        "Accuracy: 0.624\n",
        "             precision    recall  f1-score   support\n",
        "\n",
        "        0.0       0.73      0.54      0.62       175\n",
        "        1.0       0.72      0.53      0.61       155\n",
        "        2.0       0.53      0.80      0.64       170\n",
        "\n",
        "avg / total       0.66      0.62      0.62       500\n",
        "\n",
        "\n",
        "Confusion Matrix\n",
        "94\t16\t65\n",
        "17\t82\t56\n",
        "18\t16\t136\n",
        "\n",
        "Distribution (%):\n",
        "Class 0: 0.26\n",
        "Class 1: 0.23\n",
        "Class 2: 0.51\n",
        "\n",
        "Non-neutral distribution (C0/C0+C1): 0.531\n",
        "\n",
        "REPORT LRL2 C=1 T=0.4\n",
        "--------------------\n",
        "Accuracy: 0.652\n",
        "             precision    recall  f1-score   support\n",
        "\n",
        "        0.0       0.72      0.59      0.65       175\n",
        "        1.0       0.71      0.57      0.64       155\n",
        "        2.0       0.58      0.78      0.67       170\n",
        "\n",
        "avg / total       0.67      0.65      0.65       500\n",
        "\n",
        "\n",
        "Confusion Matrix\n",
        "104\t19\t52\n",
        "21\t89\t45\n",
        "20\t17\t133\n",
        "\n",
        "Distribution (%):\n",
        "Class 0: 0.29\n",
        "Class 1: 0.25\n",
        "Class 2: 0.46\n",
        "\n",
        "Non-neutral distribution (C0/C0+C1): 0.537\n",
        "\n",
        "REPORT LRL2 C=10 T=0.4\n",
        "--------------------\n",
        "Accuracy: 0.646\n",
        "             precision    recall  f1-score   support\n",
        "\n",
        "        0.0       0.71      0.59      0.64       175\n",
        "        1.0       0.67      0.59      0.63       155\n",
        "        2.0       0.59      0.76      0.66       170\n",
        "\n",
        "avg / total       0.66      0.65      0.64       500\n",
        "\n",
        "\n",
        "Confusion Matrix\n",
        "103\t25\t47\n",
        "21\t91\t43\n",
        "21\t20\t129\n",
        "\n",
        "Distribution (%):\n",
        "Class 0: 0.29\n",
        "Class 1: 0.27\n",
        "Class 2: 0.44\n",
        "\n",
        "Non-neutral distribution (C0/C0+C1): 0.516\n",
        "\n",
        "REPORT LRL2 C=100 T=0.4\n",
        "--------------------\n",
        "Accuracy: 0.644\n",
        "             precision    recall  f1-score   support\n",
        "\n",
        "        0.0       0.71      0.59      0.64       175\n",
        "        1.0       0.67      0.59      0.63       155\n",
        "        2.0       0.59      0.75      0.66       170\n",
        "\n",
        "avg / total       0.65      0.64      0.64       500\n",
        "\n",
        "\n",
        "Confusion Matrix\n",
        "103\t25\t47\n",
        "21\t91\t43\n",
        "22\t20\t128\n",
        "\n",
        "Distribution (%):\n",
        "Class 0: 0.29\n",
        "Class 1: 0.27\n",
        "Class 2: 0.44\n",
        "\n",
        "Non-neutral distribution (C0/C0+C1): 0.518\n",
        "\n",
        "REPORT LRL2 C=1000 T=0.4\n",
        "--------------------\n",
        "Accuracy: 0.644\n",
        "             precision    recall  f1-score   support\n",
        "\n",
        "        0.0       0.71      0.59      0.64       175\n",
        "        1.0       0.67      0.59      0.63       155\n",
        "        2.0       0.59      0.75      0.66       170\n",
        "\n",
        "avg / total       0.65      0.64      0.64       500\n",
        "\n",
        "\n",
        "Confusion Matrix\n",
        "103\t25\t47\n",
        "21\t91\t43\n",
        "22\t20\t128\n",
        "\n",
        "Distribution (%):\n",
        "Class 0: 0.29\n",
        "Class 1: 0.27\n",
        "Class 2: 0.44\n",
        "\n",
        "Non-neutral distribution (C0/C0+C1): 0.518\n",
        "\n",
        "REPORT LRL2 C=10000 T=0.4\n",
        "--------------------\n",
        "Accuracy: 0.644\n",
        "             precision    recall  f1-score   support\n",
        "\n",
        "        0.0       0.71      0.59      0.64       175\n",
        "        1.0       0.67      0.59      0.63       155\n",
        "        2.0       0.59      0.75      0.66       170\n",
        "\n",
        "avg / total       0.65      0.64      0.64       500\n",
        "\n",
        "\n",
        "Confusion Matrix\n",
        "103\t25\t47\n",
        "21\t91\t43\n",
        "22\t20\t128\n",
        "\n",
        "Distribution (%):\n",
        "Class 0: 0.29\n",
        "Class 1: 0.27\n",
        "Class 2: 0.44\n",
        "\n",
        "Non-neutral distribution (C0/C0+C1): 0.518\n",
        "None\n"
       ]
      }
     ],
     "prompt_number": 305
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "C = [pow(10,x) for x in range(-1,5)]\n",
      "snip_dict = vct_dict.transform(snippets)\n",
      "data = {'bow':vct_dict.transform(imdb.test.data), 'target':imdb.test.target}\n",
      "results = test_parameters2(\"LogisticRegression(penalty='l2', C={})\", C, data, .48, snip_dict)\n",
      "print print_report(user_labels, results, C, .48, name=\"lrl2\")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Parameters for LogisticRegression(penalty='l2', C={}) and T > 0.48\n",
        "Testing ... C= 0.1 T= 0.48\n",
        "Testing ... C="
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 1 T= 0.48\n",
        "Testing ... C="
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 10 T= 0.48\n",
        "Testing ... C="
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 100 T= 0.48\n",
        "Testing ... C="
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 1000 T= 0.48\n",
        "Testing ... C="
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 10000 T= 0.48\n",
        "\n",
        "REPORT LRL2 C=0.1 T=0.48"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "--------------------\n",
        "Accuracy: 0.648\n",
        "             precision    recall  f1-score   support\n",
        "\n",
        "        0.0       0.67      0.66      0.67       175\n",
        "        1.0       0.69      0.57      0.62       155\n",
        "        2.0       0.60      0.71      0.65       170\n",
        "\n",
        "avg / total       0.65      0.65      0.65       500\n",
        "\n",
        "\n",
        "Confusion Matrix\n",
        "116\t20\t39\n",
        "27\t88\t40\n",
        "30\t20\t120\n",
        "\n",
        "Distribution (%):\n",
        "Class 0: 0.35\n",
        "Class 1: 0.26\n",
        "Class 2: 0.40\n",
        "\n",
        "Non-neutral distribution (C0/C0+C1): 0.575\n",
        "\n",
        "REPORT LRL2 C=1 T=0.48\n",
        "--------------------\n",
        "Accuracy: 0.646\n",
        "             precision    recall  f1-score   support\n",
        "\n",
        "        0.0       0.65      0.66      0.65       175\n",
        "        1.0       0.66      0.60      0.63       155\n",
        "        2.0       0.63      0.68      0.65       170\n",
        "\n",
        "avg / total       0.65      0.65      0.65       500\n",
        "\n",
        "\n",
        "Confusion Matrix\n",
        "115\t25\t35\n",
        "30\t93\t32\n",
        "32\t23\t115\n",
        "\n",
        "Distribution (%):\n",
        "Class 0: 0.35\n",
        "Class 1: 0.28\n",
        "Class 2: 0.36\n",
        "\n",
        "Non-neutral distribution (C0/C0+C1): 0.557\n",
        "\n",
        "REPORT LRL2 C=10 T=0.48\n",
        "--------------------\n",
        "Accuracy: 0.48\n",
        "             precision    recall  f1-score   support\n",
        "\n",
        "        0.0       0.65      0.66      0.65       175\n",
        "        1.0       0.39      0.80      0.52       155\n",
        "        2.0       0.20      0.01      0.01       170\n",
        "\n",
        "avg / total       0.42      0.48      0.40       500\n",
        "\n",
        "\n",
        "Confusion Matrix\n",
        "115\t58\t2\n",
        "29\t124\t2\n",
        "33\t136\t1\n",
        "\n",
        "Distribution (%):\n",
        "Class 0: 0.35\n",
        "Class 1: 0.64\n",
        "Class 2: 0.01\n",
        "\n",
        "Non-neutral distribution (C0/C0+C1): 0.358\n",
        "\n",
        "REPORT LRL2 C=100 T=0.48\n",
        "--------------------\n",
        "Accuracy: 0.48\n",
        "             precision    recall  f1-score   support\n",
        "\n",
        "        0.0       0.65      0.66      0.66       175\n",
        "        1.0       0.39      0.80      0.52       155\n",
        "        2.0       0.17      0.01      0.01       170\n",
        "\n",
        "avg / total       0.41      0.48      0.40       500\n",
        "\n",
        "\n",
        "Confusion Matrix\n",
        "115\t58\t2\n",
        "28\t124\t3\n",
        "33\t136\t1\n",
        "\n",
        "Distribution (%):\n",
        "Class 0: 0.35\n",
        "Class 1: 0.64\n",
        "Class 2: 0.01\n",
        "\n",
        "Non-neutral distribution (C0/C0+C1): 0.356\n",
        "\n",
        "REPORT LRL2 C=1000 T=0.48\n",
        "--------------------\n",
        "Accuracy: 0.48\n",
        "             precision    recall  f1-score   support\n",
        "\n",
        "        0.0       0.65      0.66      0.66       175\n",
        "        1.0       0.39      0.80      0.52       155\n",
        "        2.0       0.17      0.01      0.01       170\n",
        "\n",
        "avg / total       0.41      0.48      0.40       500\n",
        "\n",
        "\n",
        "Confusion Matrix\n",
        "115\t58\t2\n",
        "28\t124\t3\n",
        "33\t136\t1\n",
        "\n",
        "Distribution (%):\n",
        "Class 0: 0.35\n",
        "Class 1: 0.64\n",
        "Class 2: 0.01\n",
        "\n",
        "Non-neutral distribution (C0/C0+C1): 0.356\n",
        "\n",
        "REPORT LRL2 C=10000 T=0.48\n",
        "--------------------\n",
        "Accuracy: 0.48\n",
        "             precision    recall  f1-score   support\n",
        "\n",
        "        0.0       0.65      0.66      0.66       175\n",
        "        1.0       0.39      0.80      0.52       155\n",
        "        2.0       0.17      0.01      0.01       170\n",
        "\n",
        "avg / total       0.41      0.48      0.40       500\n",
        "\n",
        "\n",
        "Confusion Matrix\n",
        "115\t58\t2\n",
        "28\t124\t3\n",
        "33\t136\t1\n",
        "\n",
        "Distribution (%):\n",
        "Class 0: 0.35\n",
        "Class 1: 0.64\n",
        "Class 2: 0.01\n",
        "\n",
        "Non-neutral distribution (C0/C0+C1): 0.356\n",
        "None\n"
       ]
      }
     ],
     "prompt_number": 306
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "data = {'bow':vct_dict.transform(imdb.test.data), 'target':imdb.test.target}\n",
      "results = test_parameters2(\"LogisticRegression(penalty='l1', C={})\", C, data, .475, snip_dict)\n",
      "print print_report(user_labels, results, C,.475, name=\"LRL1\")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Parameters for LogisticRegression(penalty='l1', C={}) and T > 0.475\n",
        "Testing ... C= 0.1 T= 0.475\n",
        "Testing ... C="
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 1 T= 0.475\n",
        "Testing ... C="
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 10 T= 0.475\n",
        "Testing ... C="
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 100 T= 0.475\n",
        "Testing ... C="
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 1000 T= 0.475\n",
        "Testing ... C="
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 10000 T= 0.475\n",
        "\n",
        "REPORT MNB C=0.1 T=0.475"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "--------------------\n",
        "Accuracy: 0.608\n",
        "             precision    recall  f1-score   support\n",
        "\n",
        "        0.0       0.66      0.55      0.60       175\n",
        "        1.0       0.67      0.53      0.59       155\n",
        "        2.0       0.54      0.74      0.62       170\n",
        "\n",
        "avg / total       0.62      0.61      0.61       500\n",
        "\n",
        "\n",
        "Confusion Matrix\n",
        "97\t20\t58\n",
        "25\t82\t48\n",
        "25\t20\t125\n",
        "\n",
        "Distribution (%):\n",
        "Class 0: 0.29\n",
        "Class 1: 0.24\n",
        "Class 2: 0.46\n",
        "\n",
        "Non-neutral distribution (C0/C0+C1): 0.546\n",
        "\n",
        "REPORT MNB C=1 T=0.475\n",
        "--------------------\n",
        "Accuracy: 0.64\n",
        "             precision    recall  f1-score   support\n",
        "\n",
        "        0.0       0.66      0.63      0.65       175\n",
        "        1.0       0.67      0.57      0.62       155\n",
        "        2.0       0.60      0.71      0.65       170\n",
        "\n",
        "avg / total       0.64      0.64      0.64       500\n",
        "\n",
        "\n",
        "Confusion Matrix\n",
        "111\t22\t42\n",
        "29\t88\t38\n",
        "28\t21\t121\n",
        "\n",
        "Distribution (%):\n",
        "Class 0: 0.34\n",
        "Class 1: 0.26\n",
        "Class 2: 0.40\n",
        "\n",
        "Non-neutral distribution (C0/C0+C1): 0.562\n",
        "\n",
        "REPORT MNB C=10 T=0.475\n",
        "--------------------\n",
        "Accuracy: 0.488\n",
        "             precision    recall  f1-score   support\n",
        "\n",
        "        0.0       0.70      0.62      0.66       175\n",
        "        1.0       0.39      0.81      0.53       155\n",
        "        2.0       0.41      0.06      0.11       170\n",
        "\n",
        "avg / total       0.51      0.49      0.43       500\n",
        "\n",
        "\n",
        "Confusion Matrix\n",
        "108\t58\t9\n",
        "23\t125\t7\n",
        "23\t136\t11\n",
        "\n",
        "Distribution (%):\n",
        "Class 0: 0.31\n",
        "Class 1: 0.64\n",
        "Class 2: 0.05\n",
        "\n",
        "Non-neutral distribution (C0/C0+C1): 0.326\n",
        "\n",
        "REPORT MNB C=100 T=0.475\n",
        "--------------------\n",
        "Accuracy: 0.48\n",
        "             precision    recall  f1-score   support\n",
        "\n",
        "        0.0       0.69      0.62      0.65       175\n",
        "        1.0       0.39      0.80      0.52       155\n",
        "        2.0       0.32      0.05      0.08       170\n",
        "\n",
        "avg / total       0.47      0.48      0.42       500\n",
        "\n",
        "\n",
        "Confusion Matrix\n",
        "108\t58\t9\n",
        "23\t124\t8\n",
        "26\t136\t8\n",
        "\n",
        "Distribution (%):\n",
        "Class 0: 0.31\n",
        "Class 1: 0.64\n",
        "Class 2: 0.05\n",
        "\n",
        "Non-neutral distribution (C0/C0+C1): 0.331\n",
        "\n",
        "REPORT MNB C=1000 T=0.475\n",
        "--------------------\n",
        "Accuracy: 0.48\n",
        "             precision    recall  f1-score   support\n",
        "\n",
        "        0.0       0.69      0.62      0.65       175\n",
        "        1.0       0.39      0.80      0.52       155\n",
        "        2.0       0.32      0.05      0.08       170\n",
        "\n",
        "avg / total       0.47      0.48      0.42       500\n",
        "\n",
        "\n",
        "Confusion Matrix\n",
        "108\t58\t9\n",
        "23\t124\t8\n",
        "26\t136\t8\n",
        "\n",
        "Distribution (%):\n",
        "Class 0: 0.31\n",
        "Class 1: 0.64\n",
        "Class 2: 0.05\n",
        "\n",
        "Non-neutral distribution (C0/C0+C1): 0.331\n",
        "\n",
        "REPORT MNB C=10000 T=0.475\n",
        "--------------------\n",
        "Accuracy: 0.48\n",
        "             precision    recall  f1-score   support\n",
        "\n",
        "        0.0       0.69      0.62      0.65       175\n",
        "        1.0       0.39      0.80      0.52       155\n",
        "        2.0       0.32      0.05      0.08       170\n",
        "\n",
        "avg / total       0.47      0.48      0.42       500\n",
        "\n",
        "\n",
        "Confusion Matrix\n",
        "108\t58\t9\n",
        "23\t124\t8\n",
        "26\t136\t8\n",
        "\n",
        "Distribution (%):\n",
        "Class 0: 0.31\n",
        "Class 1: 0.64\n",
        "Class 2: 0.05\n",
        "\n",
        "Non-neutral distribution (C0/C0+C1): 0.331\n",
        "None\n"
       ]
      }
     ],
     "prompt_number": 314
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn.naive_bayes import MultinomialNB\n",
      "print data['bow'].shape\n",
      "results = test_parameters2(\"MultinomialNB(alpha={})\", C, data, .475, snip_dict)\n",
      "print print_report(user_labels, results, C,.475, name=\"MNB\")\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "(25000, 721)\n",
        "Parameters for MultinomialNB(alpha={}) and T > 0.475\n",
        "Testing ... C= 0.1 T= 0.475\n",
        "Testing ... C= 1 T= 0.475\n",
        "Testing ... C= 10 T= 0.475\n",
        "Testing ... C= 100 T= 0.475\n",
        "Testing ... C= 1000 T= 0.475\n",
        "Testing ... C= 10000 T= 0.475\n",
        "\n",
        "REPORT MNB C=0.1 T=0.475"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "--------------------\n",
        "Accuracy: 0.644\n",
        "             precision    recall  f1-score   support\n",
        "\n",
        "        0.0       0.65      0.66      0.65       175\n",
        "        1.0       0.66      0.58      0.62       155\n",
        "        2.0       0.63      0.69      0.66       170\n",
        "\n",
        "avg / total       0.65      0.64      0.64       500\n",
        "\n",
        "\n",
        "Confusion Matrix\n",
        "115\t24\t36\n",
        "32\t90\t33\n",
        "31\t22\t117\n",
        "\n",
        "Distribution (%):\n",
        "Class 0: 0.36\n",
        "Class 1: 0.27\n",
        "Class 2: 0.37\n",
        "\n",
        "Non-neutral distribution (C0/C0+C1): 0.567\n",
        "\n",
        "REPORT MNB C=1 T=0.475\n",
        "--------------------\n",
        "Accuracy: 0.644\n",
        "             precision    recall  f1-score   support\n",
        "\n",
        "        0.0       0.65      0.66      0.65       175\n",
        "        1.0       0.66      0.58      0.62       155\n",
        "        2.0       0.63      0.69      0.66       170\n",
        "\n",
        "avg / total       0.65      0.64      0.64       500\n",
        "\n",
        "\n",
        "Confusion Matrix\n",
        "115\t24\t36\n",
        "32\t90\t33\n",
        "31\t22\t117\n",
        "\n",
        "Distribution (%):\n",
        "Class 0: 0.36\n",
        "Class 1: 0.27\n",
        "Class 2: 0.37\n",
        "\n",
        "Non-neutral distribution (C0/C0+C1): 0.567\n",
        "\n",
        "REPORT MNB C=10 T=0.475\n",
        "--------------------\n",
        "Accuracy: 0.648\n",
        "             precision    recall  f1-score   support\n",
        "\n",
        "        0.0       0.66      0.65      0.65       175\n",
        "        1.0       0.67      0.58      0.62       155\n",
        "        2.0       0.62      0.71      0.66       170\n",
        "\n",
        "avg / total       0.65      0.65      0.65       500\n",
        "\n",
        "\n",
        "Confusion Matrix\n",
        "113\t23\t39\n",
        "31\t90\t34\n",
        "27\t22\t121\n",
        "\n",
        "Distribution (%):\n",
        "Class 0: 0.34\n",
        "Class 1: 0.27\n",
        "Class 2: 0.39\n",
        "\n",
        "Non-neutral distribution (C0/C0+C1): 0.559\n",
        "\n",
        "REPORT MNB C=100 T=0.475\n",
        "--------------------\n",
        "Accuracy: 0.638\n",
        "             precision    recall  f1-score   support\n",
        "\n",
        "        0.0       0.67      0.62      0.64       175\n",
        "        1.0       0.70      0.55      0.62       155\n",
        "        2.0       0.58      0.74      0.65       170\n",
        "\n",
        "avg / total       0.65      0.64      0.64       500\n",
        "\n",
        "\n",
        "Confusion Matrix\n",
        "108\t18\t49\n",
        "27\t86\t42\n",
        "27\t18\t125\n",
        "\n",
        "Distribution (%):\n",
        "Class 0: 0.32\n",
        "Class 1: 0.24\n",
        "Class 2: 0.43\n",
        "\n",
        "Non-neutral distribution (C0/C0+C1): 0.570\n",
        "\n",
        "REPORT MNB C=1000 T=0.475\n",
        "--------------------\n",
        "Accuracy: 0.538\n",
        "             precision    recall  f1-score   support\n",
        "\n",
        "        0.0       0.74      0.37      0.49       175\n",
        "        1.0       0.75      0.34      0.47       155\n",
        "        2.0       0.44      0.89      0.59       170\n",
        "\n",
        "avg / total       0.64      0.54      0.52       500\n",
        "\n",
        "\n",
        "Confusion Matrix\n",
        "64\t10\t101\n",
        "12\t53\t90\n",
        "10\t8\t152\n",
        "\n",
        "Distribution (%):\n",
        "Class 0: 0.17\n",
        "Class 1: 0.14\n",
        "Class 2: 0.69\n",
        "\n",
        "Non-neutral distribution (C0/C0+C1): 0.548\n",
        "\n",
        "REPORT MNB C=10000 T=0.475\n",
        "--------------------\n",
        "Accuracy: 0.34\n",
        "             precision    recall  f1-score   support\n",
        "\n",
        "        0.0       0.00      0.00      0.00       175\n",
        "        1.0       0.00      0.00      0.00       155\n",
        "        2.0       0.34      1.00      0.51       170\n",
        "\n",
        "avg / total       0.12      0.34      0.17       500\n",
        "\n",
        "\n",
        "Confusion Matrix\n",
        "0\t0\t175\n",
        "0\t0\t155\n",
        "0\t0\t170\n",
        "\n",
        "Distribution (%):\n",
        "Class 0: 0.00\n",
        "Class 1: 0.00\n",
        "Class 2: 1.00\n",
        "Non-neutral distribution: N/A\n",
        "None\n"
       ]
      }
     ],
     "prompt_number": 318
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}