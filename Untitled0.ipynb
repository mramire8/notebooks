{
 "metadata": {
  "name": ""
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import sys\n",
      "import os\n",
      "sys.path.append(os.path.abspath('C:/cygwin/home/mramire8/python_code/structured'))\n",
      "sys.path.append(os.path.abspath('/Users/maru/MyCode/structured'))\n",
      "import utilities.experimentutils as exputil\n",
      "import learner\n",
      "import utilities.datautils as datautil\n",
      "import numpy as np\n",
      "import experiment.base as exp\n",
      "import nltk\n",
      "from sklearn import metrics\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 4
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "## Get the data ready\n",
      "imdb_path = 'C:/Users/mramire8/Documents/Research/Oracle confidence and Interruption/dataset/aclImdb/raw-data'\n",
      "# imdb_path = '/Users/maru/MyCode/data/imdb'\n",
      "\n",
      "rnd = np.random.RandomState(2345)\n",
      "clf = exputil.get_classifier('lrl2',parameter=1)\n",
      "expert = exputil.get_classifier('lrl2',parameter=1)\n",
      "vct = exputil.get_vectorizer({'vectorizer':\"tfidf\", 'limit':None, 'min_size':None})\n",
      "data = datautil.load_dataset('imdb', imdb_path, categories=None, rnd=5463, shuffle=True)\n",
      "data.train.data = np.array(data.train.data, dtype=object)\n",
      "data.test.data = np.array(data.test.data, dtype=object)\n",
      "data.train.bow = vct.fit_transform(data.train.data)\n",
      "data.test.bow = vct.transform(data.test.data)\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 5
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#Train the expert\n",
      "expert = exputil.get_classifier('lrl2',parameter=1)\n",
      "expert.fit(data.train.bow, data.train.target)\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 6,
       "text": [
        "LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
        "          intercept_scaling=1, penalty='l2', random_state=None, tol=0.0001)"
       ]
      }
     ],
     "prompt_number": 6
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "## Select N random documents from the test\n",
      "n = 1000\n",
      "rnd = np.random.RandomState(2345)\n",
      "# rnd_docs = rnd.choice(len(data.test.target), size = n, replace = False)\n",
      "# Select the bootstrap.\n",
      "data.train.remaining = rnd.permutation(len(data.train.target))\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 7
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "## Printing functions\n",
      "def print_distr(cm):\n",
      "    return \"\\t\".join([str(c) for c in cm.sum(0)])\n",
      "\n",
      "def print_cm(cm):\n",
      "    return \"\\n\".join([\"{}\\t{}\".format(*r) for r in cm])\n",
      "\n",
      "def test_dist(data, st, expert):\n",
      "    # Test\n",
      "    num_trials = 5\n",
      "    \n",
      "    #Get random document for testing (will not change over time)\n",
      "    test_idx = rnd.permutation(len(data.test.target))\n",
      "    n_test = 1000\n",
      "    \n",
      "    sentences = sent_tk.tokenize_sents(data.test.data[test_idx[:n_test]])\n",
      "    test_true = data.test.target[test_idx[:n_test]]\n",
      "    test_text = data.test.data[test_idx[:n_test]]\n",
      "    sent_len = np.array([len(s) for s in sentences])\n",
      "    \n",
      "    print \"Test Set\"\n",
      "    print \"Total Documents\", sent_len.shape[0]\n",
      "    print \"Total sentences:\", sent_len.sum()\n",
      "    \n",
      "    for t in range(num_trials):\n",
      "        train_idx = rnd.choice(len(data.train.target), 500, replace=False)\n",
      "    \n",
      "        print \"-\" * 40\n",
      "        print \"Trial \", t\n",
      "        print \n",
      "        #replace the calibration method of the student\n",
      "#         st._do_calibration = cal_method\n",
      "        \n",
      "        # Train a student on rnadom docs\n",
      "        st.fit(data.train.bow[train_idx], data.train.target[train_idx], doc_text=data.train.data[train_idx])\n",
      "        ## compute the max scoring snippet (with calibration)\n",
      "        _, snippet_text = st._compute_snippet(test_text)\n",
      "        \n",
      "        cms = np.zeros((2,2))\n",
      "        cme = np.zeros((2,2))\n",
      "        \n",
      "        for i, idx in enumerate(test_idx[:n_test]):\n",
      "            doc_i = []\n",
      "            bow = vct.transform(sentences[i])\n",
      "            pred = st.snippet_model.predict(bow)\n",
      "            exp_pred = expert.predict(bow)\n",
      "            true = [test_true[i]]*sent_len[i]\n",
      "            cms += metrics.confusion_matrix(true, pred, labels=[0,1])\n",
      "    \n",
      "            cme += metrics.confusion_matrix(true, exp_pred, labels=[0,1])\n",
      "            \n",
      "        print \"\\nAll sentences\"\n",
      "        print \"Num sentences:\", sent_len.sum()\n",
      "        print \"Student CM:\\n\", print_cm(cms)\n",
      "        print \"True dist.:\", cms.sum(1)\n",
      "        print \"St. distr :\", print_distr(cms)\n",
      "        print \"St. accu: {0:.3f}\".format(1. * (cms[0][0] + cms[1][1]) / cms.sum())\n",
      "        print \"Expert  CM:\\n\", print_cm(cme)\n",
      "        print \"Exp. distr:\", print_distr(cme)\n",
      "        print \"Exp. accu:{0:.3f}\".format(1. * (cme[0][0] + cme[1][1]) / cms.sum())\n",
      "                                         \n",
      "        bow = vct.transform(snippet_text)\n",
      "        pred = st.snippet_model.predict(bow)\n",
      "        exp_pred = expert.predict(bow)\n",
      "        cms = metrics.confusion_matrix(test_true, pred)\n",
      "        cme = metrics.confusion_matrix(test_true, exp_pred)\n",
      "        \n",
      "        print \"\\nSelected Sentences\"\n",
      "        print \"Num sentences:\", len(snippet_text)\n",
      "        print \"Student CM:\\n\", print_cm(cms)\n",
      "        print \"True dist.:\", cms.sum(1)\n",
      "        print \"St. distr :\", print_distr(cms)\n",
      "        print \"St. accu: %.3f\" % metrics.accuracy_score(test_true, pred)\n",
      "        print \"Expert  CM:\\n\", print_cm(cme)\n",
      "        print \"Exp. distr:\", print_distr(cme)\n",
      "        print \"Exp. accu: %.3f\" % metrics.accuracy_score(test_true, exp_pred)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 32
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "## Set the learner options \n",
      "sent_tk = nltk.data.load('tokenizers/punkt/english.pickle')\n",
      "st = learner.strategy.StructuredLearner(clf)\n",
      "st.set_sent_tokenizer(sent_tk)\n",
      "st.set_vct(vct)\n",
      "st.set_snippet_utility('sr')\n",
      "st.set_calibration_method(\"_no_calibrate\")\n",
      "\n",
      "test_dist(data, st, expert)\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "ename": "ValueError",
       "evalue": "X has 26570 features per sample; expecting 27316",
       "output_type": "pyerr",
       "traceback": [
        "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
        "\u001b[1;32m<ipython-input-30-eb86e1eebf72>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[0mst\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_calibration_method\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"_no_calibrate\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m \u001b[0mtest_dist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mst\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mexpert\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
        "\u001b[1;32m<ipython-input-29-f5a7579114b6>\u001b[0m in \u001b[0;36mtest_dist\u001b[1;34m(data, st, expert)\u001b[0m\n\u001b[0;32m     44\u001b[0m             \u001b[0mbow\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mvct\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msentences\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     45\u001b[0m             \u001b[0mpred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mst\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msnippet_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbow\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 46\u001b[1;33m             \u001b[0mexp_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mexpert\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbow\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     47\u001b[0m             \u001b[0mtrue\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mtest_true\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0msent_len\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     48\u001b[0m             \u001b[0mcms\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconfusion_matrix\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpred\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
        "\u001b[1;32mC:\\Python27\\lib\\site-packages\\sklearn\\linear_model\\base.pyc\u001b[0m in \u001b[0;36mpredict\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    213\u001b[0m             \u001b[0mPredicted\u001b[0m \u001b[1;32mclass\u001b[0m \u001b[0mlabel\u001b[0m \u001b[0mper\u001b[0m \u001b[0msample\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    214\u001b[0m         \"\"\"\n\u001b[1;32m--> 215\u001b[1;33m         \u001b[0mscores\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdecision_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    216\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mscores\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    217\u001b[0m             \u001b[0mindices\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mscores\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mint\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
        "\u001b[1;32mC:\\Python27\\lib\\site-packages\\sklearn\\linear_model\\base.pyc\u001b[0m in \u001b[0;36mdecision_function\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    194\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0mn_features\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    195\u001b[0m             raise ValueError(\"X has %d features per sample; expecting %d\"\n\u001b[1;32m--> 196\u001b[1;33m                              % (X.shape[1], n_features))\n\u001b[0m\u001b[0;32m    197\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    198\u001b[0m         scores = safe_sparse_dot(X, self.coef_.T,\n",
        "\u001b[1;31mValueError\u001b[0m: X has 26570 features per sample; expecting 27316"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Test Set\n",
        "Total Documents 1000\n",
        "Total sentences: 10733\n",
        "----------------------------------------\n",
        "Trial  0\n",
        "\n"
       ]
      }
     ],
     "prompt_number": 30
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "sraa_path = 'C:/Users/mramire8/Documents/Research/Oracle confidence and Interruption/dataset/sraa/sraa/sraa/partition1/data'\n",
      "sraa = datautil.load_dataset('sraa', sraa_path, categories=None, rnd=5463, shuffle=True)\n",
      "sraa.train.data = np.array(sraa.train.data, dtype=object)\n",
      "sraa.test.data = np.array(sraa.test.data, dtype=object)\n",
      "sraa.train.bow = vct.fit_transform(sraa.train.data)\n",
      "sraa.test.bow = vct.transform(sraa.test.data)\n",
      "sraa.train.remaining = rnd.permutation(len(sraa.train.target))\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 33
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "data.train.remaining = rnd.permutation(len(data.train.target))\n",
      "\n",
      "st_sraa = learner.strategy.StructuredLearner(clf)\n",
      "st_sraa.set_sent_tokenizer(sent_tk)\n",
      "st_sraa.set_vct(vct)\n",
      "st_sraa.set_snippet_utility('sr')\n",
      "st_sraa.set_calibration_method(\"_no_calibrate\")\n",
      "\n",
      "#Train the expert\n",
      "expert_sraa = exputil.get_classifier('lrl2',parameter=1)\n",
      "expert_sraa.fit(sraa.train.bow, sraa.train.target)\n",
      "\n",
      "\n",
      "test_dist(sraa,st_sraa, expert_sraa)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Test Set\n",
        "Total Documents 1000\n",
        "Total sentences: 10700\n",
        "----------------------------------------\n",
        "Trial  0\n",
        "\n",
        "\n",
        "All sentences"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Num sentences: 10700\n",
        "Student CM:\n",
        "4849.0\t848.0\n",
        "2068.0\t2935.0\n",
        "True dist.: [ 5697.  5003.]\n",
        "St. distr : 6917.0\t3783.0\n",
        "St. accu: 0.727\n",
        "Expert  CM:\n",
        "5451.0\t246.0\n",
        "2010.0\t2993.0\n",
        "Exp. distr: 7461.0\t3239.0\n",
        "Exp. accu:0.789\n",
        "\n",
        "Selected Sentences\n",
        "Num sentences: 1000\n",
        "Student CM:\n",
        "610\t9\n",
        "114\t267\n",
        "True dist.: [619 381]\n",
        "St. distr : 724\t276\n",
        "St. accu: 0.877\n",
        "Expert  CM:\n",
        "612\t7\n",
        "106\t275\n",
        "Exp. distr: 718\t282\n",
        "Exp. accu: 0.887\n",
        "----------------------------------------"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Trial  1\n",
        "\n",
        "\n",
        "All sentences"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Num sentences: 10700\n",
        "Student CM:\n",
        "5090.0\t607.0\n",
        "2364.0\t2639.0\n",
        "True dist.: [ 5697.  5003.]\n",
        "St. distr : 7454.0\t3246.0\n",
        "St. accu: 0.722\n",
        "Expert  CM:\n",
        "5451.0\t246.0\n",
        "2010.0\t2993.0\n",
        "Exp. distr: 7461.0\t3239.0\n",
        "Exp. accu:0.789\n",
        "\n",
        "Selected Sentences\n",
        "Num sentences: 1000\n",
        "Student CM:\n",
        "603\t16\n",
        "102\t279\n",
        "True dist.: [619 381]\n",
        "St. distr : 705\t295\n",
        "St. accu: 0.882\n",
        "Expert  CM:\n",
        "613\t6\n",
        "96\t285\n",
        "Exp. distr: 709\t291\n",
        "Exp. accu: 0.898\n",
        "----------------------------------------\n",
        "Trial  2\n",
        "\n",
        "\n",
        "All sentences"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Num sentences: 10700\n",
        "Student CM:\n",
        "5388.0\t309.0\n",
        "2898.0\t2105.0\n",
        "True dist.: [ 5697.  5003.]\n",
        "St. distr : 8286.0\t2414.0\n",
        "St. accu: 0.700\n",
        "Expert  CM:\n",
        "5451.0\t246.0\n",
        "2010.0\t2993.0\n",
        "Exp. distr: 7461.0\t3239.0\n",
        "Exp. accu:0.789\n",
        "\n",
        "Selected Sentences\n",
        "Num sentences: 1000\n",
        "Student CM:\n",
        "616\t3\n",
        "177\t204\n",
        "True dist.: [619 381]\n",
        "St. distr : 793\t207\n",
        "St. accu: 0.820\n",
        "Expert  CM:\n",
        "618\t1\n",
        "144\t237\n",
        "Exp. distr: 762\t238\n",
        "Exp. accu: 0.855\n",
        "----------------------------------------\n",
        "Trial  3\n",
        "\n",
        "\n",
        "All sentences"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Num sentences: 10700\n",
        "Student CM:\n",
        "5387.0\t310.0\n",
        "2873.0\t2130.0\n",
        "True dist.: [ 5697.  5003.]\n",
        "St. distr : 8260.0\t2440.0\n",
        "St. accu: 0.703\n",
        "Expert  CM:\n",
        "5451.0\t246.0\n",
        "2010.0\t2993.0\n",
        "Exp. distr: 7461.0\t3239.0\n",
        "Exp. accu:0.789\n",
        "\n",
        "Selected Sentences\n",
        "Num sentences: 1000\n",
        "Student CM:\n",
        "618\t1\n",
        "168\t213\n",
        "True dist.: [619 381]\n",
        "St. distr : 786\t214\n",
        "St. accu: 0.831\n",
        "Expert  CM:\n",
        "619\t0\n",
        "134\t247\n",
        "Exp. distr: 753\t247\n",
        "Exp. accu: 0.866\n",
        "----------------------------------------"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Trial  4\n",
        "\n",
        "\n",
        "All sentences"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Num sentences: 10700\n",
        "Student CM:\n",
        "4954.0\t743.0\n",
        "2197.0\t2806.0\n",
        "True dist.: [ 5697.  5003.]\n",
        "St. distr : 7151.0\t3549.0\n",
        "St. accu: 0.725\n",
        "Expert  CM:\n",
        "5451.0\t246.0\n",
        "2010.0\t2993.0\n",
        "Exp. distr: 7461.0\t3239.0\n",
        "Exp. accu:0.789\n",
        "\n",
        "Selected Sentences\n",
        "Num sentences: 1000\n",
        "Student CM:\n",
        "607\t12\n",
        "104\t277\n",
        "True dist.: [619 381]\n",
        "St. distr : 711\t289\n",
        "St. accu: 0.884\n",
        "Expert  CM:\n",
        "613\t6\n",
        "89\t292\n",
        "Exp. distr: 702\t298\n",
        "Exp. accu: 0.905\n"
       ]
      }
     ],
     "prompt_number": 34
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "st_sraa.set_calibration_method( 'zscores_rank')\n",
      "test_dist(sraa,st_sraa, expert_sraa)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Test Set\n",
        "Total Documents 1000\n",
        "Total sentences: 10707\n",
        "----------------------------------------\n",
        "Trial  0\n",
        "\n",
        "\n",
        "All sentences"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Num sentences: 10707\n",
        "Student CM:\n",
        "6506.0\t239.0\n",
        "2268.0\t1694.0\n",
        "True dist.: [ 6745.  3962.]\n",
        "St. distr : 8774.0\t1933.0\n",
        "St. accu: 0.766\n",
        "Expert  CM:\n",
        "6502.0\t243.0\n",
        "1560.0\t2402.0\n",
        "Exp. distr: 8062.0\t2645.0\n",
        "Exp. accu:0.832\n",
        "\n",
        "Selected Sentences\n",
        "Num sentences: 1000\n",
        "Student CM:\n",
        "574\t54\n",
        "68\t304\n",
        "True dist.: [628 372]\n",
        "St. distr : 642\t358\n",
        "St. accu: 0.878\n",
        "Expert  CM:\n",
        "606\t22\n",
        "58\t314\n",
        "Exp. distr: 664\t336\n",
        "Exp. accu: 0.920\n",
        "----------------------------------------"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Trial  1\n",
        "\n",
        "\n",
        "All sentences"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Num sentences: 10707\n",
        "Student CM:\n",
        "5608.0\t1137.0\n",
        "1658.0\t2304.0\n",
        "True dist.: [ 6745.  3962.]\n",
        "St. distr : 7266.0\t3441.0\n",
        "St. accu: 0.739\n",
        "Expert  CM:\n",
        "6502.0\t243.0\n",
        "1560.0\t2402.0\n",
        "Exp. distr: 8062.0\t2645.0\n",
        "Exp. accu:0.832\n",
        "\n",
        "Selected Sentences\n",
        "Num sentences: 1000\n",
        "Student CM:\n",
        "562\t66\n",
        "45\t327\n",
        "True dist.: [628 372]\n",
        "St. distr : 607\t393\n",
        "St. accu: 0.889\n",
        "Expert  CM:\n",
        "602\t26\n",
        "56\t316\n",
        "Exp. distr: 658\t342\n",
        "Exp. accu: 0.918\n",
        "----------------------------------------"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Trial  2\n",
        "\n",
        "\n",
        "All sentences"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Num sentences: 10707\n",
        "Student CM:\n",
        "6644.0\t101.0\n",
        "2761.0\t1201.0\n",
        "True dist.: [ 6745.  3962.]\n",
        "St. distr : 9405.0\t1302.0\n",
        "St. accu: 0.733\n",
        "Expert  CM:\n",
        "6502.0\t243.0\n",
        "1560.0\t2402.0\n",
        "Exp. distr: 8062.0\t2645.0\n",
        "Exp. accu:0.832\n",
        "\n",
        "Selected Sentences\n",
        "Num sentences: 1000\n",
        "Student CM:\n",
        "600\t28\n",
        "75\t297\n",
        "True dist.: [628 372]\n",
        "St. distr : 675\t325\n",
        "St. accu: 0.897"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Expert  CM:\n",
        "611\t17\n",
        "43\t329\n",
        "Exp. distr: 654\t346\n",
        "Exp. accu: 0.940\n",
        "----------------------------------------\n",
        "Trial  3\n",
        "\n",
        "\n",
        "All sentences"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Num sentences: 10707\n",
        "Student CM:\n",
        "6642.0\t103.0\n",
        "2675.0\t1287.0\n",
        "True dist.: [ 6745.  3962.]\n",
        "St. distr : 9317.0\t1390.0\n",
        "St. accu: 0.741\n",
        "Expert  CM:\n",
        "6502.0\t243.0\n",
        "1560.0\t2402.0\n",
        "Exp. distr: 8062.0\t2645.0\n",
        "Exp. accu:0.832\n",
        "\n",
        "Selected Sentences"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Num sentences: 1000\n",
        "Student CM:\n",
        "594\t34\n",
        "74\t298\n",
        "True dist.: [628 372]\n",
        "St. distr : 668\t332\n",
        "St. accu: 0.892\n",
        "Expert  CM:\n",
        "600\t28\n",
        "45\t327\n",
        "Exp. distr: 645\t355\n",
        "Exp. accu: 0.927\n",
        "----------------------------------------\n",
        "Trial  4\n",
        "\n",
        "\n",
        "All sentences"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Num sentences: 10707\n",
        "Student CM:\n",
        "6685.0\t60.0\n",
        "2872.0\t1090.0\n",
        "True dist.: [ 6745.  3962.]\n",
        "St. distr : 9557.0\t1150.0\n",
        "St. accu: 0.726\n",
        "Expert  CM:\n",
        "6502.0\t243.0\n",
        "1560.0\t2402.0\n",
        "Exp. distr: 8062.0\t2645.0\n",
        "Exp. accu:0.832\n",
        "\n",
        "Selected Sentences\n",
        "Num sentences: 1000\n",
        "Student CM:\n",
        "609\t19\n",
        "88\t284\n",
        "True dist.: [628 372]\n",
        "St. distr : 697\t303\n",
        "St. accu: 0.893\n",
        "Expert  CM:\n",
        "605\t23\n",
        "50\t322\n",
        "Exp. distr: 655\t345\n",
        "Exp. accu: 0.927\n"
       ]
      }
     ],
     "prompt_number": 35
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}