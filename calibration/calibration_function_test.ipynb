{
 "metadata": {
  "name": "",
  "signature": "sha256:cbc32ead6ee3b93da0566ac636cef99ff120efc3bfefe0ca612551d9415db0cf"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Calibration Functions\n",
      "\n",
      "Testing several calibration functions using a bootstrap student and and expert model"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "'''\n",
      "Created on Dec 18, 2014\n",
      "\n",
      "@author: mbilgic\n",
      "'''\n",
      "\n",
      "## Data preparation and experiment setting \n",
      "\n",
      "STRUCTURED ='.'\n",
      "# imdb_path = 'C:/Users/mbilgic/Desktop/aclImdb/'    \n",
      "imdb_path = '../data/imdb'\n",
      "\n",
      "import sys\n",
      "import os\n",
      "sys.path.append(os.path.abspath(STRUCTURED))\n",
      "sys.path.append(os.path.abspath('/Users/maru/MyCode/structured'))\n",
      "\n",
      "import utilities.experimentutils as exputil\n",
      "import learner\n",
      "import utilities.datautils as datautil\n",
      "import numpy as np\n",
      "import experiment.base as exp\n",
      "import nltk\n",
      "\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Load the data\n",
      "print \"Loading the data...\"\n",
      "data = datautil.load_dataset('imdb', imdb_path, categories=None, rnd=5463, shuffle=True)\n",
      "sent_tk = nltk.data.load('tokenizers/punkt/english.pickle')\n",
      "\n",
      "# Vectorize the data\n",
      "print \"Vectorizing the data...\"\n",
      "vct = exputil.get_vectorizer({'vectorizer':\"tfidf\", 'limit':None, 'min_size':None})    \n",
      "data.train.bow = vct.fit_transform(data.train.data)\n",
      "data.test.bow = vct.transform(data.test.data)\n",
      "data.train.data = np.array(data.train.data, dtype=object)\n",
      "data.test.data = np.array(data.test.data, dtype=object)\n",
      "print \"Train size: (%d, %d)\" %data.train.bow.shape\n",
      "print \"Test size: (%d, %d)\" %data.test.bow.shape\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Loading the data...\n",
        "Vectorizing the data..."
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Train size: (25000, 27316)"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Test size: (25000, 27316)\n"
       ]
      }
     ],
     "prompt_number": 2
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# The expert\n",
      "print \"Training the expert...\"\n",
      "expert = exputil.get_classifier('lrl2',parameter=1)\n",
      "expert.fit(data.train.bow, data.train.target)\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Training the expert...\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 3,
       "text": [
        "LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
        "          intercept_scaling=1, penalty='l2', random_state=None, tol=0.0001)"
       ]
      }
     ],
     "prompt_number": 3
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "## Select N random documents from the test\n",
      "n = 1000\n",
      "rnd = np.random.RandomState(2345)\n",
      "rnd_docs = rnd.choice(len(data.test.target), size = n, replace = False)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 4
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "## Get the sentences per document\n",
      "sentences = sent_tk.tokenize_sents(data.test.data[rnd_docs])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 5
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "## Test trials loop\n",
      "num_trials = 5\n",
      "    \n",
      "for t in range(num_trials):\n",
      "    print \"\\n\\nTrial: %d\" %t\n",
      "    rnd = np.random.RandomState(t)\n",
      "\n",
      "    # The student\n",
      "    student = learner.strategy.StructuredLearner(exputil.get_classifier('lrl2',parameter=1))        \n",
      "    student.set_sent_tokenizer(sent_tk)\n",
      "    student.set_vct(vct)\n",
      "    student.set_snippet_utility('sr')\n",
      "\n",
      "    # Get a bootstrap\n",
      "    bootstrap_size = 200\n",
      "    bootstrap = rnd.choice(len(data.train.target), size = bootstrap_size, replace = False)\n",
      "\n",
      "    # Fit the student to bootstrap\n",
      "    print \"Training the student...\"\n",
      "    student.fit(data.train.bow[bootstrap], data.train.target[bootstrap], doc_text=data.train.data[bootstrap])\n",
      "\n",
      "    student_cm = np.zeros(shape=(2,2))\n",
      "    expert_cm = np.zeros(shape=(2,2))\n",
      "\n",
      "    for i, idx in enumerate(rnd_docs):        \n",
      "        true_target = data.test.target[idx]                \n",
      "        bow = vct.transform(sentences[i])\n",
      "\n",
      "        expert_pred = expert.predict(bow)\n",
      "        for p in expert_pred:\n",
      "            expert_cm[true_target, p] += 1\n",
      "\n",
      "        student_pred = student.snippet_model.predict(bow)\n",
      "        for p in student_pred:\n",
      "            student_cm[true_target, p] += 1\n",
      "\n",
      "\n",
      "\n",
      "    print \"\\n\\nNum test documents: %d\" %len(sentences)\n",
      "    num_sentences = 0\n",
      "    for sent in sentences:\n",
      "        num_sentences += len(sent)\n",
      "    print \"Num test sentences: %d\" %num_sentences\n",
      "\n",
      "    print \"True class distribution: %s\" % expert_cm.sum(1)\n",
      "\n",
      "    print \"Expert predictions: %s\" % expert_cm.sum(0)\n",
      "    print \"Expert accuracy: %0.4f\" % ((expert_cm[0,0]+expert_cm[1,1])/float(num_sentences))\n",
      "\n",
      "    print \"Student predictions: %s\" % student_cm.sum(0)\n",
      "    print \"Student accuracy: %0.4f\" % ((student_cm[0,0]+student_cm[1,1])/float(num_sentences))\n",
      "\n",
      "    calibration = ['_no_calibrate', 'zscores_pred', 'zscores_rank']\n",
      "\n",
      "    for cal in calibration:\n",
      "        student.set_calibration_method(cal)\n",
      "\n",
      "        _, chosen_sentences = student._compute_snippet(data.test.data[rnd_docs])\n",
      "\n",
      "        student_cm = np.zeros(shape=(2,2))\n",
      "        expert_cm = np.zeros(shape=(2,2))\n",
      "\n",
      "        for i, idx in enumerate(rnd_docs):        \n",
      "            true_target = data.test.target[idx]                \n",
      "            bow = vct.transform([chosen_sentences[i]])\n",
      "\n",
      "            expert_pred = expert.predict(bow)\n",
      "            for p in expert_pred:\n",
      "                expert_cm[true_target, p] += 1\n",
      "\n",
      "            student_pred = student.snippet_model.predict(bow)\n",
      "            for p in student_pred:\n",
      "                student_cm[true_target, p] += 1\n",
      "\n",
      "        print \"\\n\\nCalibration: %s\" %cal\n",
      "\n",
      "        num_sentences = len(chosen_sentences)\n",
      "\n",
      "        print \"Num test sentences: %d\" %num_sentences\n",
      "\n",
      "        print \"True class distribution: %s\" % expert_cm.sum(1)\n",
      "\n",
      "        print \"Expert predictions: %s\" % expert_cm.sum(0)\n",
      "        print \"Expert accuracy: %0.4f\" % ((expert_cm[0,0]+expert_cm[1,1])/float(num_sentences))\n",
      "\n",
      "        print \"Student predictions: %s\" % student_cm.sum(0)\n",
      "        print \"Student accuracy: %0.4f\" % ((student_cm[0,0]+student_cm[1,1])/float(num_sentences))        "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "\n",
        "Trial: 0\n",
        "Training the student...\n",
        "\n",
        "\n",
        "Num test documents: 1000"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Num test sentences: 10697\n",
        "True class distribution: [ 5542.  5155.]\n",
        "Expert predictions: [ 5523.  5174.]\n",
        "Expert accuracy: 0.6837\n",
        "Student predictions: [ 3615.  7082.]\n",
        "Student accuracy: 0.5882\n",
        "\n",
        "\n",
        "Calibration: _no_calibrate"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Num test sentences: 1000\n",
        "True class distribution: [ 500.  500.]\n",
        "Expert predictions: [ 424.  576.]\n",
        "Expert accuracy: 0.7340\n",
        "Student predictions: [ 342.  658.]\n",
        "Student accuracy: 0.7100\n",
        "\n",
        "\n",
        "Calibration: zscores_pred"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Num test sentences: 1000\n",
        "True class distribution: [ 500.  500.]\n",
        "Expert predictions: [ 427.  573.]\n",
        "Expert accuracy: 0.7330\n",
        "Student predictions: [ 358.  642.]\n",
        "Student accuracy: 0.7160\n",
        "\n",
        "\n",
        "Calibration: zscores_rank"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Num test sentences: 1000\n",
        "True class distribution: [ 500.  500.]\n",
        "Expert predictions: [ 487.  513.]\n",
        "Expert accuracy: 0.7330\n",
        "Student predictions: [ 479.  521.]\n",
        "Student accuracy: 0.7110\n",
        "\n",
        "\n",
        "Trial: 1\n",
        "Training the student...\n",
        "\n",
        "\n",
        "Num test documents: 1000"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Num test sentences: 10697\n",
        "True class distribution: [ 5542.  5155.]\n",
        "Expert predictions: [ 5523.  5174.]\n",
        "Expert accuracy: 0.6837\n",
        "Student predictions: [ 8573.  2124.]\n",
        "Student accuracy: 0.6002\n",
        "\n",
        "\n",
        "Calibration: _no_calibrate"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Num test sentences: 1000\n",
        "True class distribution: [ 500.  500.]\n",
        "Expert predictions: [ 699.  301.]\n",
        "Expert accuracy: 0.6990\n",
        "Student predictions: [ 886.  114.]\n",
        "Student accuracy: 0.5880\n",
        "\n",
        "\n",
        "Calibration: zscores_pred"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Num test sentences: 1000\n",
        "True class distribution: [ 500.  500.]\n",
        "Expert predictions: [ 620.  380.]\n",
        "Expert accuracy: 0.7400\n",
        "Student predictions: [ 745.  255.]\n",
        "Student accuracy: 0.6690\n",
        "\n",
        "\n",
        "Calibration: zscores_rank"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Num test sentences: 1000\n",
        "True class distribution: [ 500.  500.]\n",
        "Expert predictions: [ 489.  511.]\n",
        "Expert accuracy: 0.7610\n",
        "Student predictions: [ 507.  493.]\n",
        "Student accuracy: 0.7290\n",
        "\n",
        "\n",
        "Trial: 2\n",
        "Training the student...\n",
        "\n",
        "\n",
        "Num test documents: 1000"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Num test sentences: 10697\n",
        "True class distribution: [ 5542.  5155.]\n",
        "Expert predictions: [ 5523.  5174.]\n",
        "Expert accuracy: 0.6837\n",
        "Student predictions: [ 5317.  5380.]\n",
        "Student accuracy: 0.6318\n",
        "\n",
        "\n",
        "Calibration: _no_calibrate"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Num test sentences: 1000\n",
        "True class distribution: [ 500.  500.]\n",
        "Expert predictions: [ 517.  483.]\n",
        "Expert accuracy: 0.7770\n",
        "Student predictions: [ 495.  505.]\n",
        "Student accuracy: 0.7650\n",
        "\n",
        "\n",
        "Calibration: zscores_pred"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Num test sentences: 1000\n",
        "True class distribution: [ 500.  500.]\n",
        "Expert predictions: [ 504.  496.]\n",
        "Expert accuracy: 0.7740\n",
        "Student predictions: [ 479.  521.]\n",
        "Student accuracy: 0.7630\n",
        "\n",
        "\n",
        "Calibration: zscores_rank"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Num test sentences: 1000\n",
        "True class distribution: [ 500.  500.]\n",
        "Expert predictions: [ 509.  491.]\n",
        "Expert accuracy: 0.7770\n",
        "Student predictions: [ 485.  515.]\n",
        "Student accuracy: 0.7670\n",
        "\n",
        "\n",
        "Trial: 3\n",
        "Training the student...\n",
        "\n",
        "\n",
        "Num test documents: 1000"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Num test sentences: 10697\n",
        "True class distribution: [ 5542.  5155.]\n",
        "Expert predictions: [ 5523.  5174.]\n",
        "Expert accuracy: 0.6837\n",
        "Student predictions: [ 2059.  8638.]\n",
        "Student accuracy: 0.5603\n",
        "\n",
        "\n",
        "Calibration: _no_calibrate"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Num test sentences: 1000\n",
        "True class distribution: [ 500.  500.]\n",
        "Expert predictions: [ 319.  681.]\n",
        "Expert accuracy: 0.7130\n",
        "Student predictions: [ 121.  879.]\n",
        "Student accuracy: 0.5950\n",
        "\n",
        "\n",
        "Calibration: zscores_pred"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Num test sentences: 1000\n",
        "True class distribution: [ 500.  500.]\n",
        "Expert predictions: [ 382.  618.]\n",
        "Expert accuracy: 0.7380\n",
        "Student predictions: [ 229.  771.]\n",
        "Student accuracy: 0.6590\n",
        "\n",
        "\n",
        "Calibration: zscores_rank"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Num test sentences: 1000\n",
        "True class distribution: [ 500.  500.]\n",
        "Expert predictions: [ 488.  512.]\n",
        "Expert accuracy: 0.7500\n",
        "Student predictions: [ 465.  535.]\n",
        "Student accuracy: 0.7130\n",
        "\n",
        "\n",
        "Trial: 4\n",
        "Training the student...\n",
        "\n",
        "\n",
        "Num test documents: 1000"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Num test sentences: 10697\n",
        "True class distribution: [ 5542.  5155.]\n",
        "Expert predictions: [ 5523.  5174.]\n",
        "Expert accuracy: 0.6837\n",
        "Student predictions: [ 4719.  5978.]\n",
        "Student accuracy: 0.5822\n",
        "\n",
        "\n",
        "Calibration: _no_calibrate"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Num test sentences: 1000\n",
        "True class distribution: [ 500.  500.]\n",
        "Expert predictions: [ 525.  475.]\n",
        "Expert accuracy: 0.7330\n",
        "Student predictions: [ 533.  467.]\n",
        "Student accuracy: 0.6950\n",
        "\n",
        "\n",
        "Calibration: zscores_pred"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Num test sentences: 1000\n",
        "True class distribution: [ 500.  500.]\n",
        "Expert predictions: [ 495.  505.]\n",
        "Expert accuracy: 0.7270\n",
        "Student predictions: [ 470.  530.]\n",
        "Student accuracy: 0.6860\n",
        "\n",
        "\n",
        "Calibration: zscores_rank"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Num test sentences: 1000\n",
        "True class distribution: [ 500.  500.]\n",
        "Expert predictions: [ 522.  478.]\n",
        "Expert accuracy: 0.7300\n",
        "Student predictions: [ 526.  474.]\n",
        "Student accuracy: 0.6920\n"
       ]
      }
     ],
     "prompt_number": 7
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}